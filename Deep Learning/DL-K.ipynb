{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#masukin data1\n",
    "data1=pandas.read_csv('D:\\\\SKRIPSI\\\\data\\\\data\\\\data pakai\\\\data_herbs(!5).csv', sep=',', header=None)\n",
    "#masukin data2\n",
    "data2=pandas.read_csv('D:\\\\SKRIPSI\\\\data\\\\data\\\\data pakai\\\\data_class(!5).csv', sep=',', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>453</th>\n",
       "      <th>454</th>\n",
       "      <th>455</th>\n",
       "      <th>456</th>\n",
       "      <th>457</th>\n",
       "      <th>458</th>\n",
       "      <th>459</th>\n",
       "      <th>460</th>\n",
       "      <th>461</th>\n",
       "      <th>462</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2984</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2986</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2988</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2993</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3001</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3002</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3003</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3004</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3005</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3006</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3007</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3009</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3010</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3011</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3012</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3013</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3014 rows × 463 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4    5    6    7    8    9    ...  453  454  455  \\\n",
       "0       0    0    0    0    0    1    0    0    0    0  ...    0    0    0   \n",
       "1       0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "2       1    0    0    0    0    1    0    0    0    0  ...    0    0    0   \n",
       "3       0    0    0    0    0    0    1    0    0    0  ...    0    0    0   \n",
       "4       0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "5       0    0    0    0    0    1    0    0    0    0  ...    0    0    0   \n",
       "6       0    0    0    0    0    1    0    0    0    0  ...    0    0    0   \n",
       "7       0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "8       0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "9       0    0    0    1    0    0    0    0    0    0  ...    0    0    0   \n",
       "10      0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "11      1    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "12      0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "13      0    0    0    0    0    1    0    0    0    0  ...    0    0    0   \n",
       "14      0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "15      0    0    0    1    0    0    0    0    0    0  ...    0    0    0   \n",
       "16      0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "17      0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "18      0    0    0    0    0    1    0    0    0    0  ...    0    0    0   \n",
       "19      0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "20      0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "21      0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "22      0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "23      0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "24      0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "25      0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "26      0    0    0    0    0    1    0    0    0    0  ...    0    0    0   \n",
       "27      0    0    0    0    0    1    0    0    0    0  ...    0    0    0   \n",
       "28      0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "29      0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "2984    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "2985    1    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "2986    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "2987    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "2988    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "2989    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "2990    1    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "2991    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "2992    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "2993    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "2994    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "2995    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "2996    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "2997    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "2998    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "2999    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "3000    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "3001    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "3002    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "3003    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "3004    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "3005    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "3006    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "3007    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "3008    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "3009    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "3010    1    0    0    1    0    0    0    0    0    0  ...    0    0    0   \n",
       "3011    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "3012    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "3013    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "\n",
       "      456  457  458  459  460  461  462  \n",
       "0       0    0    0    0    0    0    0  \n",
       "1       0    0    0    0    0    0    0  \n",
       "2       0    0    0    0    0    0    0  \n",
       "3       0    0    0    0    0    0    0  \n",
       "4       0    0    0    0    0    0    0  \n",
       "5       0    0    0    0    0    0    0  \n",
       "6       0    0    0    0    0    0    0  \n",
       "7       0    0    0    0    0    0    0  \n",
       "8       0    0    0    0    0    0    0  \n",
       "9       0    0    0    0    0    0    0  \n",
       "10      0    0    0    0    0    0    0  \n",
       "11      0    0    0    0    0    0    0  \n",
       "12      0    0    0    0    0    0    0  \n",
       "13      0    0    0    0    0    0    0  \n",
       "14      0    0    0    0    0    0    0  \n",
       "15      0    0    0    0    0    0    0  \n",
       "16      0    0    0    0    0    0    0  \n",
       "17      0    0    0    0    0    0    0  \n",
       "18      0    0    0    0    0    0    0  \n",
       "19      0    0    0    0    0    0    0  \n",
       "20      0    0    0    0    0    0    0  \n",
       "21      0    0    0    0    0    0    0  \n",
       "22      0    0    0    0    0    0    0  \n",
       "23      0    0    0    0    0    0    0  \n",
       "24      0    0    0    0    0    0    0  \n",
       "25      0    0    0    0    0    0    0  \n",
       "26      0    0    0    0    0    0    0  \n",
       "27      0    0    0    0    0    0    0  \n",
       "28      0    0    0    0    0    0    0  \n",
       "29      0    0    0    0    0    0    0  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  \n",
       "2984    0    0    0    0    0    1    0  \n",
       "2985    0    0    0    0    0    0    0  \n",
       "2986    0    0    0    0    0    0    0  \n",
       "2987    0    0    0    0    0    0    0  \n",
       "2988    0    0    0    0    0    0    0  \n",
       "2989    0    0    0    0    0    0    0  \n",
       "2990    0    0    0    0    0    0    0  \n",
       "2991    0    0    0    0    0    0    0  \n",
       "2992    0    0    0    0    0    0    0  \n",
       "2993    0    0    0    0    0    0    0  \n",
       "2994    0    0    0    0    0    0    0  \n",
       "2995    0    0    0    0    0    0    0  \n",
       "2996    0    0    0    0    0    0    0  \n",
       "2997    0    0    0    0    0    0    0  \n",
       "2998    0    0    0    0    0    0    0  \n",
       "2999    0    0    0    0    0    0    0  \n",
       "3000    0    0    0    0    0    0    0  \n",
       "3001    0    0    0    0    0    0    0  \n",
       "3002    0    0    0    0    0    0    0  \n",
       "3003    0    0    0    0    0    0    0  \n",
       "3004    0    0    0    0    0    1    0  \n",
       "3005    0    0    0    0    0    0    0  \n",
       "3006    0    0    0    0    0    0    0  \n",
       "3007    0    0    0    0    0    0    0  \n",
       "3008    0    0    0    0    0    0    0  \n",
       "3009    0    0    0    0    0    0    0  \n",
       "3010    0    0    0    0    0    0    0  \n",
       "3011    0    0    0    0    0    0    0  \n",
       "3012    0    0    0    0    0    0    0  \n",
       "3013    0    0    0    0    0    0    0  \n",
       "\n",
       "[3014 rows x 463 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2984</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2986</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2988</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2993</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3001</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3002</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3003</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3004</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3005</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3006</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3007</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3009</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3010</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3011</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3012</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3013</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3014 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  16  17\n",
       "0      0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
       "1      0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
       "2      0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
       "3      0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0\n",
       "4      0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
       "5      0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
       "6      0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
       "7      0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
       "8      0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
       "9      0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
       "10     0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
       "11     0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
       "12     0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
       "13     0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0\n",
       "14     0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
       "15     0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
       "16     0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
       "17     0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
       "18     0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
       "19     0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
       "20     0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
       "21     0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
       "22     0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
       "23     0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
       "24     0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
       "25     0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
       "26     0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
       "27     0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
       "28     0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
       "29     0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
       "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..\n",
       "2984   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
       "2985   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
       "2986   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
       "2987   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
       "2988   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
       "2989   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
       "2990   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
       "2991   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
       "2992   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
       "2993   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
       "2994   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
       "2995   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
       "2996   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
       "2997   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
       "2998   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
       "2999   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
       "3000   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
       "3001   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
       "3002   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
       "3003   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
       "3004   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
       "3005   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
       "3006   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
       "3007   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
       "3008   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
       "3009   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
       "3010   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
       "3011   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
       "3012   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
       "3013   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
       "\n",
       "[3014 rows x 18 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data1\n",
    "y = data2\n",
    "z = pandas.read_csv('D:\\\\SKRIPSI\\\\data\\\\data\\\\data pakai\\\\class(!5).csv', sep=',', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2984</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2986</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2988</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2993</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3001</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3002</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3003</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3004</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3005</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3006</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3007</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3009</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3010</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3011</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3012</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3013</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3014 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0     17\n",
       "1     17\n",
       "2     17\n",
       "3     10\n",
       "4     17\n",
       "5     17\n",
       "6     17\n",
       "7     17\n",
       "8     17\n",
       "9     17\n",
       "10    17\n",
       "11    17\n",
       "12    17\n",
       "13    10\n",
       "14    17\n",
       "15    17\n",
       "16    17\n",
       "17    17\n",
       "18    17\n",
       "19    17\n",
       "20    17\n",
       "21    17\n",
       "22    17\n",
       "23    17\n",
       "24    17\n",
       "25    17\n",
       "26    17\n",
       "27    17\n",
       "28    17\n",
       "29    17\n",
       "...   ..\n",
       "2984  16\n",
       "2985  16\n",
       "2986  16\n",
       "2987  16\n",
       "2988  16\n",
       "2989  16\n",
       "2990  16\n",
       "2991  16\n",
       "2992  16\n",
       "2993  16\n",
       "2994  16\n",
       "2995  16\n",
       "2996  16\n",
       "2997  16\n",
       "2998  16\n",
       "2999  16\n",
       "3000  16\n",
       "3001  16\n",
       "3002  16\n",
       "3003  16\n",
       "3004  16\n",
       "3005  16\n",
       "3006  16\n",
       "3007  16\n",
       "3008  16\n",
       "3009  16\n",
       "3010  16\n",
       "3011  16\n",
       "3012  16\n",
       "3013  16\n",
       "\n",
       "[3014 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=4.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 :\n",
      "\n",
      "Train on 2253 samples, validate on 761 samples\n",
      "Epoch 1/30\n",
      "2253/2253 [==============================] - 5s 2ms/step - loss: 0.1708 - binary_accuracy: 0.9461 - val_loss: 0.1554 - val_binary_accuracy: 0.9501\n",
      "Epoch 2/30\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1365 - binary_accuracy: 0.9549 - val_loss: 0.1455 - val_binary_accuracy: 0.9523\n",
      "Epoch 3/30\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1141 - binary_accuracy: 0.9630 - val_loss: 0.1377 - val_binary_accuracy: 0.9547\n",
      "Epoch 4/30\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0989 - binary_accuracy: 0.9675 - val_loss: 0.1484 - val_binary_accuracy: 0.9532\n",
      "Epoch 5/30\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0848 - binary_accuracy: 0.9719 - val_loss: 0.1544 - val_binary_accuracy: 0.9533\n",
      "Epoch 6/30\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0756 - binary_accuracy: 0.9758 - val_loss: 0.1821 - val_binary_accuracy: 0.9528\n",
      "Epoch 7/30\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0653 - binary_accuracy: 0.9789 - val_loss: 0.1714 - val_binary_accuracy: 0.9523\n",
      "Epoch 8/30\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0640 - binary_accuracy: 0.9796 - val_loss: 0.1925 - val_binary_accuracy: 0.9515\n",
      "Epoch 9/30\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0576 - binary_accuracy: 0.9823 - val_loss: 0.1784 - val_binary_accuracy: 0.9520\n",
      "Epoch 10/30\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0499 - binary_accuracy: 0.9842 - val_loss: 0.2119 - val_binary_accuracy: 0.9513\n",
      "Epoch 11/30\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0458 - binary_accuracy: 0.9856 - val_loss: 0.2322 - val_binary_accuracy: 0.9516\n",
      "Epoch 12/30\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0444 - binary_accuracy: 0.9868 - val_loss: 0.2723 - val_binary_accuracy: 0.9483\n",
      "Epoch 13/30\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0436 - binary_accuracy: 0.9866 - val_loss: 0.2250 - val_binary_accuracy: 0.9520\n",
      "Epoch 14/30\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0399 - binary_accuracy: 0.9875 - val_loss: 0.2625 - val_binary_accuracy: 0.9485\n",
      "Epoch 15/30\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0388 - binary_accuracy: 0.9875 - val_loss: 0.2914 - val_binary_accuracy: 0.9491\n",
      "Epoch 16/30\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0346 - binary_accuracy: 0.9890 - val_loss: 0.2904 - val_binary_accuracy: 0.9501\n",
      "Epoch 17/30\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0342 - binary_accuracy: 0.9899 - val_loss: 0.2798 - val_binary_accuracy: 0.9512\n",
      "Epoch 18/30\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0281 - binary_accuracy: 0.9913 - val_loss: 0.2958 - val_binary_accuracy: 0.9488\n",
      "Epoch 19/30\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0270 - binary_accuracy: 0.9915 - val_loss: 0.2883 - val_binary_accuracy: 0.9515\n",
      "Epoch 20/30\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0299 - binary_accuracy: 0.9909 - val_loss: 0.2754 - val_binary_accuracy: 0.9532\n",
      "Epoch 21/30\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0289 - binary_accuracy: 0.9911 - val_loss: 0.2570 - val_binary_accuracy: 0.9509\n",
      "Epoch 22/30\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0256 - binary_accuracy: 0.9924 - val_loss: 0.2900 - val_binary_accuracy: 0.9498\n",
      "Epoch 23/30\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0225 - binary_accuracy: 0.9931 - val_loss: 0.3744 - val_binary_accuracy: 0.9493\n",
      "Epoch 24/30\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0234 - binary_accuracy: 0.9930 - val_loss: 0.3590 - val_binary_accuracy: 0.9507\n",
      "Epoch 25/30\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0217 - binary_accuracy: 0.9933 - val_loss: 0.3483 - val_binary_accuracy: 0.9513\n",
      "Epoch 26/30\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0256 - binary_accuracy: 0.9926 - val_loss: 0.3754 - val_binary_accuracy: 0.9478\n",
      "Epoch 27/30\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0224 - binary_accuracy: 0.9933 - val_loss: 0.3441 - val_binary_accuracy: 0.9511\n",
      "Epoch 28/30\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0239 - binary_accuracy: 0.9927 - val_loss: 0.3489 - val_binary_accuracy: 0.9501\n",
      "Epoch 29/30\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0249 - binary_accuracy: 0.9933 - val_loss: 0.2915 - val_binary_accuracy: 0.9504\n",
      "Epoch 30/30\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0269 - binary_accuracy: 0.9925 - val_loss: 0.3193 - val_binary_accuracy: 0.9519\n",
      "761/761 [==============================] - 0s 244us/step\n",
      "Fold 2 :\n",
      "\n",
      "Train on 2260 samples, validate on 754 samples\n",
      "Epoch 1/30\n",
      "2260/2260 [==============================] - 5s 2ms/step - loss: 0.1716 - binary_accuracy: 0.9456 - val_loss: 0.1518 - val_binary_accuracy: 0.9483\n",
      "Epoch 2/30\n",
      "2260/2260 [==============================] - 4s 2ms/step - loss: 0.1426 - binary_accuracy: 0.9531 - val_loss: 0.1406 - val_binary_accuracy: 0.9527\n",
      "Epoch 3/30\n",
      "2260/2260 [==============================] - 4s 2ms/step - loss: 0.1228 - binary_accuracy: 0.9595 - val_loss: 0.1377 - val_binary_accuracy: 0.9546\n",
      "Epoch 4/30\n",
      "2260/2260 [==============================] - 4s 2ms/step - loss: 0.1099 - binary_accuracy: 0.9648 - val_loss: 0.1286 - val_binary_accuracy: 0.9576\n",
      "Epoch 5/30\n",
      "2260/2260 [==============================] - 4s 2ms/step - loss: 0.0984 - binary_accuracy: 0.9685 - val_loss: 0.1329 - val_binary_accuracy: 0.9600\n",
      "Epoch 6/30\n",
      "2260/2260 [==============================] - 4s 2ms/step - loss: 0.0874 - binary_accuracy: 0.9718 - val_loss: 0.1404 - val_binary_accuracy: 0.9595\n",
      "Epoch 7/30\n",
      "2260/2260 [==============================] - 4s 2ms/step - loss: 0.0789 - binary_accuracy: 0.9754 - val_loss: 0.1416 - val_binary_accuracy: 0.9605\n",
      "Epoch 8/30\n",
      "2260/2260 [==============================] - 4s 2ms/step - loss: 0.0716 - binary_accuracy: 0.9781 - val_loss: 0.1377 - val_binary_accuracy: 0.9591\n",
      "Epoch 9/30\n",
      "2260/2260 [==============================] - 4s 2ms/step - loss: 0.0641 - binary_accuracy: 0.9788 - val_loss: 0.1769 - val_binary_accuracy: 0.9581\n",
      "Epoch 10/30\n",
      "2260/2260 [==============================] - 4s 2ms/step - loss: 0.0644 - binary_accuracy: 0.9800 - val_loss: 0.1657 - val_binary_accuracy: 0.9600\n",
      "Epoch 11/30\n",
      "2260/2260 [==============================] - 4s 2ms/step - loss: 0.0592 - binary_accuracy: 0.9815 - val_loss: 0.1855 - val_binary_accuracy: 0.9583\n",
      "Epoch 12/30\n",
      "2260/2260 [==============================] - 4s 2ms/step - loss: 0.0544 - binary_accuracy: 0.9832 - val_loss: 0.2134 - val_binary_accuracy: 0.9570\n",
      "Epoch 13/30\n",
      "2260/2260 [==============================] - 4s 2ms/step - loss: 0.0475 - binary_accuracy: 0.9853 - val_loss: 0.2070 - val_binary_accuracy: 0.9574\n",
      "Epoch 14/30\n",
      "2260/2260 [==============================] - 4s 2ms/step - loss: 0.0420 - binary_accuracy: 0.9861 - val_loss: 0.2097 - val_binary_accuracy: 0.9564\n",
      "Epoch 15/30\n",
      "2260/2260 [==============================] - 4s 2ms/step - loss: 0.0418 - binary_accuracy: 0.9864 - val_loss: 0.2201 - val_binary_accuracy: 0.9581\n",
      "Epoch 16/30\n",
      "2260/2260 [==============================] - 4s 2ms/step - loss: 0.0426 - binary_accuracy: 0.9870 - val_loss: 0.2470 - val_binary_accuracy: 0.9584\n",
      "Epoch 17/30\n",
      "2260/2260 [==============================] - 5s 2ms/step - loss: 0.0423 - binary_accuracy: 0.9868 - val_loss: 0.2202 - val_binary_accuracy: 0.9572\n",
      "Epoch 18/30\n",
      "2260/2260 [==============================] - 4s 2ms/step - loss: 0.0391 - binary_accuracy: 0.9876 - val_loss: 0.2121 - val_binary_accuracy: 0.9581\n",
      "Epoch 19/30\n",
      "2260/2260 [==============================] - 4s 2ms/step - loss: 0.0355 - binary_accuracy: 0.9890 - val_loss: 0.2339 - val_binary_accuracy: 0.9587\n",
      "Epoch 20/30\n",
      "2260/2260 [==============================] - 4s 2ms/step - loss: 0.0346 - binary_accuracy: 0.9897 - val_loss: 0.2542 - val_binary_accuracy: 0.9590\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2260/2260 [==============================] - 4s 2ms/step - loss: 0.0353 - binary_accuracy: 0.9891 - val_loss: 0.2589 - val_binary_accuracy: 0.9579\n",
      "Epoch 22/30\n",
      "2260/2260 [==============================] - 4s 2ms/step - loss: 0.0339 - binary_accuracy: 0.9894 - val_loss: 0.2605 - val_binary_accuracy: 0.9546\n",
      "Epoch 23/30\n",
      "2260/2260 [==============================] - 4s 2ms/step - loss: 0.0338 - binary_accuracy: 0.9896 - val_loss: 0.2700 - val_binary_accuracy: 0.9570\n",
      "Epoch 24/30\n",
      "2260/2260 [==============================] - 4s 2ms/step - loss: 0.0294 - binary_accuracy: 0.9912 - val_loss: 0.2472 - val_binary_accuracy: 0.9580\n",
      "Epoch 25/30\n",
      "2260/2260 [==============================] - 4s 2ms/step - loss: 0.0283 - binary_accuracy: 0.9912 - val_loss: 0.2845 - val_binary_accuracy: 0.9574\n",
      "Epoch 26/30\n",
      "2260/2260 [==============================] - 4s 2ms/step - loss: 0.0268 - binary_accuracy: 0.9916 - val_loss: 0.3090 - val_binary_accuracy: 0.9569\n",
      "Epoch 27/30\n",
      "2260/2260 [==============================] - 4s 2ms/step - loss: 0.0305 - binary_accuracy: 0.9909 - val_loss: 0.2671 - val_binary_accuracy: 0.9562\n",
      "Epoch 28/30\n",
      "2260/2260 [==============================] - 4s 2ms/step - loss: 0.0263 - binary_accuracy: 0.9920 - val_loss: 0.2469 - val_binary_accuracy: 0.9584\n",
      "Epoch 29/30\n",
      "2260/2260 [==============================] - 4s 2ms/step - loss: 0.0252 - binary_accuracy: 0.9923 - val_loss: 0.2733 - val_binary_accuracy: 0.9570\n",
      "Epoch 30/30\n",
      "2260/2260 [==============================] - 4s 2ms/step - loss: 0.0230 - binary_accuracy: 0.9930 - val_loss: 0.3271 - val_binary_accuracy: 0.9579\n",
      "754/754 [==============================] - 0s 258us/step\n",
      "Fold 3 :\n",
      "\n",
      "Train on 2264 samples, validate on 750 samples\n",
      "Epoch 1/30\n",
      "2264/2264 [==============================] - 5s 2ms/step - loss: 0.1697 - binary_accuracy: 0.9458 - val_loss: 0.1515 - val_binary_accuracy: 0.9480\n",
      "Epoch 2/30\n",
      "2264/2264 [==============================] - 4s 2ms/step - loss: 0.1392 - binary_accuracy: 0.9538 - val_loss: 0.1477 - val_binary_accuracy: 0.9501\n",
      "Epoch 3/30\n",
      "2264/2264 [==============================] - 4s 2ms/step - loss: 0.1220 - binary_accuracy: 0.9593 - val_loss: 0.1463 - val_binary_accuracy: 0.9554\n",
      "Epoch 4/30\n",
      "2264/2264 [==============================] - 4s 2ms/step - loss: 0.1095 - binary_accuracy: 0.9639 - val_loss: 0.1480 - val_binary_accuracy: 0.9570\n",
      "Epoch 5/30\n",
      "2264/2264 [==============================] - 4s 2ms/step - loss: 0.0980 - binary_accuracy: 0.9688 - val_loss: 0.1374 - val_binary_accuracy: 0.9578\n",
      "Epoch 6/30\n",
      "2264/2264 [==============================] - 4s 2ms/step - loss: 0.0883 - binary_accuracy: 0.9721 - val_loss: 0.1556 - val_binary_accuracy: 0.9563\n",
      "Epoch 7/30\n",
      "2264/2264 [==============================] - 4s 2ms/step - loss: 0.0815 - binary_accuracy: 0.9737 - val_loss: 0.1569 - val_binary_accuracy: 0.9585\n",
      "Epoch 8/30\n",
      "2264/2264 [==============================] - 4s 2ms/step - loss: 0.0730 - binary_accuracy: 0.9759 - val_loss: 0.1747 - val_binary_accuracy: 0.9577\n",
      "Epoch 9/30\n",
      "2264/2264 [==============================] - 4s 2ms/step - loss: 0.0686 - binary_accuracy: 0.9774 - val_loss: 0.1680 - val_binary_accuracy: 0.9590\n",
      "Epoch 10/30\n",
      "2264/2264 [==============================] - 4s 2ms/step - loss: 0.0627 - binary_accuracy: 0.9796 - val_loss: 0.1861 - val_binary_accuracy: 0.9584\n",
      "Epoch 11/30\n",
      "2264/2264 [==============================] - 4s 2ms/step - loss: 0.0574 - binary_accuracy: 0.9808 - val_loss: 0.2052 - val_binary_accuracy: 0.9578\n",
      "Epoch 12/30\n",
      "2264/2264 [==============================] - 4s 2ms/step - loss: 0.0559 - binary_accuracy: 0.9818 - val_loss: 0.2018 - val_binary_accuracy: 0.9589\n",
      "Epoch 13/30\n",
      "2264/2264 [==============================] - 4s 2ms/step - loss: 0.0516 - binary_accuracy: 0.9834 - val_loss: 0.2024 - val_binary_accuracy: 0.9586\n",
      "Epoch 14/30\n",
      "2264/2264 [==============================] - 4s 2ms/step - loss: 0.0482 - binary_accuracy: 0.9846 - val_loss: 0.2155 - val_binary_accuracy: 0.9578\n",
      "Epoch 15/30\n",
      "2264/2264 [==============================] - 4s 2ms/step - loss: 0.0456 - binary_accuracy: 0.9851 - val_loss: 0.2291 - val_binary_accuracy: 0.9559\n",
      "Epoch 16/30\n",
      "2264/2264 [==============================] - 4s 2ms/step - loss: 0.0439 - binary_accuracy: 0.9864 - val_loss: 0.2216 - val_binary_accuracy: 0.9556\n",
      "Epoch 17/30\n",
      "2264/2264 [==============================] - 4s 2ms/step - loss: 0.0396 - binary_accuracy: 0.9877 - val_loss: 0.2623 - val_binary_accuracy: 0.9579\n",
      "Epoch 18/30\n",
      "2264/2264 [==============================] - 4s 2ms/step - loss: 0.0392 - binary_accuracy: 0.9877 - val_loss: 0.2343 - val_binary_accuracy: 0.9597\n",
      "Epoch 19/30\n",
      "2264/2264 [==============================] - 4s 2ms/step - loss: 0.0388 - binary_accuracy: 0.9881 - val_loss: 0.2395 - val_binary_accuracy: 0.9587\n",
      "Epoch 20/30\n",
      "2264/2264 [==============================] - 4s 2ms/step - loss: 0.0339 - binary_accuracy: 0.9894 - val_loss: 0.2538 - val_binary_accuracy: 0.9581\n",
      "Epoch 21/30\n",
      "2264/2264 [==============================] - 5s 2ms/step - loss: 0.0340 - binary_accuracy: 0.9896 - val_loss: 0.2617 - val_binary_accuracy: 0.9570\n",
      "Epoch 22/30\n",
      "2264/2264 [==============================] - 4s 2ms/step - loss: 0.0340 - binary_accuracy: 0.9900 - val_loss: 0.2428 - val_binary_accuracy: 0.9567\n",
      "Epoch 23/30\n",
      "2264/2264 [==============================] - 4s 2ms/step - loss: 0.0348 - binary_accuracy: 0.9896 - val_loss: 0.2326 - val_binary_accuracy: 0.9576\n",
      "Epoch 24/30\n",
      "2264/2264 [==============================] - 4s 2ms/step - loss: 0.0327 - binary_accuracy: 0.9903 - val_loss: 0.2540 - val_binary_accuracy: 0.9558\n",
      "Epoch 25/30\n",
      "2264/2264 [==============================] - 4s 2ms/step - loss: 0.0296 - binary_accuracy: 0.9909 - val_loss: 0.3148 - val_binary_accuracy: 0.9587\n",
      "Epoch 26/30\n",
      "2264/2264 [==============================] - 4s 2ms/step - loss: 0.0297 - binary_accuracy: 0.9910 - val_loss: 0.2933 - val_binary_accuracy: 0.9582\n",
      "Epoch 27/30\n",
      "2264/2264 [==============================] - 4s 2ms/step - loss: 0.0267 - binary_accuracy: 0.9914 - val_loss: 0.3027 - val_binary_accuracy: 0.9566\n",
      "Epoch 28/30\n",
      "2264/2264 [==============================] - 4s 2ms/step - loss: 0.0266 - binary_accuracy: 0.9918 - val_loss: 0.2591 - val_binary_accuracy: 0.9576\n",
      "Epoch 29/30\n",
      "2264/2264 [==============================] - 4s 2ms/step - loss: 0.0256 - binary_accuracy: 0.9919 - val_loss: 0.2814 - val_binary_accuracy: 0.9569\n",
      "Epoch 30/30\n",
      "2264/2264 [==============================] - 4s 2ms/step - loss: 0.0285 - binary_accuracy: 0.9916 - val_loss: 0.3374 - val_binary_accuracy: 0.9569\n",
      "750/750 [==============================] - 0s 243us/step\n",
      "Fold 4 :\n",
      "\n",
      "Train on 2265 samples, validate on 749 samples\n",
      "Epoch 1/30\n",
      "2265/2265 [==============================] - 5s 2ms/step - loss: 0.1700 - binary_accuracy: 0.9454 - val_loss: 0.1541 - val_binary_accuracy: 0.9486\n",
      "Epoch 2/30\n",
      "2265/2265 [==============================] - 4s 2ms/step - loss: 0.1419 - binary_accuracy: 0.9529 - val_loss: 0.1354 - val_binary_accuracy: 0.9549\n",
      "Epoch 3/30\n",
      "2265/2265 [==============================] - 4s 2ms/step - loss: 0.1213 - binary_accuracy: 0.9596 - val_loss: 0.1255 - val_binary_accuracy: 0.9596\n",
      "Epoch 4/30\n",
      "2265/2265 [==============================] - 4s 2ms/step - loss: 0.1046 - binary_accuracy: 0.9658 - val_loss: 0.1337 - val_binary_accuracy: 0.9611\n",
      "Epoch 5/30\n",
      "2265/2265 [==============================] - 4s 2ms/step - loss: 0.0955 - binary_accuracy: 0.9699 - val_loss: 0.1341 - val_binary_accuracy: 0.9602\n",
      "Epoch 6/30\n",
      "2265/2265 [==============================] - 4s 2ms/step - loss: 0.0852 - binary_accuracy: 0.9726 - val_loss: 0.1543 - val_binary_accuracy: 0.9585\n",
      "Epoch 7/30\n",
      "2265/2265 [==============================] - 4s 2ms/step - loss: 0.0780 - binary_accuracy: 0.9751 - val_loss: 0.1551 - val_binary_accuracy: 0.9575\n",
      "Epoch 8/30\n",
      "2265/2265 [==============================] - 4s 2ms/step - loss: 0.0715 - binary_accuracy: 0.9760 - val_loss: 0.1729 - val_binary_accuracy: 0.9589\n",
      "Epoch 9/30\n",
      "2265/2265 [==============================] - 4s 2ms/step - loss: 0.0665 - binary_accuracy: 0.9786 - val_loss: 0.1892 - val_binary_accuracy: 0.9578\n",
      "Epoch 10/30\n",
      "2265/2265 [==============================] - 4s 2ms/step - loss: 0.0612 - binary_accuracy: 0.9800 - val_loss: 0.1788 - val_binary_accuracy: 0.9601\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2265/2265 [==============================] - 4s 2ms/step - loss: 0.0555 - binary_accuracy: 0.9812 - val_loss: 0.1963 - val_binary_accuracy: 0.9588\n",
      "Epoch 12/30\n",
      "2265/2265 [==============================] - 4s 2ms/step - loss: 0.0525 - binary_accuracy: 0.9831 - val_loss: 0.1763 - val_binary_accuracy: 0.9589\n",
      "Epoch 13/30\n",
      "2265/2265 [==============================] - 4s 2ms/step - loss: 0.0480 - binary_accuracy: 0.9846 - val_loss: 0.1983 - val_binary_accuracy: 0.9595\n",
      "Epoch 14/30\n",
      "2265/2265 [==============================] - 4s 2ms/step - loss: 0.0481 - binary_accuracy: 0.9844 - val_loss: 0.1808 - val_binary_accuracy: 0.9613\n",
      "Epoch 15/30\n",
      "2265/2265 [==============================] - 4s 2ms/step - loss: 0.0440 - binary_accuracy: 0.9862 - val_loss: 0.1936 - val_binary_accuracy: 0.9585\n",
      "Epoch 16/30\n",
      "2265/2265 [==============================] - 4s 2ms/step - loss: 0.0406 - binary_accuracy: 0.9873 - val_loss: 0.2265 - val_binary_accuracy: 0.9585\n",
      "Epoch 17/30\n",
      "2265/2265 [==============================] - 4s 2ms/step - loss: 0.0397 - binary_accuracy: 0.9876 - val_loss: 0.2262 - val_binary_accuracy: 0.95850\n",
      "Epoch 18/30\n",
      "2265/2265 [==============================] - 4s 2ms/step - loss: 0.0378 - binary_accuracy: 0.9886 - val_loss: 0.2581 - val_binary_accuracy: 0.9560\n",
      "Epoch 19/30\n",
      "2265/2265 [==============================] - 4s 2ms/step - loss: 0.0380 - binary_accuracy: 0.9880 - val_loss: 0.2495 - val_binary_accuracy: 0.9599\n",
      "Epoch 20/30\n",
      "2265/2265 [==============================] - 4s 2ms/step - loss: 0.0355 - binary_accuracy: 0.9889 - val_loss: 0.2069 - val_binary_accuracy: 0.9597\n",
      "Epoch 21/30\n",
      "2265/2265 [==============================] - 4s 2ms/step - loss: 0.0348 - binary_accuracy: 0.9896 - val_loss: 0.2340 - val_binary_accuracy: 0.9581\n",
      "Epoch 22/30\n",
      "2265/2265 [==============================] - 4s 2ms/step - loss: 0.0292 - binary_accuracy: 0.9910 - val_loss: 0.2524 - val_binary_accuracy: 0.9594\n",
      "Epoch 23/30\n",
      "2265/2265 [==============================] - 4s 2ms/step - loss: 0.0273 - binary_accuracy: 0.9915 - val_loss: 0.2485 - val_binary_accuracy: 0.9594\n",
      "Epoch 24/30\n",
      "2265/2265 [==============================] - 4s 2ms/step - loss: 0.0287 - binary_accuracy: 0.9911 - val_loss: 0.2181 - val_binary_accuracy: 0.9595\n",
      "Epoch 25/30\n",
      "2265/2265 [==============================] - 4s 2ms/step - loss: 0.0305 - binary_accuracy: 0.9908 - val_loss: 0.2633 - val_binary_accuracy: 0.9572\n",
      "Epoch 26/30\n",
      "2265/2265 [==============================] - 4s 2ms/step - loss: 0.0279 - binary_accuracy: 0.9919 - val_loss: 0.2605 - val_binary_accuracy: 0.9588\n",
      "Epoch 27/30\n",
      "2265/2265 [==============================] - 4s 2ms/step - loss: 0.0236 - binary_accuracy: 0.9926 - val_loss: 0.2612 - val_binary_accuracy: 0.9581\n",
      "Epoch 28/30\n",
      "2265/2265 [==============================] - 4s 2ms/step - loss: 0.0225 - binary_accuracy: 0.9927 - val_loss: 0.2881 - val_binary_accuracy: 0.9587\n",
      "Epoch 29/30\n",
      "2265/2265 [==============================] - 4s 2ms/step - loss: 0.0235 - binary_accuracy: 0.9925 - val_loss: 0.2727 - val_binary_accuracy: 0.9591\n",
      "Epoch 30/30\n",
      "2265/2265 [==============================] - 4s 2ms/step - loss: 0.0223 - binary_accuracy: 0.9929 - val_loss: 0.2640 - val_binary_accuracy: 0.9576\n",
      "749/749 [==============================] - 0s 241us/step\n"
     ]
    }
   ],
   "source": [
    "#k=4, fungsi aktivasi=ReLU, nilai dropout=0.4\n",
    "kf = StratifiedKFold(n_splits=4, random_state=None, shuffle=False)\n",
    "val_loss_cv = []\n",
    "val_acc_cv = []\n",
    "j = 0\n",
    "for train_index, test_index in kf.split(X,z):\n",
    "    j+=1\n",
    "    print(f\"Fold {j} :\")\n",
    "    print(\"\")\n",
    "    X_train,X_test = X.iloc[train_index,:],X.iloc[test_index,:]\n",
    "    y_train,y_test = y.iloc[train_index,:],y.iloc[test_index,:]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim=X_train.shape[1], units=463,\n",
    "                     kernel_initializer='normal', bias_initializer='zeros'))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    for i in range(0, 6):\n",
    "        model.add(Dense(units=463, kernel_initializer='normal',\n",
    "                         bias_initializer='zeros'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(.4))\n",
    "\n",
    "    model.add(Dense(units=18))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
    "    model.fit(X_train, y_train,batch_size=24,epochs=30,verbose=1,validation_data=(X_test, y_test))\n",
    "    score = model.evaluate(X_test, y_test, verbose=1)\n",
    "    val_loss_cv.append(score[0])\n",
    "    val_acc_cv.append(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss_cv : [0.3192877048105197, 0.327115672573803, 0.3373868299325307, 0.2639534745181355]\n",
      "mean_val_loss_cv : 0.31193592045874724\n",
      "val_acc_cv : [0.9518907782126037, 0.957928076030721, 0.9568888792991638, 0.9575730516054284]\n",
      "mean_val_acc_cv : 0.9560701962869792\n"
     ]
    }
   ],
   "source": [
    "print(f\"val_loss_cv : {val_loss_cv}\")\n",
    "print(f\"mean_val_loss_cv : {np.mean(val_loss_cv)}\")\n",
    "print(f\"val_acc_cv : {val_acc_cv}\")\n",
    "print(f\"mean_val_acc_cv : {np.mean(val_acc_cv)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 :\n",
      "\n",
      "Train on 2403 samples, validate on 611 samples\n",
      "Epoch 1/30\n",
      "2403/2403 [==============================] - 6s 2ms/step - loss: 0.1714 - binary_accuracy: 0.9454 - val_loss: 0.1509 - val_binary_accuracy: 0.9482\n",
      "Epoch 2/30\n",
      "2403/2403 [==============================] - 5s 2ms/step - loss: 0.1387 - binary_accuracy: 0.9540 - val_loss: 0.1331 - val_binary_accuracy: 0.9564\n",
      "Epoch 3/30\n",
      "2403/2403 [==============================] - 4s 2ms/step - loss: 0.1147 - binary_accuracy: 0.9625 - val_loss: 0.1381 - val_binary_accuracy: 0.9544\n",
      "Epoch 4/30\n",
      "2403/2403 [==============================] - 4s 2ms/step - loss: 0.0994 - binary_accuracy: 0.9682 - val_loss: 0.1493 - val_binary_accuracy: 0.9531\n",
      "Epoch 5/30\n",
      "2403/2403 [==============================] - 4s 2ms/step - loss: 0.0895 - binary_accuracy: 0.9710 - val_loss: 0.1410 - val_binary_accuracy: 0.9542s: 0.0880 - binary_ac\n",
      "Epoch 6/30\n",
      "2403/2403 [==============================] - 4s 2ms/step - loss: 0.0768 - binary_accuracy: 0.9749 - val_loss: 0.1659 - val_binary_accuracy: 0.9532\n",
      "Epoch 7/30\n",
      "2403/2403 [==============================] - 4s 2ms/step - loss: 0.0694 - binary_accuracy: 0.9780 - val_loss: 0.1862 - val_binary_accuracy: 0.9514\n",
      "Epoch 8/30\n",
      "2403/2403 [==============================] - 4s 2ms/step - loss: 0.0639 - binary_accuracy: 0.9798 - val_loss: 0.1795 - val_binary_accuracy: 0.9534\n",
      "Epoch 9/30\n",
      "2403/2403 [==============================] - 4s 2ms/step - loss: 0.0612 - binary_accuracy: 0.9805 - val_loss: 0.1740 - val_binary_accuracy: 0.9547\n",
      "Epoch 10/30\n",
      "2403/2403 [==============================] - 4s 2ms/step - loss: 0.0520 - binary_accuracy: 0.9839 - val_loss: 0.1927 - val_binary_accuracy: 0.9520\n",
      "Epoch 11/30\n",
      "2403/2403 [==============================] - 5s 2ms/step - loss: 0.0485 - binary_accuracy: 0.9848 - val_loss: 0.2248 - val_binary_accuracy: 0.9516\n",
      "Epoch 12/30\n",
      "2403/2403 [==============================] - 4s 2ms/step - loss: 0.0486 - binary_accuracy: 0.9850 - val_loss: 0.1878 - val_binary_accuracy: 0.9554: 1s - loss: 0.0470 - binary_accuracy: - ETA: 0s - loss: 0.0467 - binary_accu\n",
      "Epoch 13/30\n",
      "2403/2403 [==============================] - 4s 2ms/step - loss: 0.0445 - binary_accuracy: 0.9857 - val_loss: 0.2189 - val_binary_accuracy: 0.9510\n",
      "Epoch 14/30\n",
      "2403/2403 [==============================] - 4s 2ms/step - loss: 0.0391 - binary_accuracy: 0.9875 - val_loss: 0.2295 - val_binary_accuracy: 0.9520\n",
      "Epoch 15/30\n",
      "2403/2403 [==============================] - 5s 2ms/step - loss: 0.0333 - binary_accuracy: 0.9892 - val_loss: 0.2316 - val_binary_accuracy: 0.9509\n",
      "Epoch 16/30\n",
      "2403/2403 [==============================] - 5s 2ms/step - loss: 0.0338 - binary_accuracy: 0.9893 - val_loss: 0.2799 - val_binary_accuracy: 0.9510\n",
      "Epoch 17/30\n",
      "2403/2403 [==============================] - 4s 2ms/step - loss: 0.0354 - binary_accuracy: 0.9893 - val_loss: 0.2609 - val_binary_accuracy: 0.9506\n",
      "Epoch 18/30\n",
      "2403/2403 [==============================] - 5s 2ms/step - loss: 0.0354 - binary_accuracy: 0.9894 - val_loss: 0.2952 - val_binary_accuracy: 0.9467\n",
      "Epoch 19/30\n",
      "2403/2403 [==============================] - 4s 2ms/step - loss: 0.0378 - binary_accuracy: 0.9894 - val_loss: 0.2524 - val_binary_accuracy: 0.9504\n",
      "Epoch 20/30\n",
      "2403/2403 [==============================] - 5s 2ms/step - loss: 0.0310 - binary_accuracy: 0.9906 - val_loss: 0.2862 - val_binary_accuracy: 0.9491\n",
      "Epoch 21/30\n",
      "2403/2403 [==============================] - 4s 2ms/step - loss: 0.0261 - binary_accuracy: 0.9921 - val_loss: 0.2704 - val_binary_accuracy: 0.9521\n",
      "Epoch 22/30\n",
      "2403/2403 [==============================] - 4s 2ms/step - loss: 0.0265 - binary_accuracy: 0.9919 - val_loss: 0.2922 - val_binary_accuracy: 0.9484\n",
      "Epoch 23/30\n",
      "2403/2403 [==============================] - 5s 2ms/step - loss: 0.0259 - binary_accuracy: 0.9926 - val_loss: 0.3256 - val_binary_accuracy: 0.9492\n",
      "Epoch 24/30\n",
      "2403/2403 [==============================] - 5s 2ms/step - loss: 0.0285 - binary_accuracy: 0.9917 - val_loss: 0.3022 - val_binary_accuracy: 0.9486\n",
      "Epoch 25/30\n",
      "2403/2403 [==============================] - 5s 2ms/step - loss: 0.0212 - binary_accuracy: 0.9927 - val_loss: 0.3754 - val_binary_accuracy: 0.9486\n",
      "Epoch 26/30\n",
      "2403/2403 [==============================] - 5s 2ms/step - loss: 0.0262 - binary_accuracy: 0.9923 - val_loss: 0.2909 - val_binary_accuracy: 0.9510\n",
      "Epoch 27/30\n",
      "2403/2403 [==============================] - 5s 2ms/step - loss: 0.0212 - binary_accuracy: 0.9932 - val_loss: 0.3268 - val_binary_accuracy: 0.9522\n",
      "Epoch 28/30\n",
      "2403/2403 [==============================] - 5s 2ms/step - loss: 0.0239 - binary_accuracy: 0.9931 - val_loss: 0.3139 - val_binary_accuracy: 0.9504\n",
      "Epoch 29/30\n",
      "2403/2403 [==============================] - 5s 2ms/step - loss: 0.0219 - binary_accuracy: 0.9937 - val_loss: 0.3413 - val_binary_accuracy: 0.9514\n",
      "Epoch 30/30\n",
      "2403/2403 [==============================] - 5s 2ms/step - loss: 0.0204 - binary_accuracy: 0.9939 - val_loss: 0.2931 - val_binary_accuracy: 0.9536\n",
      "611/611 [==============================] - 0s 281us/step\n",
      "Fold 2 :\n",
      "\n",
      "Train on 2406 samples, validate on 608 samples\n",
      "Epoch 1/30\n",
      "2406/2406 [==============================] - 6s 3ms/step - loss: 0.1718 - binary_accuracy: 0.9455 - val_loss: 0.1407 - val_binary_accuracy: 0.9527\n",
      "Epoch 2/30\n",
      "2406/2406 [==============================] - 4s 2ms/step - loss: 0.1374 - binary_accuracy: 0.9555 - val_loss: 0.1391 - val_binary_accuracy: 0.9519\n",
      "Epoch 3/30\n",
      "2406/2406 [==============================] - 4s 2ms/step - loss: 0.1196 - binary_accuracy: 0.9613 - val_loss: 0.1379 - val_binary_accuracy: 0.9569\n",
      "Epoch 4/30\n",
      "2406/2406 [==============================] - 4s 2ms/step - loss: 0.1102 - binary_accuracy: 0.9646 - val_loss: 0.1366 - val_binary_accuracy: 0.9575\n",
      "Epoch 5/30\n",
      "2406/2406 [==============================] - 4s 2ms/step - loss: 0.0951 - binary_accuracy: 0.9692 - val_loss: 0.1368 - val_binary_accuracy: 0.9582\n",
      "Epoch 6/30\n",
      "2406/2406 [==============================] - 4s 2ms/step - loss: 0.0859 - binary_accuracy: 0.9730 - val_loss: 0.1406 - val_binary_accuracy: 0.9580\n",
      "Epoch 7/30\n",
      "2406/2406 [==============================] - 4s 2ms/step - loss: 0.0790 - binary_accuracy: 0.9746 - val_loss: 0.1375 - val_binary_accuracy: 0.9599\n",
      "Epoch 8/30\n",
      "2406/2406 [==============================] - 4s 2ms/step - loss: 0.0725 - binary_accuracy: 0.9770 - val_loss: 0.1575 - val_binary_accuracy: 0.9566\n",
      "Epoch 9/30\n",
      "2406/2406 [==============================] - 4s 2ms/step - loss: 0.0674 - binary_accuracy: 0.9782 - val_loss: 0.1477 - val_binary_accuracy: 0.9583\n",
      "Epoch 10/30\n",
      "2406/2406 [==============================] - 5s 2ms/step - loss: 0.0610 - binary_accuracy: 0.9799 - val_loss: 0.1746 - val_binary_accuracy: 0.9553\n",
      "Epoch 11/30\n",
      "2406/2406 [==============================] - 5s 2ms/step - loss: 0.0571 - binary_accuracy: 0.9821 - val_loss: 0.1978 - val_binary_accuracy: 0.9548\n",
      "Epoch 12/30\n",
      "2406/2406 [==============================] - 4s 2ms/step - loss: 0.0521 - binary_accuracy: 0.9829 - val_loss: 0.1879 - val_binary_accuracy: 0.9591\n",
      "Epoch 13/30\n",
      "2406/2406 [==============================] - 5s 2ms/step - loss: 0.0478 - binary_accuracy: 0.9849 - val_loss: 0.1926 - val_binary_accuracy: 0.9569\n",
      "Epoch 14/30\n",
      "2406/2406 [==============================] - 4s 2ms/step - loss: 0.0443 - binary_accuracy: 0.9862 - val_loss: 0.2217 - val_binary_accuracy: 0.9565\n",
      "Epoch 15/30\n",
      "2406/2406 [==============================] - 4s 2ms/step - loss: 0.0462 - binary_accuracy: 0.9864 - val_loss: 0.2340 - val_binary_accuracy: 0.9555\n",
      "Epoch 16/30\n",
      "2406/2406 [==============================] - 4s 2ms/step - loss: 0.0407 - binary_accuracy: 0.9872 - val_loss: 0.2144 - val_binary_accuracy: 0.9554\n",
      "Epoch 17/30\n",
      "2406/2406 [==============================] - 4s 2ms/step - loss: 0.0409 - binary_accuracy: 0.9869 - val_loss: 0.2034 - val_binary_accuracy: 0.9570\n",
      "Epoch 18/30\n",
      "2406/2406 [==============================] - 4s 2ms/step - loss: 0.0374 - binary_accuracy: 0.9880 - val_loss: 0.2531 - val_binary_accuracy: 0.9556\n",
      "Epoch 19/30\n",
      "2406/2406 [==============================] - 4s 2ms/step - loss: 0.0354 - binary_accuracy: 0.9886 - val_loss: 0.2661 - val_binary_accuracy: 0.9559\n",
      "Epoch 20/30\n",
      "2406/2406 [==============================] - 4s 2ms/step - loss: 0.0365 - binary_accuracy: 0.9886 - val_loss: 0.2510 - val_binary_accuracy: 0.9569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "2406/2406 [==============================] - 4s 2ms/step - loss: 0.0311 - binary_accuracy: 0.9904 - val_loss: 0.2717 - val_binary_accuracy: 0.9558\n",
      "Epoch 22/30\n",
      "2406/2406 [==============================] - 4s 2ms/step - loss: 0.0347 - binary_accuracy: 0.9892 - val_loss: 0.2432 - val_binary_accuracy: 0.9554\n",
      "Epoch 23/30\n",
      "2406/2406 [==============================] - 4s 2ms/step - loss: 0.0361 - binary_accuracy: 0.9890 - val_loss: 0.2525 - val_binary_accuracy: 0.9554\n",
      "Epoch 24/30\n",
      "2406/2406 [==============================] - 4s 2ms/step - loss: 0.0306 - binary_accuracy: 0.9907 - val_loss: 0.2649 - val_binary_accuracy: 0.9561\n",
      "Epoch 25/30\n",
      "2406/2406 [==============================] - 4s 2ms/step - loss: 0.0266 - binary_accuracy: 0.9916 - val_loss: 0.3068 - val_binary_accuracy: 0.9539\n",
      "Epoch 26/30\n",
      "2406/2406 [==============================] - 5s 2ms/step - loss: 0.0266 - binary_accuracy: 0.9912 - val_loss: 0.3062 - val_binary_accuracy: 0.9555\n",
      "Epoch 27/30\n",
      "2406/2406 [==============================] - 4s 2ms/step - loss: 0.0260 - binary_accuracy: 0.9917 - val_loss: 0.3272 - val_binary_accuracy: 0.9547\n",
      "Epoch 28/30\n",
      "2406/2406 [==============================] - 4s 2ms/step - loss: 0.0295 - binary_accuracy: 0.9914 - val_loss: 0.3013 - val_binary_accuracy: 0.9560\n",
      "Epoch 29/30\n",
      "2406/2406 [==============================] - 5s 2ms/step - loss: 0.0252 - binary_accuracy: 0.9918 - val_loss: 0.3425 - val_binary_accuracy: 0.9560\n",
      "Epoch 30/30\n",
      "2406/2406 [==============================] - 4s 2ms/step - loss: 0.0237 - binary_accuracy: 0.9927 - val_loss: 0.3346 - val_binary_accuracy: 0.9556\n",
      "608/608 [==============================] - 0s 244us/step\n",
      "Fold 3 :\n",
      "\n",
      "Train on 2414 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2414/2414 [==============================] - 6s 3ms/step - loss: 0.1712 - binary_accuracy: 0.9461 - val_loss: 0.1593 - val_binary_accuracy: 0.9488\n",
      "Epoch 2/30\n",
      "2414/2414 [==============================] - 4s 2ms/step - loss: 0.1422 - binary_accuracy: 0.9535 - val_loss: 0.1385 - val_binary_accuracy: 0.9543\n",
      "Epoch 3/30\n",
      "2414/2414 [==============================] - 5s 2ms/step - loss: 0.1211 - binary_accuracy: 0.9605 - val_loss: 0.1307 - val_binary_accuracy: 0.9582\n",
      "Epoch 4/30\n",
      "2414/2414 [==============================] - 5s 2ms/step - loss: 0.1070 - binary_accuracy: 0.9646 - val_loss: 0.1293 - val_binary_accuracy: 0.9593\n",
      "Epoch 5/30\n",
      "2414/2414 [==============================] - 5s 2ms/step - loss: 0.0973 - binary_accuracy: 0.9691 - val_loss: 0.1398 - val_binary_accuracy: 0.9588\n",
      "Epoch 6/30\n",
      "2414/2414 [==============================] - 5s 2ms/step - loss: 0.0879 - binary_accuracy: 0.9722 - val_loss: 0.1386 - val_binary_accuracy: 0.9604\n",
      "Epoch 7/30\n",
      "2414/2414 [==============================] - 4s 2ms/step - loss: 0.0822 - binary_accuracy: 0.9737 - val_loss: 0.1447 - val_binary_accuracy: 0.9581\n",
      "Epoch 8/30\n",
      "2414/2414 [==============================] - 4s 2ms/step - loss: 0.0740 - binary_accuracy: 0.9758 - val_loss: 0.1706 - val_binary_accuracy: 0.9585\n",
      "Epoch 9/30\n",
      "2414/2414 [==============================] - 4s 2ms/step - loss: 0.0678 - binary_accuracy: 0.9769 - val_loss: 0.1606 - val_binary_accuracy: 0.9584\n",
      "Epoch 10/30\n",
      "2414/2414 [==============================] - 4s 2ms/step - loss: 0.0641 - binary_accuracy: 0.9790 - val_loss: 0.1704 - val_binary_accuracy: 0.9588\n",
      "Epoch 11/30\n",
      "2414/2414 [==============================] - 5s 2ms/step - loss: 0.0595 - binary_accuracy: 0.9810 - val_loss: 0.2020 - val_binary_accuracy: 0.9604\n",
      "Epoch 12/30\n",
      "2414/2414 [==============================] - 4s 2ms/step - loss: 0.0562 - binary_accuracy: 0.9815 - val_loss: 0.1833 - val_binary_accuracy: 0.9569\n",
      "Epoch 13/30\n",
      "2414/2414 [==============================] - 4s 2ms/step - loss: 0.0529 - binary_accuracy: 0.9831 - val_loss: 0.1627 - val_binary_accuracy: 0.9584\n",
      "Epoch 14/30\n",
      "2414/2414 [==============================] - 5s 2ms/step - loss: 0.0528 - binary_accuracy: 0.9834 - val_loss: 0.1948 - val_binary_accuracy: 0.9594l\n",
      "Epoch 15/30\n",
      "2414/2414 [==============================] - 4s 2ms/step - loss: 0.0508 - binary_accuracy: 0.9835 - val_loss: 0.1825 - val_binary_accuracy: 0.9583\n",
      "Epoch 16/30\n",
      "2414/2414 [==============================] - 4s 2ms/step - loss: 0.0424 - binary_accuracy: 0.9864 - val_loss: 0.2225 - val_binary_accuracy: 0.9576\n",
      "Epoch 17/30\n",
      "2414/2414 [==============================] - 4s 2ms/step - loss: 0.0395 - binary_accuracy: 0.9875 - val_loss: 0.2323 - val_binary_accuracy: 0.9574\n",
      "Epoch 18/30\n",
      "2414/2414 [==============================] - 4s 2ms/step - loss: 0.0414 - binary_accuracy: 0.9868 - val_loss: 0.1953 - val_binary_accuracy: 0.9588\n",
      "Epoch 19/30\n",
      "2414/2414 [==============================] - 4s 2ms/step - loss: 0.0399 - binary_accuracy: 0.9877 - val_loss: 0.2291 - val_binary_accuracy: 0.9582\n",
      "Epoch 20/30\n",
      "2414/2414 [==============================] - 5s 2ms/step - loss: 0.0375 - binary_accuracy: 0.9883 - val_loss: 0.2392 - val_binary_accuracy: 0.9600\n",
      "Epoch 21/30\n",
      "2414/2414 [==============================] - 4s 2ms/step - loss: 0.0356 - binary_accuracy: 0.9888 - val_loss: 0.2321 - val_binary_accuracy: 0.9600\n",
      "Epoch 22/30\n",
      "2414/2414 [==============================] - 4s 2ms/step - loss: 0.0346 - binary_accuracy: 0.9898 - val_loss: 0.2263 - val_binary_accuracy: 0.9592\n",
      "Epoch 23/30\n",
      "2414/2414 [==============================] - 4s 2ms/step - loss: 0.0322 - binary_accuracy: 0.9902 - val_loss: 0.2489 - val_binary_accuracy: 0.9589\n",
      "Epoch 24/30\n",
      "2414/2414 [==============================] - 4s 2ms/step - loss: 0.0339 - binary_accuracy: 0.9900 - val_loss: 0.2635 - val_binary_accuracy: 0.9571\n",
      "Epoch 25/30\n",
      "2414/2414 [==============================] - 5s 2ms/step - loss: 0.0330 - binary_accuracy: 0.9902 - val_loss: 0.2387 - val_binary_accuracy: 0.9577\n",
      "Epoch 26/30\n",
      "2414/2414 [==============================] - 4s 2ms/step - loss: 0.0304 - binary_accuracy: 0.9908 - val_loss: 0.2774 - val_binary_accuracy: 0.9569\n",
      "Epoch 27/30\n",
      "2414/2414 [==============================] - 5s 2ms/step - loss: 0.0264 - binary_accuracy: 0.9918 - val_loss: 0.2670 - val_binary_accuracy: 0.9568\n",
      "Epoch 28/30\n",
      "2414/2414 [==============================] - 4s 2ms/step - loss: 0.0346 - binary_accuracy: 0.9897 - val_loss: 0.2765 - val_binary_accuracy: 0.9572\n",
      "Epoch 29/30\n",
      "2414/2414 [==============================] - 4s 2ms/step - loss: 0.0297 - binary_accuracy: 0.9913 - val_loss: 0.2926 - val_binary_accuracy: 0.9576\n",
      "Epoch 30/30\n",
      "2414/2414 [==============================] - 4s 2ms/step - loss: 0.0289 - binary_accuracy: 0.9911 - val_loss: 0.2700 - val_binary_accuracy: 0.9565\n",
      "600/600 [==============================] - 0s 248us/step\n",
      "Fold 4 :\n",
      "\n",
      "Train on 2416 samples, validate on 598 samples\n",
      "Epoch 1/30\n",
      "2416/2416 [==============================] - 6s 3ms/step - loss: 0.1701 - binary_accuracy: 0.9462 - val_loss: 0.1547 - val_binary_accuracy: 0.9482\n",
      "Epoch 2/30\n",
      "2416/2416 [==============================] - 5s 2ms/step - loss: 0.1386 - binary_accuracy: 0.9536 - val_loss: 0.1297 - val_binary_accuracy: 0.9562\n",
      "Epoch 3/30\n",
      "2416/2416 [==============================] - 4s 2ms/step - loss: 0.1200 - binary_accuracy: 0.9607 - val_loss: 0.1344 - val_binary_accuracy: 0.9560\n",
      "Epoch 4/30\n",
      "2416/2416 [==============================] - 5s 2ms/step - loss: 0.1046 - binary_accuracy: 0.9664 - val_loss: 0.1304 - val_binary_accuracy: 0.9587\n",
      "Epoch 5/30\n",
      "2416/2416 [==============================] - 4s 2ms/step - loss: 0.0954 - binary_accuracy: 0.9685 - val_loss: 0.1358 - val_binary_accuracy: 0.9612\n",
      "Epoch 6/30\n",
      "2416/2416 [==============================] - 4s 2ms/step - loss: 0.0878 - binary_accuracy: 0.9723 - val_loss: 0.1400 - val_binary_accuracy: 0.9593\n",
      "Epoch 7/30\n",
      "2416/2416 [==============================] - 5s 2ms/step - loss: 0.0818 - binary_accuracy: 0.9745 - val_loss: 0.1455 - val_binary_accuracy: 0.9587\n",
      "Epoch 8/30\n",
      "2416/2416 [==============================] - 4s 2ms/step - loss: 0.0739 - binary_accuracy: 0.9767 - val_loss: 0.1565 - val_binary_accuracy: 0.9588\n",
      "Epoch 9/30\n",
      "2416/2416 [==============================] - 5s 2ms/step - loss: 0.0703 - binary_accuracy: 0.9777 - val_loss: 0.1638 - val_binary_accuracy: 0.9605\n",
      "Epoch 10/30\n",
      "2416/2416 [==============================] - 4s 2ms/step - loss: 0.0624 - binary_accuracy: 0.9796 - val_loss: 0.1572 - val_binary_accuracy: 0.9600\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2416/2416 [==============================] - 4s 2ms/step - loss: 0.0579 - binary_accuracy: 0.9813 - val_loss: 0.1666 - val_binary_accuracy: 0.9615\n",
      "Epoch 12/30\n",
      "2416/2416 [==============================] - 4s 2ms/step - loss: 0.0557 - binary_accuracy: 0.9824 - val_loss: 0.1927 - val_binary_accuracy: 0.9621\n",
      "Epoch 13/30\n",
      "2416/2416 [==============================] - 4s 2ms/step - loss: 0.0487 - binary_accuracy: 0.9840 - val_loss: 0.2058 - val_binary_accuracy: 0.9595\n",
      "Epoch 14/30\n",
      "2416/2416 [==============================] - 4s 2ms/step - loss: 0.0475 - binary_accuracy: 0.9847 - val_loss: 0.2114 - val_binary_accuracy: 0.9588\n",
      "Epoch 15/30\n",
      "2416/2416 [==============================] - 4s 2ms/step - loss: 0.0430 - binary_accuracy: 0.9865 - val_loss: 0.2385 - val_binary_accuracy: 0.9574\n",
      "Epoch 16/30\n",
      "2416/2416 [==============================] - 4s 2ms/step - loss: 0.0388 - binary_accuracy: 0.9873 - val_loss: 0.2454 - val_binary_accuracy: 0.9600\n",
      "Epoch 17/30\n",
      "2416/2416 [==============================] - 4s 2ms/step - loss: 0.0393 - binary_accuracy: 0.9873 - val_loss: 0.2262 - val_binary_accuracy: 0.9618\n",
      "Epoch 18/30\n",
      "2416/2416 [==============================] - 5s 2ms/step - loss: 0.0357 - binary_accuracy: 0.9884 - val_loss: 0.2435 - val_binary_accuracy: 0.9584\n",
      "Epoch 19/30\n",
      "2416/2416 [==============================] - 4s 2ms/step - loss: 0.0374 - binary_accuracy: 0.9880 - val_loss: 0.2263 - val_binary_accuracy: 0.9595\n",
      "Epoch 20/30\n",
      "2416/2416 [==============================] - 5s 2ms/step - loss: 0.0375 - binary_accuracy: 0.9885 - val_loss: 0.2275 - val_binary_accuracy: 0.9610\n",
      "Epoch 21/30\n",
      "2416/2416 [==============================] - 4s 2ms/step - loss: 0.0309 - binary_accuracy: 0.9902 - val_loss: 0.2679 - val_binary_accuracy: 0.9577\n",
      "Epoch 22/30\n",
      "2416/2416 [==============================] - 4s 2ms/step - loss: 0.0337 - binary_accuracy: 0.9896 - val_loss: 0.2582 - val_binary_accuracy: 0.9594\n",
      "Epoch 23/30\n",
      "2416/2416 [==============================] - 5s 2ms/step - loss: 0.0311 - binary_accuracy: 0.9902 - val_loss: 0.2412 - val_binary_accuracy: 0.9600\n",
      "Epoch 24/30\n",
      "2416/2416 [==============================] - 4s 2ms/step - loss: 0.0272 - binary_accuracy: 0.9912 - val_loss: 0.2853 - val_binary_accuracy: 0.9609\n",
      "Epoch 25/30\n",
      "2416/2416 [==============================] - 5s 2ms/step - loss: 0.0271 - binary_accuracy: 0.9917 - val_loss: 0.2680 - val_binary_accuracy: 0.9598\n",
      "Epoch 26/30\n",
      "2416/2416 [==============================] - 4s 2ms/step - loss: 0.0310 - binary_accuracy: 0.9903 - val_loss: 0.2425 - val_binary_accuracy: 0.9594\n",
      "Epoch 27/30\n",
      "2416/2416 [==============================] - 4s 2ms/step - loss: 0.0290 - binary_accuracy: 0.9905 - val_loss: 0.3092 - val_binary_accuracy: 0.9587\n",
      "Epoch 28/30\n",
      "2416/2416 [==============================] - 4s 2ms/step - loss: 0.0262 - binary_accuracy: 0.9913 - val_loss: 0.2756 - val_binary_accuracy: 0.9581\n",
      "Epoch 29/30\n",
      "2416/2416 [==============================] - 5s 2ms/step - loss: 0.0269 - binary_accuracy: 0.9915 - val_loss: 0.2739 - val_binary_accuracy: 0.9594\n",
      "Epoch 30/30\n",
      "2416/2416 [==============================] - 5s 2ms/step - loss: 0.0248 - binary_accuracy: 0.9915 - val_loss: 0.2958 - val_binary_accuracy: 0.9596\n",
      "598/598 [==============================] - 0s 240us/step\n",
      "Fold 5 :\n",
      "\n",
      "Train on 2417 samples, validate on 597 samples\n",
      "Epoch 1/30\n",
      "2417/2417 [==============================] - 6s 3ms/step - loss: 0.1699 - binary_accuracy: 0.9452 - val_loss: 0.1553 - val_binary_accuracy: 0.9482\n",
      "Epoch 2/30\n",
      "2417/2417 [==============================] - 5s 2ms/step - loss: 0.1383 - binary_accuracy: 0.9547 - val_loss: 0.1314 - val_binary_accuracy: 0.9573\n",
      "Epoch 3/30\n",
      "2417/2417 [==============================] - 4s 2ms/step - loss: 0.1192 - binary_accuracy: 0.9610 - val_loss: 0.1174 - val_binary_accuracy: 0.9618\n",
      "Epoch 4/30\n",
      "2417/2417 [==============================] - 5s 2ms/step - loss: 0.1058 - binary_accuracy: 0.9661 - val_loss: 0.1229 - val_binary_accuracy: 0.9612\n",
      "Epoch 5/30\n",
      "2417/2417 [==============================] - 5s 2ms/step - loss: 0.0961 - binary_accuracy: 0.9685 - val_loss: 0.1319 - val_binary_accuracy: 0.9596\n",
      "Epoch 6/30\n",
      "2417/2417 [==============================] - 4s 2ms/step - loss: 0.0883 - binary_accuracy: 0.9716 - val_loss: 0.1310 - val_binary_accuracy: 0.9620\n",
      "Epoch 7/30\n",
      "2417/2417 [==============================] - 4s 2ms/step - loss: 0.0820 - binary_accuracy: 0.9731 - val_loss: 0.1350 - val_binary_accuracy: 0.9618\n",
      "Epoch 8/30\n",
      "2417/2417 [==============================] - 5s 2ms/step - loss: 0.0769 - binary_accuracy: 0.9741 - val_loss: 0.1414 - val_binary_accuracy: 0.9627\n",
      "Epoch 9/30\n",
      "2417/2417 [==============================] - 5s 2ms/step - loss: 0.0680 - binary_accuracy: 0.9781 - val_loss: 0.1490 - val_binary_accuracy: 0.9625\n",
      "Epoch 10/30\n",
      "2417/2417 [==============================] - 5s 2ms/step - loss: 0.0623 - binary_accuracy: 0.9801 - val_loss: 0.1760 - val_binary_accuracy: 0.9602\n",
      "Epoch 11/30\n",
      "2417/2417 [==============================] - 5s 2ms/step - loss: 0.0583 - binary_accuracy: 0.9807 - val_loss: 0.1599 - val_binary_accuracy: 0.9630\n",
      "Epoch 12/30\n",
      "2417/2417 [==============================] - 5s 2ms/step - loss: 0.0514 - binary_accuracy: 0.9830 - val_loss: 0.1737 - val_binary_accuracy: 0.9598\n",
      "Epoch 13/30\n",
      "2417/2417 [==============================] - 4s 2ms/step - loss: 0.0480 - binary_accuracy: 0.9847 - val_loss: 0.1798 - val_binary_accuracy: 0.9602\n",
      "Epoch 14/30\n",
      "2417/2417 [==============================] - 5s 2ms/step - loss: 0.0454 - binary_accuracy: 0.9853 - val_loss: 0.1917 - val_binary_accuracy: 0.9578\n",
      "Epoch 15/30\n",
      "2417/2417 [==============================] - 4s 2ms/step - loss: 0.0436 - binary_accuracy: 0.9855 - val_loss: 0.1994 - val_binary_accuracy: 0.9593\n",
      "Epoch 16/30\n",
      "2417/2417 [==============================] - 5s 2ms/step - loss: 0.0428 - binary_accuracy: 0.9863 - val_loss: 0.2064 - val_binary_accuracy: 0.9597\n",
      "Epoch 17/30\n",
      "2417/2417 [==============================] - 5s 2ms/step - loss: 0.0413 - binary_accuracy: 0.9870 - val_loss: 0.2178 - val_binary_accuracy: 0.9595\n",
      "Epoch 18/30\n",
      "2417/2417 [==============================] - 4s 2ms/step - loss: 0.0388 - binary_accuracy: 0.9878 - val_loss: 0.2375 - val_binary_accuracy: 0.9561: \n",
      "Epoch 19/30\n",
      "2417/2417 [==============================] - 5s 2ms/step - loss: 0.0384 - binary_accuracy: 0.9878 - val_loss: 0.2113 - val_binary_accuracy: 0.9579\n",
      "Epoch 20/30\n",
      "2417/2417 [==============================] - 5s 2ms/step - loss: 0.0365 - binary_accuracy: 0.9885 - val_loss: 0.2167 - val_binary_accuracy: 0.9612\n",
      "Epoch 21/30\n",
      "2417/2417 [==============================] - 4s 2ms/step - loss: 0.0369 - binary_accuracy: 0.9886 - val_loss: 0.2397 - val_binary_accuracy: 0.9569\n",
      "Epoch 22/30\n",
      "2417/2417 [==============================] - 4s 2ms/step - loss: 0.0327 - binary_accuracy: 0.9896 - val_loss: 0.2545 - val_binary_accuracy: 0.9580\n",
      "Epoch 23/30\n",
      "2417/2417 [==============================] - 5s 2ms/step - loss: 0.0262 - binary_accuracy: 0.9908 - val_loss: 0.2768 - val_binary_accuracy: 0.9576\n",
      "Epoch 24/30\n",
      "2417/2417 [==============================] - 4s 2ms/step - loss: 0.0304 - binary_accuracy: 0.9904 - val_loss: 0.2653 - val_binary_accuracy: 0.9575\n",
      "Epoch 25/30\n",
      "2417/2417 [==============================] - 4s 2ms/step - loss: 0.0300 - binary_accuracy: 0.9909 - val_loss: 0.2602 - val_binary_accuracy: 0.9570\n",
      "Epoch 26/30\n",
      "2417/2417 [==============================] - 4s 2ms/step - loss: 0.0269 - binary_accuracy: 0.9912 - val_loss: 0.2594 - val_binary_accuracy: 0.9598\n",
      "Epoch 27/30\n",
      "2417/2417 [==============================] - 4s 2ms/step - loss: 0.0274 - binary_accuracy: 0.9909 - val_loss: 0.2408 - val_binary_accuracy: 0.9597\n",
      "Epoch 28/30\n",
      "2417/2417 [==============================] - 4s 2ms/step - loss: 0.0279 - binary_accuracy: 0.9912 - val_loss: 0.2787 - val_binary_accuracy: 0.9570\n",
      "Epoch 29/30\n",
      "2417/2417 [==============================] - 4s 2ms/step - loss: 0.0305 - binary_accuracy: 0.9902 - val_loss: 0.2333 - val_binary_accuracy: 0.9587\n",
      "Epoch 30/30\n",
      "2417/2417 [==============================] - 4s 2ms/step - loss: 0.0239 - binary_accuracy: 0.9923 - val_loss: 0.2642 - val_binary_accuracy: 0.9606\n",
      "597/597 [==============================] - 0s 241us/step\n"
     ]
    }
   ],
   "source": [
    "#k=5, fungsi aktivasi=ReLU, nilai dropout=0.4\n",
    "kf = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "val_loss_cv = []\n",
    "val_acc_cv = []\n",
    "j = 0\n",
    "for train_index, test_index in kf.split(X,z):\n",
    "    j+=1\n",
    "    print(f\"Fold {j} :\")\n",
    "    print(\"\")\n",
    "    X_train,X_test = X.iloc[train_index,:],X.iloc[test_index,:]\n",
    "    y_train,y_test = y.iloc[train_index,:],y.iloc[test_index,:]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim=X_train.shape[1], units=463,\n",
    "                     kernel_initializer='normal', bias_initializer='zeros'))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    for i in range(0, 6):\n",
    "        model.add(Dense(units=463, kernel_initializer='normal',\n",
    "                         bias_initializer='zeros'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(.4))\n",
    "\n",
    "    model.add(Dense(units=18))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
    "    model.fit(X_train, y_train,batch_size=24,epochs=30,verbose=1,validation_data=(X_test, y_test))\n",
    "    score = model.evaluate(X_test, y_test, verbose=1)\n",
    "    val_loss_cv.append(score[0])\n",
    "    val_acc_cv.append(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss_cv : [0.29312483705397324, 0.334647356679565, 0.2700427395105362, 0.2958250970744768, 0.2642489616795001]\n",
      "mean_val_loss_cv : 0.2915777983996103\n",
      "val_acc_cv : [0.9536279185313835, 0.9555920989889848, 0.9564814750353495, 0.9595875032370704, 0.9606365096229604]\n",
      "mean_val_acc_cv : 0.9571851010831498\n"
     ]
    }
   ],
   "source": [
    "print(f\"val_loss_cv : {val_loss_cv}\")\n",
    "print(f\"mean_val_loss_cv : {np.mean(val_loss_cv)}\")\n",
    "print(f\"val_acc_cv : {val_acc_cv}\")\n",
    "print(f\"mean_val_acc_cv : {np.mean(val_acc_cv)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=6.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 :\n",
      "\n",
      "Train on 2504 samples, validate on 510 samples\n",
      "Epoch 1/30\n",
      "2504/2504 [==============================] - 7s 3ms/step - loss: 0.1697 - binary_accuracy: 0.9457 - val_loss: 0.1455 - val_binary_accuracy: 0.9532\n",
      "Epoch 2/30\n",
      "2504/2504 [==============================] - 5s 2ms/step - loss: 0.1369 - binary_accuracy: 0.9553 - val_loss: 0.1368 - val_binary_accuracy: 0.9551\n",
      "Epoch 3/30\n",
      "2504/2504 [==============================] - 5s 2ms/step - loss: 0.1149 - binary_accuracy: 0.9626 - val_loss: 0.1422 - val_binary_accuracy: 0.9549\n",
      "Epoch 4/30\n",
      "2504/2504 [==============================] - 5s 2ms/step - loss: 0.1028 - binary_accuracy: 0.9678 - val_loss: 0.1428 - val_binary_accuracy: 0.9556\n",
      "Epoch 5/30\n",
      "2504/2504 [==============================] - 5s 2ms/step - loss: 0.0900 - binary_accuracy: 0.9712 - val_loss: 0.1538 - val_binary_accuracy: 0.9546\n",
      "Epoch 6/30\n",
      "2504/2504 [==============================] - 5s 2ms/step - loss: 0.0816 - binary_accuracy: 0.9742 - val_loss: 0.1479 - val_binary_accuracy: 0.9560\n",
      "Epoch 7/30\n",
      "2504/2504 [==============================] - 5s 2ms/step - loss: 0.0749 - binary_accuracy: 0.9764 - val_loss: 0.1539 - val_binary_accuracy: 0.9573\n",
      "Epoch 8/30\n",
      "2504/2504 [==============================] - 5s 2ms/step - loss: 0.0632 - binary_accuracy: 0.9793 - val_loss: 0.1643 - val_binary_accuracy: 0.9532\n",
      "Epoch 9/30\n",
      "2504/2504 [==============================] - 5s 2ms/step - loss: 0.0585 - binary_accuracy: 0.9809 - val_loss: 0.2013 - val_binary_accuracy: 0.9515\n",
      "Epoch 10/30\n",
      "2504/2504 [==============================] - 5s 2ms/step - loss: 0.0534 - binary_accuracy: 0.9825 - val_loss: 0.2161 - val_binary_accuracy: 0.9537\n",
      "Epoch 11/30\n",
      "2504/2504 [==============================] - 5s 2ms/step - loss: 0.0514 - binary_accuracy: 0.9840 - val_loss: 0.1922 - val_binary_accuracy: 0.9547\n",
      "Epoch 12/30\n",
      "2504/2504 [==============================] - 5s 2ms/step - loss: 0.0483 - binary_accuracy: 0.9850 - val_loss: 0.2219 - val_binary_accuracy: 0.9535\n",
      "Epoch 13/30\n",
      "2504/2504 [==============================] - 5s 2ms/step - loss: 0.0458 - binary_accuracy: 0.9851 - val_loss: 0.2240 - val_binary_accuracy: 0.9535\n",
      "Epoch 14/30\n",
      "2504/2504 [==============================] - 5s 2ms/step - loss: 0.0438 - binary_accuracy: 0.9868 - val_loss: 0.1830 - val_binary_accuracy: 0.9534\n",
      "Epoch 15/30\n",
      "2504/2504 [==============================] - 5s 2ms/step - loss: 0.0417 - binary_accuracy: 0.9870 - val_loss: 0.2175 - val_binary_accuracy: 0.9527\n",
      "Epoch 16/30\n",
      "2504/2504 [==============================] - 5s 2ms/step - loss: 0.0361 - binary_accuracy: 0.9887 - val_loss: 0.2589 - val_binary_accuracy: 0.9529\n",
      "Epoch 17/30\n",
      "2504/2504 [==============================] - 5s 2ms/step - loss: 0.0355 - binary_accuracy: 0.9892 - val_loss: 0.2328 - val_binary_accuracy: 0.9549\n",
      "Epoch 18/30\n",
      "2504/2504 [==============================] - 5s 2ms/step - loss: 0.0364 - binary_accuracy: 0.9896 - val_loss: 0.2404 - val_binary_accuracy: 0.9535\n",
      "Epoch 19/30\n",
      "2504/2504 [==============================] - 5s 2ms/step - loss: 0.0302 - binary_accuracy: 0.9907 - val_loss: 0.2458 - val_binary_accuracy: 0.9532\n",
      "Epoch 20/30\n",
      "2504/2504 [==============================] - 5s 2ms/step - loss: 0.0317 - binary_accuracy: 0.9904 - val_loss: 0.2720 - val_binary_accuracy: 0.9529\n",
      "Epoch 21/30\n",
      "2504/2504 [==============================] - 5s 2ms/step - loss: 0.0270 - binary_accuracy: 0.9913 - val_loss: 0.2622 - val_binary_accuracy: 0.9547\n",
      "Epoch 22/30\n",
      "2504/2504 [==============================] - 5s 2ms/step - loss: 0.0270 - binary_accuracy: 0.9914 - val_loss: 0.3042 - val_binary_accuracy: 0.9509\n",
      "Epoch 23/30\n",
      "2504/2504 [==============================] - 5s 2ms/step - loss: 0.0271 - binary_accuracy: 0.9917 - val_loss: 0.3258 - val_binary_accuracy: 0.9498\n",
      "Epoch 24/30\n",
      "2504/2504 [==============================] - 5s 2ms/step - loss: 0.0281 - binary_accuracy: 0.9911 - val_loss: 0.2745 - val_binary_accuracy: 0.9516\n",
      "Epoch 25/30\n",
      "2504/2504 [==============================] - 5s 2ms/step - loss: 0.0291 - binary_accuracy: 0.9909 - val_loss: 0.3268 - val_binary_accuracy: 0.9510\n",
      "Epoch 26/30\n",
      "2504/2504 [==============================] - 5s 2ms/step - loss: 0.0287 - binary_accuracy: 0.9914 - val_loss: 0.2788 - val_binary_accuracy: 0.9524\n",
      "Epoch 27/30\n",
      "2504/2504 [==============================] - 5s 2ms/step - loss: 0.0234 - binary_accuracy: 0.9927 - val_loss: 0.3436 - val_binary_accuracy: 0.9504\n",
      "Epoch 28/30\n",
      "2504/2504 [==============================] - 5s 2ms/step - loss: 0.0245 - binary_accuracy: 0.9928 - val_loss: 0.3072 - val_binary_accuracy: 0.9526\n",
      "Epoch 29/30\n",
      "2504/2504 [==============================] - 5s 2ms/step - loss: 0.0207 - binary_accuracy: 0.9933 - val_loss: 0.3389 - val_binary_accuracy: 0.9517\n",
      "Epoch 30/30\n",
      "2504/2504 [==============================] - 5s 2ms/step - loss: 0.0258 - binary_accuracy: 0.9926 - val_loss: 0.3176 - val_binary_accuracy: 0.9521\n",
      "510/510 [==============================] - 0s 279us/step\n",
      "Fold 2 :\n",
      "\n",
      "Train on 2508 samples, validate on 506 samples\n",
      "Epoch 1/30\n",
      "2508/2508 [==============================] - 7s 3ms/step - loss: 0.1685 - binary_accuracy: 0.9458 - val_loss: 0.1504 - val_binary_accuracy: 0.9515\n",
      "Epoch 2/30\n",
      "2508/2508 [==============================] - 5s 2ms/step - loss: 0.1369 - binary_accuracy: 0.9546 - val_loss: 0.1413 - val_binary_accuracy: 0.9528\n",
      "Epoch 3/30\n",
      "2508/2508 [==============================] - 5s 2ms/step - loss: 0.1156 - binary_accuracy: 0.9623 - val_loss: 0.1434 - val_binary_accuracy: 0.9534\n",
      "Epoch 4/30\n",
      "2508/2508 [==============================] - 5s 2ms/step - loss: 0.1055 - binary_accuracy: 0.9658 - val_loss: 0.1378 - val_binary_accuracy: 0.9549\n",
      "Epoch 5/30\n",
      "2508/2508 [==============================] - 5s 2ms/step - loss: 0.0949 - binary_accuracy: 0.9698 - val_loss: 0.1461 - val_binary_accuracy: 0.9598\n",
      "Epoch 6/30\n",
      "2508/2508 [==============================] - 5s 2ms/step - loss: 0.0885 - binary_accuracy: 0.9722 - val_loss: 0.1489 - val_binary_accuracy: 0.9558\n",
      "Epoch 7/30\n",
      "2508/2508 [==============================] - 5s 2ms/step - loss: 0.0770 - binary_accuracy: 0.9751 - val_loss: 0.1565 - val_binary_accuracy: 0.9571\n",
      "Epoch 8/30\n",
      "2508/2508 [==============================] - 5s 2ms/step - loss: 0.0720 - binary_accuracy: 0.9770 - val_loss: 0.1558 - val_binary_accuracy: 0.9561\n",
      "Epoch 9/30\n",
      "2508/2508 [==============================] - 5s 2ms/step - loss: 0.0630 - binary_accuracy: 0.9801 - val_loss: 0.1779 - val_binary_accuracy: 0.9562\n",
      "Epoch 10/30\n",
      "2508/2508 [==============================] - 5s 2ms/step - loss: 0.0609 - binary_accuracy: 0.9811 - val_loss: 0.1580 - val_binary_accuracy: 0.9586\n",
      "Epoch 11/30\n",
      "2508/2508 [==============================] - 5s 2ms/step - loss: 0.0539 - binary_accuracy: 0.9831 - val_loss: 0.1766 - val_binary_accuracy: 0.9577\n",
      "Epoch 12/30\n",
      "2508/2508 [==============================] - 5s 2ms/step - loss: 0.0519 - binary_accuracy: 0.9842 - val_loss: 0.1937 - val_binary_accuracy: 0.9562\n",
      "Epoch 13/30\n",
      "2508/2508 [==============================] - 5s 2ms/step - loss: 0.0454 - binary_accuracy: 0.9853 - val_loss: 0.1957 - val_binary_accuracy: 0.9552\n",
      "Epoch 14/30\n",
      "2508/2508 [==============================] - 5s 2ms/step - loss: 0.0427 - binary_accuracy: 0.9863 - val_loss: 0.1983 - val_binary_accuracy: 0.9587\n",
      "Epoch 15/30\n",
      "2508/2508 [==============================] - 5s 2ms/step - loss: 0.0405 - binary_accuracy: 0.9876 - val_loss: 0.2333 - val_binary_accuracy: 0.9553\n",
      "Epoch 16/30\n",
      "2508/2508 [==============================] - 5s 2ms/step - loss: 0.0370 - binary_accuracy: 0.9892 - val_loss: 0.2184 - val_binary_accuracy: 0.9539\n",
      "Epoch 17/30\n",
      "2508/2508 [==============================] - 5s 2ms/step - loss: 0.0359 - binary_accuracy: 0.9890 - val_loss: 0.2190 - val_binary_accuracy: 0.9565\n",
      "Epoch 18/30\n",
      "2508/2508 [==============================] - 5s 2ms/step - loss: 0.0341 - binary_accuracy: 0.9895 - val_loss: 0.2665 - val_binary_accuracy: 0.9563\n",
      "Epoch 19/30\n",
      "2508/2508 [==============================] - 5s 2ms/step - loss: 0.0359 - binary_accuracy: 0.9892 - val_loss: 0.2832 - val_binary_accuracy: 0.9545\n",
      "Epoch 20/30\n",
      "2508/2508 [==============================] - 5s 2ms/step - loss: 0.0346 - binary_accuracy: 0.9900 - val_loss: 0.2319 - val_binary_accuracy: 0.9554\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2508/2508 [==============================] - 4s 2ms/step - loss: 0.0288 - binary_accuracy: 0.9913 - val_loss: 0.2556 - val_binary_accuracy: 0.9548\n",
      "Epoch 22/30\n",
      "2508/2508 [==============================] - 4s 2ms/step - loss: 0.0316 - binary_accuracy: 0.9905 - val_loss: 0.2407 - val_binary_accuracy: 0.9562\n",
      "Epoch 23/30\n",
      "2508/2508 [==============================] - 4s 2ms/step - loss: 0.0303 - binary_accuracy: 0.9909 - val_loss: 0.2707 - val_binary_accuracy: 0.9537\n",
      "Epoch 24/30\n",
      "2508/2508 [==============================] - 4s 2ms/step - loss: 0.0286 - binary_accuracy: 0.9914 - val_loss: 0.2681 - val_binary_accuracy: 0.9562\n",
      "Epoch 25/30\n",
      "2508/2508 [==============================] - 4s 2ms/step - loss: 0.0268 - binary_accuracy: 0.9916 - val_loss: 0.2606 - val_binary_accuracy: 0.9554\n",
      "Epoch 26/30\n",
      "2508/2508 [==============================] - 5s 2ms/step - loss: 0.0268 - binary_accuracy: 0.9918 - val_loss: 0.2858 - val_binary_accuracy: 0.9533\n",
      "Epoch 27/30\n",
      "2508/2508 [==============================] - 4s 2ms/step - loss: 0.0281 - binary_accuracy: 0.9917 - val_loss: 0.2828 - val_binary_accuracy: 0.9567\n",
      "Epoch 28/30\n",
      "2508/2508 [==============================] - 5s 2ms/step - loss: 0.0219 - binary_accuracy: 0.9933 - val_loss: 0.3122 - val_binary_accuracy: 0.9567\n",
      "Epoch 29/30\n",
      "2508/2508 [==============================] - 4s 2ms/step - loss: 0.0246 - binary_accuracy: 0.9930 - val_loss: 0.2876 - val_binary_accuracy: 0.9565\n",
      "Epoch 30/30\n",
      "2508/2508 [==============================] - 4s 2ms/step - loss: 0.0227 - binary_accuracy: 0.9932 - val_loss: 0.3048 - val_binary_accuracy: 0.9537\n",
      "506/506 [==============================] - 0s 253us/step\n",
      "Fold 3 :\n",
      "\n",
      "Train on 2511 samples, validate on 503 samples\n",
      "Epoch 1/30\n",
      "2511/2511 [==============================] - 6s 3ms/step - loss: 0.1689 - binary_accuracy: 0.9461 - val_loss: 0.1409 - val_binary_accuracy: 0.9532\n",
      "Epoch 2/30\n",
      "2511/2511 [==============================] - 4s 2ms/step - loss: 0.1392 - binary_accuracy: 0.9533 - val_loss: 0.1345 - val_binary_accuracy: 0.9518\n",
      "Epoch 3/30\n",
      "2511/2511 [==============================] - 4s 2ms/step - loss: 0.1187 - binary_accuracy: 0.9605 - val_loss: 0.1197 - val_binary_accuracy: 0.9601\n",
      "Epoch 4/30\n",
      "2511/2511 [==============================] - 4s 2ms/step - loss: 0.1072 - binary_accuracy: 0.9648 - val_loss: 0.1266 - val_binary_accuracy: 0.9612\n",
      "Epoch 5/30\n",
      "2511/2511 [==============================] - 4s 2ms/step - loss: 0.0952 - binary_accuracy: 0.9694 - val_loss: 0.1297 - val_binary_accuracy: 0.9603\n",
      "Epoch 6/30\n",
      "2511/2511 [==============================] - 5s 2ms/step - loss: 0.0862 - binary_accuracy: 0.9725 - val_loss: 0.1395 - val_binary_accuracy: 0.9616\n",
      "Epoch 7/30\n",
      "2511/2511 [==============================] - 4s 2ms/step - loss: 0.0808 - binary_accuracy: 0.9746 - val_loss: 0.1370 - val_binary_accuracy: 0.9623\n",
      "Epoch 8/30\n",
      "2511/2511 [==============================] - 5s 2ms/step - loss: 0.0725 - binary_accuracy: 0.9768 - val_loss: 0.1533 - val_binary_accuracy: 0.9608\n",
      "Epoch 9/30\n",
      "2511/2511 [==============================] - 5s 2ms/step - loss: 0.0672 - binary_accuracy: 0.9786 - val_loss: 0.1658 - val_binary_accuracy: 0.9619\n",
      "Epoch 10/30\n",
      "2511/2511 [==============================] - 5s 2ms/step - loss: 0.0648 - binary_accuracy: 0.9794 - val_loss: 0.1631 - val_binary_accuracy: 0.9595\n",
      "Epoch 11/30\n",
      "2511/2511 [==============================] - 5s 2ms/step - loss: 0.0563 - binary_accuracy: 0.9817 - val_loss: 0.1743 - val_binary_accuracy: 0.9612\n",
      "Epoch 12/30\n",
      "2511/2511 [==============================] - 5s 2ms/step - loss: 0.0520 - binary_accuracy: 0.9832 - val_loss: 0.1921 - val_binary_accuracy: 0.9606\n",
      "Epoch 13/30\n",
      "2511/2511 [==============================] - 5s 2ms/step - loss: 0.0518 - binary_accuracy: 0.9839 - val_loss: 0.1776 - val_binary_accuracy: 0.9620\n",
      "Epoch 14/30\n",
      "2511/2511 [==============================] - 5s 2ms/step - loss: 0.0471 - binary_accuracy: 0.9848 - val_loss: 0.1864 - val_binary_accuracy: 0.9638\n",
      "Epoch 15/30\n",
      "2511/2511 [==============================] - 5s 2ms/step - loss: 0.0444 - binary_accuracy: 0.9859 - val_loss: 0.2033 - val_binary_accuracy: 0.9611\n",
      "Epoch 16/30\n",
      "2511/2511 [==============================] - 5s 2ms/step - loss: 0.0440 - binary_accuracy: 0.9866 - val_loss: 0.1933 - val_binary_accuracy: 0.9620\n",
      "Epoch 17/30\n",
      "2511/2511 [==============================] - 5s 2ms/step - loss: 0.0407 - binary_accuracy: 0.9876 - val_loss: 0.2142 - val_binary_accuracy: 0.9617\n",
      "Epoch 18/30\n",
      "2511/2511 [==============================] - 5s 2ms/step - loss: 0.0397 - binary_accuracy: 0.9876 - val_loss: 0.2073 - val_binary_accuracy: 0.9640\n",
      "Epoch 19/30\n",
      "2511/2511 [==============================] - 5s 2ms/step - loss: 0.0381 - binary_accuracy: 0.9881 - val_loss: 0.2195 - val_binary_accuracy: 0.9628\n",
      "Epoch 20/30\n",
      "2511/2511 [==============================] - 5s 2ms/step - loss: 0.0344 - binary_accuracy: 0.9897 - val_loss: 0.2180 - val_binary_accuracy: 0.9624\n",
      "Epoch 21/30\n",
      "2511/2511 [==============================] - 5s 2ms/step - loss: 0.0329 - binary_accuracy: 0.9895 - val_loss: 0.2222 - val_binary_accuracy: 0.9633\n",
      "Epoch 22/30\n",
      "2511/2511 [==============================] - 5s 2ms/step - loss: 0.0313 - binary_accuracy: 0.9898 - val_loss: 0.2442 - val_binary_accuracy: 0.9629\n",
      "Epoch 23/30\n",
      "2511/2511 [==============================] - 5s 2ms/step - loss: 0.0321 - binary_accuracy: 0.9903 - val_loss: 0.2197 - val_binary_accuracy: 0.9607\n",
      "Epoch 24/30\n",
      "2511/2511 [==============================] - 5s 2ms/step - loss: 0.0286 - binary_accuracy: 0.9908 - val_loss: 0.2132 - val_binary_accuracy: 0.9629\n",
      "Epoch 25/30\n",
      "2511/2511 [==============================] - 5s 2ms/step - loss: 0.0282 - binary_accuracy: 0.9914 - val_loss: 0.2383 - val_binary_accuracy: 0.9649\n",
      "Epoch 26/30\n",
      "2511/2511 [==============================] - 5s 2ms/step - loss: 0.0263 - binary_accuracy: 0.9915 - val_loss: 0.2279 - val_binary_accuracy: 0.9629\n",
      "Epoch 27/30\n",
      "2511/2511 [==============================] - 5s 2ms/step - loss: 0.0288 - binary_accuracy: 0.9915 - val_loss: 0.2276 - val_binary_accuracy: 0.9639\n",
      "Epoch 28/30\n",
      "2511/2511 [==============================] - 5s 2ms/step - loss: 0.0308 - binary_accuracy: 0.9909 - val_loss: 0.2440 - val_binary_accuracy: 0.9619\n",
      "Epoch 29/30\n",
      "2511/2511 [==============================] - 5s 2ms/step - loss: 0.0255 - binary_accuracy: 0.9921 - val_loss: 0.2439 - val_binary_accuracy: 0.9631\n",
      "Epoch 30/30\n",
      "2511/2511 [==============================] - 5s 2ms/step - loss: 0.0258 - binary_accuracy: 0.9923 - val_loss: 0.2440 - val_binary_accuracy: 0.9630\n",
      "503/503 [==============================] - 0s 256us/step\n",
      "Fold 4 :\n",
      "\n",
      "Train on 2514 samples, validate on 500 samples\n",
      "Epoch 1/30\n",
      "2514/2514 [==============================] - 7s 3ms/step - loss: 0.1679 - binary_accuracy: 0.9461 - val_loss: 0.1477 - val_binary_accuracy: 0.9513\n",
      "Epoch 2/30\n",
      "2514/2514 [==============================] - 5s 2ms/step - loss: 0.1341 - binary_accuracy: 0.9554 - val_loss: 0.1393 - val_binary_accuracy: 0.9552\n",
      "Epoch 3/30\n",
      "2514/2514 [==============================] - 5s 2ms/step - loss: 0.1180 - binary_accuracy: 0.9615 - val_loss: 0.1356 - val_binary_accuracy: 0.9570\n",
      "Epoch 4/30\n",
      "2514/2514 [==============================] - 5s 2ms/step - loss: 0.1030 - binary_accuracy: 0.9658 - val_loss: 0.1380 - val_binary_accuracy: 0.9601\n",
      "Epoch 5/30\n",
      "2514/2514 [==============================] - 5s 2ms/step - loss: 0.0915 - binary_accuracy: 0.9702 - val_loss: 0.1426 - val_binary_accuracy: 0.9582\n",
      "Epoch 6/30\n",
      "2514/2514 [==============================] - ETA: 0s - loss: 0.0850 - binary_accuracy: 0.972 - 5s 2ms/step - loss: 0.0852 - binary_accuracy: 0.9723 - val_loss: 0.1447 - val_binary_accuracy: 0.9604\n",
      "Epoch 7/30\n",
      "2514/2514 [==============================] - 5s 2ms/step - loss: 0.0760 - binary_accuracy: 0.9749 - val_loss: 0.1735 - val_binary_accuracy: 0.9610\n",
      "Epoch 8/30\n",
      "2514/2514 [==============================] - 5s 2ms/step - loss: 0.0706 - binary_accuracy: 0.9773 - val_loss: 0.1627 - val_binary_accuracy: 0.9603\n",
      "Epoch 9/30\n",
      "2514/2514 [==============================] - 5s 2ms/step - loss: 0.0629 - binary_accuracy: 0.9792 - val_loss: 0.1578 - val_binary_accuracy: 0.9606\n",
      "Epoch 10/30\n",
      "2514/2514 [==============================] - 5s 2ms/step - loss: 0.0584 - binary_accuracy: 0.9807 - val_loss: 0.1587 - val_binary_accuracy: 0.9597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "2514/2514 [==============================] - 4s 2ms/step - loss: 0.0568 - binary_accuracy: 0.9812 - val_loss: 0.1929 - val_binary_accuracy: 0.9563\n",
      "Epoch 12/30\n",
      "2514/2514 [==============================] - 4s 2ms/step - loss: 0.0543 - binary_accuracy: 0.9827 - val_loss: 0.1628 - val_binary_accuracy: 0.9604\n",
      "Epoch 13/30\n",
      "2514/2514 [==============================] - 5s 2ms/step - loss: 0.0470 - binary_accuracy: 0.9845 - val_loss: 0.1995 - val_binary_accuracy: 0.9604\n",
      "Epoch 14/30\n",
      "2514/2514 [==============================] - 4s 2ms/step - loss: 0.0464 - binary_accuracy: 0.9849 - val_loss: 0.2203 - val_binary_accuracy: 0.9583\n",
      "Epoch 15/30\n",
      "2514/2514 [==============================] - 4s 2ms/step - loss: 0.0433 - binary_accuracy: 0.9865 - val_loss: 0.2212 - val_binary_accuracy: 0.9610\n",
      "Epoch 16/30\n",
      "2514/2514 [==============================] - 4s 2ms/step - loss: 0.0392 - binary_accuracy: 0.9870 - val_loss: 0.2094 - val_binary_accuracy: 0.9603\n",
      "Epoch 17/30\n",
      "2514/2514 [==============================] - 5s 2ms/step - loss: 0.0401 - binary_accuracy: 0.9878 - val_loss: 0.2522 - val_binary_accuracy: 0.9584\n",
      "Epoch 18/30\n",
      "2514/2514 [==============================] - 4s 2ms/step - loss: 0.0425 - binary_accuracy: 0.9875 - val_loss: 0.2049 - val_binary_accuracy: 0.9604\n",
      "Epoch 19/30\n",
      "2514/2514 [==============================] - 5s 2ms/step - loss: 0.0347 - binary_accuracy: 0.9888 - val_loss: 0.2626 - val_binary_accuracy: 0.9588\n",
      "Epoch 20/30\n",
      "2514/2514 [==============================] - 5s 2ms/step - loss: 0.0368 - binary_accuracy: 0.9892 - val_loss: 0.2517 - val_binary_accuracy: 0.9609\n",
      "Epoch 21/30\n",
      "2514/2514 [==============================] - 5s 2ms/step - loss: 0.0322 - binary_accuracy: 0.9903 - val_loss: 0.2559 - val_binary_accuracy: 0.9577\n",
      "Epoch 22/30\n",
      "2514/2514 [==============================] - 5s 2ms/step - loss: 0.0313 - binary_accuracy: 0.9903 - val_loss: 0.2720 - val_binary_accuracy: 0.9571\n",
      "Epoch 23/30\n",
      "2514/2514 [==============================] - 4s 2ms/step - loss: 0.0287 - binary_accuracy: 0.9907 - val_loss: 0.2624 - val_binary_accuracy: 0.9582\n",
      "Epoch 24/30\n",
      "2514/2514 [==============================] - 4s 2ms/step - loss: 0.0314 - binary_accuracy: 0.9910 - val_loss: 0.2527 - val_binary_accuracy: 0.9589\n",
      "Epoch 25/30\n",
      "2514/2514 [==============================] - 5s 2ms/step - loss: 0.0289 - binary_accuracy: 0.9912 - val_loss: 0.2708 - val_binary_accuracy: 0.9594\n",
      "Epoch 26/30\n",
      "2514/2514 [==============================] - 5s 2ms/step - loss: 0.0282 - binary_accuracy: 0.9909 - val_loss: 0.2420 - val_binary_accuracy: 0.9603\n",
      "Epoch 27/30\n",
      "2514/2514 [==============================] - 6s 2ms/step - loss: 0.0283 - binary_accuracy: 0.9911 - val_loss: 0.2749 - val_binary_accuracy: 0.9579\n",
      "Epoch 28/30\n",
      "2514/2514 [==============================] - 5s 2ms/step - loss: 0.0280 - binary_accuracy: 0.9914 - val_loss: 0.2677 - val_binary_accuracy: 0.9564\n",
      "Epoch 29/30\n",
      "2514/2514 [==============================] - 5s 2ms/step - loss: 0.0256 - binary_accuracy: 0.9918 - val_loss: 0.2744 - val_binary_accuracy: 0.9577\n",
      "Epoch 30/30\n",
      "2514/2514 [==============================] - 4s 2ms/step - loss: 0.0230 - binary_accuracy: 0.9927 - val_loss: 0.3152 - val_binary_accuracy: 0.9570\n",
      "500/500 [==============================] - 0s 277us/step\n",
      "Fold 5 :\n",
      "\n",
      "Train on 2516 samples, validate on 498 samples\n",
      "Epoch 1/30\n",
      "2516/2516 [==============================] - 7s 3ms/step - loss: 0.1705 - binary_accuracy: 0.9455 - val_loss: 0.1554 - val_binary_accuracy: 0.9467\n",
      "Epoch 2/30\n",
      "2516/2516 [==============================] - 5s 2ms/step - loss: 0.1388 - binary_accuracy: 0.9528 - val_loss: 0.1293 - val_binary_accuracy: 0.9592\n",
      "Epoch 3/30\n",
      "2516/2516 [==============================] - 5s 2ms/step - loss: 0.1187 - binary_accuracy: 0.9607 - val_loss: 0.1279 - val_binary_accuracy: 0.9598\n",
      "Epoch 4/30\n",
      "2516/2516 [==============================] - 5s 2ms/step - loss: 0.1055 - binary_accuracy: 0.9662 - val_loss: 0.1261 - val_binary_accuracy: 0.9608\n",
      "Epoch 5/30\n",
      "2516/2516 [==============================] - 5s 2ms/step - loss: 0.0934 - binary_accuracy: 0.9700 - val_loss: 0.1294 - val_binary_accuracy: 0.9623\n",
      "Epoch 6/30\n",
      "2516/2516 [==============================] - 5s 2ms/step - loss: 0.0847 - binary_accuracy: 0.9720 - val_loss: 0.1331 - val_binary_accuracy: 0.9608\n",
      "Epoch 7/30\n",
      "2516/2516 [==============================] - 5s 2ms/step - loss: 0.0807 - binary_accuracy: 0.9740 - val_loss: 0.1575 - val_binary_accuracy: 0.9593\n",
      "Epoch 8/30\n",
      "2516/2516 [==============================] - 5s 2ms/step - loss: 0.0729 - binary_accuracy: 0.9760 - val_loss: 0.1621 - val_binary_accuracy: 0.9615\n",
      "Epoch 9/30\n",
      "2516/2516 [==============================] - 5s 2ms/step - loss: 0.0648 - binary_accuracy: 0.9790 - val_loss: 0.1503 - val_binary_accuracy: 0.9608\n",
      "Epoch 10/30\n",
      "2516/2516 [==============================] - 5s 2ms/step - loss: 0.0570 - binary_accuracy: 0.9814 - val_loss: 0.1731 - val_binary_accuracy: 0.9600\n",
      "Epoch 11/30\n",
      "2516/2516 [==============================] - 5s 2ms/step - loss: 0.0557 - binary_accuracy: 0.9822 - val_loss: 0.1854 - val_binary_accuracy: 0.9607\n",
      "Epoch 12/30\n",
      "2516/2516 [==============================] - 5s 2ms/step - loss: 0.0502 - binary_accuracy: 0.9843 - val_loss: 0.1911 - val_binary_accuracy: 0.9585\n",
      "Epoch 13/30\n",
      "2516/2516 [==============================] - 5s 2ms/step - loss: 0.0466 - binary_accuracy: 0.9857 - val_loss: 0.1880 - val_binary_accuracy: 0.9613\n",
      "Epoch 14/30\n",
      "2516/2516 [==============================] - 5s 2ms/step - loss: 0.0453 - binary_accuracy: 0.9861 - val_loss: 0.1772 - val_binary_accuracy: 0.9608\n",
      "Epoch 15/30\n",
      "2516/2516 [==============================] - 5s 2ms/step - loss: 0.0402 - binary_accuracy: 0.9873 - val_loss: 0.1880 - val_binary_accuracy: 0.9591\n",
      "Epoch 16/30\n",
      "2516/2516 [==============================] - 5s 2ms/step - loss: 0.0373 - binary_accuracy: 0.9880 - val_loss: 0.2079 - val_binary_accuracy: 0.9587\n",
      "Epoch 17/30\n",
      "2516/2516 [==============================] - 5s 2ms/step - loss: 0.0362 - binary_accuracy: 0.9883 - val_loss: 0.2100 - val_binary_accuracy: 0.9626\n",
      "Epoch 18/30\n",
      "2516/2516 [==============================] - 5s 2ms/step - loss: 0.0375 - binary_accuracy: 0.9887 - val_loss: 0.2050 - val_binary_accuracy: 0.9625\n",
      "Epoch 19/30\n",
      "2516/2516 [==============================] - 5s 2ms/step - loss: 0.0328 - binary_accuracy: 0.9901 - val_loss: 0.2073 - val_binary_accuracy: 0.9621\n",
      "Epoch 20/30\n",
      "2516/2516 [==============================] - 5s 2ms/step - loss: 0.0317 - binary_accuracy: 0.9905 - val_loss: 0.2379 - val_binary_accuracy: 0.9607\n",
      "Epoch 21/30\n",
      "2516/2516 [==============================] - 5s 2ms/step - loss: 0.0304 - binary_accuracy: 0.9903 - val_loss: 0.2446 - val_binary_accuracy: 0.9581\n",
      "Epoch 22/30\n",
      "2516/2516 [==============================] - 5s 2ms/step - loss: 0.0309 - binary_accuracy: 0.9907 - val_loss: 0.2578 - val_binary_accuracy: 0.9593\n",
      "Epoch 23/30\n",
      "2516/2516 [==============================] - 5s 2ms/step - loss: 0.0270 - binary_accuracy: 0.9915 - val_loss: 0.2546 - val_binary_accuracy: 0.9573\n",
      "Epoch 24/30\n",
      "2516/2516 [==============================] - 5s 2ms/step - loss: 0.0308 - binary_accuracy: 0.9906 - val_loss: 0.2225 - val_binary_accuracy: 0.9602\n",
      "Epoch 25/30\n",
      "2516/2516 [==============================] - 5s 2ms/step - loss: 0.0312 - binary_accuracy: 0.9907 - val_loss: 0.2537 - val_binary_accuracy: 0.9595\n",
      "Epoch 26/30\n",
      "2516/2516 [==============================] - 5s 2ms/step - loss: 0.0351 - binary_accuracy: 0.9897 - val_loss: 0.2168 - val_binary_accuracy: 0.9605\n",
      "Epoch 27/30\n",
      "2516/2516 [==============================] - 5s 2ms/step - loss: 0.0254 - binary_accuracy: 0.9918 - val_loss: 0.2584 - val_binary_accuracy: 0.9594\n",
      "Epoch 28/30\n",
      "2516/2516 [==============================] - 5s 2ms/step - loss: 0.0244 - binary_accuracy: 0.9924 - val_loss: 0.2622 - val_binary_accuracy: 0.9607\n",
      "Epoch 29/30\n",
      "2516/2516 [==============================] - 5s 2ms/step - loss: 0.0247 - binary_accuracy: 0.9921 - val_loss: 0.2453 - val_binary_accuracy: 0.9589\n",
      "Epoch 30/30\n",
      "2516/2516 [==============================] - 5s 2ms/step - loss: 0.0220 - binary_accuracy: 0.9927 - val_loss: 0.2935 - val_binary_accuracy: 0.9595\n",
      "498/498 [==============================] - 0s 266us/step\n",
      "Fold 6 :\n",
      "\n",
      "Train on 2517 samples, validate on 497 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2517/2517 [==============================] - 7s 3ms/step - loss: 0.1701 - binary_accuracy: 0.9460 - val_loss: 0.1477 - val_binary_accuracy: 0.9515\n",
      "Epoch 2/30\n",
      "2517/2517 [==============================] - 5s 2ms/step - loss: 0.1365 - binary_accuracy: 0.9548 - val_loss: 0.1356 - val_binary_accuracy: 0.9569\n",
      "Epoch 3/30\n",
      "2517/2517 [==============================] - 5s 2ms/step - loss: 0.1191 - binary_accuracy: 0.9615 - val_loss: 0.1249 - val_binary_accuracy: 0.9593\n",
      "Epoch 4/30\n",
      "2517/2517 [==============================] - 5s 2ms/step - loss: 0.1024 - binary_accuracy: 0.9672 - val_loss: 0.1264 - val_binary_accuracy: 0.9599\n",
      "Epoch 5/30\n",
      "2517/2517 [==============================] - 5s 2ms/step - loss: 0.0927 - binary_accuracy: 0.9704 - val_loss: 0.1259 - val_binary_accuracy: 0.9623\n",
      "Epoch 6/30\n",
      "2517/2517 [==============================] - 5s 2ms/step - loss: 0.0861 - binary_accuracy: 0.9718 - val_loss: 0.1212 - val_binary_accuracy: 0.9621\n",
      "Epoch 7/30\n",
      "2517/2517 [==============================] - 5s 2ms/step - loss: 0.0773 - binary_accuracy: 0.9746 - val_loss: 0.1341 - val_binary_accuracy: 0.9607\n",
      "Epoch 8/30\n",
      "2517/2517 [==============================] - 5s 2ms/step - loss: 0.0714 - binary_accuracy: 0.9771 - val_loss: 0.1317 - val_binary_accuracy: 0.9617\n",
      "Epoch 9/30\n",
      "2517/2517 [==============================] - 5s 2ms/step - loss: 0.0633 - binary_accuracy: 0.9788 - val_loss: 0.1503 - val_binary_accuracy: 0.9618\n",
      "Epoch 10/30\n",
      "2517/2517 [==============================] - 6s 2ms/step - loss: 0.0578 - binary_accuracy: 0.9810 - val_loss: 0.1488 - val_binary_accuracy: 0.9599\n",
      "Epoch 11/30\n",
      "2517/2517 [==============================] - 5s 2ms/step - loss: 0.0559 - binary_accuracy: 0.9814 - val_loss: 0.1687 - val_binary_accuracy: 0.9611\n",
      "Epoch 12/30\n",
      "2517/2517 [==============================] - 5s 2ms/step - loss: 0.0521 - binary_accuracy: 0.9828 - val_loss: 0.1762 - val_binary_accuracy: 0.9613\n",
      "Epoch 13/30\n",
      "2517/2517 [==============================] - 5s 2ms/step - loss: 0.0457 - binary_accuracy: 0.9847 - val_loss: 0.1939 - val_binary_accuracy: 0.9607\n",
      "Epoch 14/30\n",
      "2517/2517 [==============================] - 5s 2ms/step - loss: 0.0461 - binary_accuracy: 0.9851 - val_loss: 0.1846 - val_binary_accuracy: 0.9586\n",
      "Epoch 15/30\n",
      "2517/2517 [==============================] - 5s 2ms/step - loss: 0.0441 - binary_accuracy: 0.9854 - val_loss: 0.1820 - val_binary_accuracy: 0.9598\n",
      "Epoch 16/30\n",
      "2517/2517 [==============================] - 6s 2ms/step - loss: 0.0391 - binary_accuracy: 0.9875 - val_loss: 0.2039 - val_binary_accuracy: 0.9596\n",
      "Epoch 17/30\n",
      "2517/2517 [==============================] - 6s 2ms/step - loss: 0.0376 - binary_accuracy: 0.9886 - val_loss: 0.2048 - val_binary_accuracy: 0.9577\n",
      "Epoch 18/30\n",
      "2517/2517 [==============================] - 5s 2ms/step - loss: 0.0384 - binary_accuracy: 0.9887 - val_loss: 0.2258 - val_binary_accuracy: 0.9580\n",
      "Epoch 19/30\n",
      "2517/2517 [==============================] - 5s 2ms/step - loss: 0.0333 - binary_accuracy: 0.9897 - val_loss: 0.2049 - val_binary_accuracy: 0.9584uracy: 0.9\n",
      "Epoch 20/30\n",
      "2517/2517 [==============================] - 5s 2ms/step - loss: 0.0308 - binary_accuracy: 0.9895 - val_loss: 0.2219 - val_binary_accuracy: 0.9593\n",
      "Epoch 21/30\n",
      "2517/2517 [==============================] - 5s 2ms/step - loss: 0.0293 - binary_accuracy: 0.9907 - val_loss: 0.2545 - val_binary_accuracy: 0.9583\n",
      "Epoch 22/30\n",
      "2517/2517 [==============================] - 5s 2ms/step - loss: 0.0323 - binary_accuracy: 0.9900 - val_loss: 0.2121 - val_binary_accuracy: 0.9581\n",
      "Epoch 23/30\n",
      "2517/2517 [==============================] - 5s 2ms/step - loss: 0.0276 - binary_accuracy: 0.9912 - val_loss: 0.2307 - val_binary_accuracy: 0.9583\n",
      "Epoch 24/30\n",
      "2517/2517 [==============================] - 5s 2ms/step - loss: 0.0279 - binary_accuracy: 0.9915 - val_loss: 0.2476 - val_binary_accuracy: 0.9588\n",
      "Epoch 25/30\n",
      "2517/2517 [==============================] - 5s 2ms/step - loss: 0.0286 - binary_accuracy: 0.9910 - val_loss: 0.2258 - val_binary_accuracy: 0.9574\n",
      "Epoch 26/30\n",
      "2517/2517 [==============================] - 5s 2ms/step - loss: 0.0228 - binary_accuracy: 0.9924 - val_loss: 0.2614 - val_binary_accuracy: 0.9564\n",
      "Epoch 27/30\n",
      "2517/2517 [==============================] - 5s 2ms/step - loss: 0.0250 - binary_accuracy: 0.9922 - val_loss: 0.2427 - val_binary_accuracy: 0.9554\n",
      "Epoch 28/30\n",
      "2517/2517 [==============================] - 5s 2ms/step - loss: 0.0275 - binary_accuracy: 0.9922 - val_loss: 0.2745 - val_binary_accuracy: 0.9584\n",
      "Epoch 29/30\n",
      "2517/2517 [==============================] - 5s 2ms/step - loss: 0.0282 - binary_accuracy: 0.9916 - val_loss: 0.2555 - val_binary_accuracy: 0.9564\n",
      "Epoch 30/30\n",
      "2517/2517 [==============================] - 5s 2ms/step - loss: 0.0233 - binary_accuracy: 0.9928 - val_loss: 0.2500 - val_binary_accuracy: 0.9589\n",
      "497/497 [==============================] - 0s 273us/step\n"
     ]
    }
   ],
   "source": [
    "#k=6, fungsi aktivasi=ReLU, nilai dropout=0.4\n",
    "kf = StratifiedKFold(n_splits=6, random_state=None, shuffle=False)\n",
    "val_loss_cv = []\n",
    "val_acc_cv = []\n",
    "j = 0\n",
    "for train_index, test_index in kf.split(X,z):\n",
    "    j+=1\n",
    "    print(f\"Fold {j} :\")\n",
    "    print(\"\")\n",
    "    X_train,X_test = X.iloc[train_index,:],X.iloc[test_index,:]\n",
    "    y_train,y_test = y.iloc[train_index,:],y.iloc[test_index,:]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim=X_train.shape[1], units=463,\n",
    "                     kernel_initializer='normal', bias_initializer='zeros'))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    for i in range(0, 6):\n",
    "        model.add(Dense(units=463, kernel_initializer='normal',\n",
    "                         bias_initializer='zeros'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(.4))\n",
    "\n",
    "    model.add(Dense(units=18))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
    "    model.fit(X_train, y_train,batch_size=24,epochs=30,verbose=1,validation_data=(X_test, y_test))\n",
    "    score = model.evaluate(X_test, y_test, verbose=1)\n",
    "    val_loss_cv.append(score[0])\n",
    "    val_acc_cv.append(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss_cv : [0.31764887805078545, 0.3048262638536838, 0.24402108966237746, 0.3152476006499201, 0.2934653869714124, 0.25004038676409657]\n",
      "mean_val_loss_cv : 0.2875416009920459\n",
      "val_acc_cv : [0.952069701166714, 0.9536670990612196, 0.9629997653705226, 0.9569999809265137, 0.9595046823762028, 0.9588642729599951]\n",
      "mean_val_acc_cv : 0.9573509169768614\n"
     ]
    }
   ],
   "source": [
    "print(f\"val_loss_cv : {val_loss_cv}\")\n",
    "print(f\"mean_val_loss_cv : {np.mean(val_loss_cv)}\")\n",
    "print(f\"val_acc_cv : {val_acc_cv}\")\n",
    "print(f\"mean_val_acc_cv : {np.mean(val_acc_cv)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=7.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 :\n",
      "\n",
      "Train on 2576 samples, validate on 438 samples\n",
      "Epoch 1/30\n",
      "2576/2576 [==============================] - 8s 3ms/step - loss: 0.1670 - binary_accuracy: 0.9468 - val_loss: 0.1492 - val_binary_accuracy: 0.9508\n",
      "Epoch 2/30\n",
      "2576/2576 [==============================] - 5s 2ms/step - loss: 0.1353 - binary_accuracy: 0.9553 - val_loss: 0.1395 - val_binary_accuracy: 0.9533\n",
      "Epoch 3/30\n",
      "2576/2576 [==============================] - 5s 2ms/step - loss: 0.1170 - binary_accuracy: 0.9612 - val_loss: 0.1310 - val_binary_accuracy: 0.9571\n",
      "Epoch 4/30\n",
      "2576/2576 [==============================] - 5s 2ms/step - loss: 0.1013 - binary_accuracy: 0.9668 - val_loss: 0.1405 - val_binary_accuracy: 0.9564\n",
      "Epoch 5/30\n",
      "2576/2576 [==============================] - 5s 2ms/step - loss: 0.0907 - binary_accuracy: 0.9706 - val_loss: 0.1402 - val_binary_accuracy: 0.9557\n",
      "Epoch 6/30\n",
      "2576/2576 [==============================] - 5s 2ms/step - loss: 0.0794 - binary_accuracy: 0.9745 - val_loss: 0.1643 - val_binary_accuracy: 0.9565\n",
      "Epoch 7/30\n",
      "2576/2576 [==============================] - 5s 2ms/step - loss: 0.0720 - binary_accuracy: 0.9768 - val_loss: 0.1502 - val_binary_accuracy: 0.9567\n",
      "Epoch 8/30\n",
      "2576/2576 [==============================] - 5s 2ms/step - loss: 0.0667 - binary_accuracy: 0.9785 - val_loss: 0.1597 - val_binary_accuracy: 0.9576\n",
      "Epoch 9/30\n",
      "2576/2576 [==============================] - 5s 2ms/step - loss: 0.0612 - binary_accuracy: 0.9803 - val_loss: 0.1804 - val_binary_accuracy: 0.9559\n",
      "Epoch 10/30\n",
      "2576/2576 [==============================] - ETA: 0s - loss: 0.0555 - binary_accuracy: 0.981 - 5s 2ms/step - loss: 0.0555 - binary_accuracy: 0.9815 - val_loss: 0.1682 - val_binary_accuracy: 0.9557\n",
      "Epoch 11/30\n",
      "2576/2576 [==============================] - 5s 2ms/step - loss: 0.0544 - binary_accuracy: 0.9823 - val_loss: 0.2058 - val_binary_accuracy: 0.9554\n",
      "Epoch 12/30\n",
      "2576/2576 [==============================] - 5s 2ms/step - loss: 0.0534 - binary_accuracy: 0.9828 - val_loss: 0.1955 - val_binary_accuracy: 0.9522\n",
      "Epoch 13/30\n",
      "2576/2576 [==============================] - 5s 2ms/step - loss: 0.0465 - binary_accuracy: 0.9843 - val_loss: 0.2078 - val_binary_accuracy: 0.9546\n",
      "Epoch 14/30\n",
      "2576/2576 [==============================] - 5s 2ms/step - loss: 0.0480 - binary_accuracy: 0.9845 - val_loss: 0.1795 - val_binary_accuracy: 0.9573\n",
      "Epoch 15/30\n",
      "2576/2576 [==============================] - 5s 2ms/step - loss: 0.0418 - binary_accuracy: 0.9866 - val_loss: 0.2089 - val_binary_accuracy: 0.9559\n",
      "Epoch 16/30\n",
      "2576/2576 [==============================] - 5s 2ms/step - loss: 0.0356 - binary_accuracy: 0.9884 - val_loss: 0.2500 - val_binary_accuracy: 0.9518\n",
      "Epoch 17/30\n",
      "2576/2576 [==============================] - 5s 2ms/step - loss: 0.0351 - binary_accuracy: 0.9889 - val_loss: 0.2355 - val_binary_accuracy: 0.9534\n",
      "Epoch 18/30\n",
      "2576/2576 [==============================] - 5s 2ms/step - loss: 0.0378 - binary_accuracy: 0.9880 - val_loss: 0.2340 - val_binary_accuracy: 0.9536\n",
      "Epoch 19/30\n",
      "2576/2576 [==============================] - 5s 2ms/step - loss: 0.0348 - binary_accuracy: 0.9890 - val_loss: 0.2220 - val_binary_accuracy: 0.9565\n",
      "Epoch 20/30\n",
      "2576/2576 [==============================] - 5s 2ms/step - loss: 0.0322 - binary_accuracy: 0.9898 - val_loss: 0.2429 - val_binary_accuracy: 0.9536\n",
      "Epoch 21/30\n",
      "2576/2576 [==============================] - 5s 2ms/step - loss: 0.0309 - binary_accuracy: 0.9905 - val_loss: 0.2480 - val_binary_accuracy: 0.9552\n",
      "Epoch 22/30\n",
      "2576/2576 [==============================] - 5s 2ms/step - loss: 0.0286 - binary_accuracy: 0.9909 - val_loss: 0.2650 - val_binary_accuracy: 0.9556\n",
      "Epoch 23/30\n",
      "2576/2576 [==============================] - 5s 2ms/step - loss: 0.0266 - binary_accuracy: 0.9918 - val_loss: 0.2937 - val_binary_accuracy: 0.9536\n",
      "Epoch 24/30\n",
      "2576/2576 [==============================] - 5s 2ms/step - loss: 0.0265 - binary_accuracy: 0.9914 - val_loss: 0.2887 - val_binary_accuracy: 0.9550\n",
      "Epoch 25/30\n",
      "2576/2576 [==============================] - 5s 2ms/step - loss: 0.0257 - binary_accuracy: 0.9920 - val_loss: 0.2890 - val_binary_accuracy: 0.9531\n",
      "Epoch 26/30\n",
      "2576/2576 [==============================] - 5s 2ms/step - loss: 0.0248 - binary_accuracy: 0.9924 - val_loss: 0.3260 - val_binary_accuracy: 0.9528\n",
      "Epoch 27/30\n",
      "2576/2576 [==============================] - 5s 2ms/step - loss: 0.0247 - binary_accuracy: 0.9925 - val_loss: 0.3007 - val_binary_accuracy: 0.9528\n",
      "Epoch 28/30\n",
      "2576/2576 [==============================] - 5s 2ms/step - loss: 0.0233 - binary_accuracy: 0.9931 - val_loss: 0.3175 - val_binary_accuracy: 0.9527\n",
      "Epoch 29/30\n",
      "2576/2576 [==============================] - 5s 2ms/step - loss: 0.0250 - binary_accuracy: 0.9924 - val_loss: 0.3693 - val_binary_accuracy: 0.9491\n",
      "Epoch 30/30\n",
      "2576/2576 [==============================] - 5s 2ms/step - loss: 0.0265 - binary_accuracy: 0.9921 - val_loss: 0.3427 - val_binary_accuracy: 0.9503\n",
      "438/438 [==============================] - 0s 257us/step\n",
      "Fold 2 :\n",
      "\n",
      "Train on 2578 samples, validate on 436 samples\n",
      "Epoch 1/30\n",
      "2578/2578 [==============================] - 8s 3ms/step - loss: 0.1680 - binary_accuracy: 0.9464 - val_loss: 0.1462 - val_binary_accuracy: 0.9522\n",
      "Epoch 2/30\n",
      "2578/2578 [==============================] - 5s 2ms/step - loss: 0.1348 - binary_accuracy: 0.9560 - val_loss: 0.1342 - val_binary_accuracy: 0.9565\n",
      "Epoch 3/30\n",
      "2578/2578 [==============================] - 5s 2ms/step - loss: 0.1150 - binary_accuracy: 0.9633 - val_loss: 0.1335 - val_binary_accuracy: 0.9554\n",
      "Epoch 4/30\n",
      "2578/2578 [==============================] - 5s 2ms/step - loss: 0.1008 - binary_accuracy: 0.9682 - val_loss: 0.1471 - val_binary_accuracy: 0.9560\n",
      "Epoch 5/30\n",
      "2578/2578 [==============================] - 5s 2ms/step - loss: 0.0897 - binary_accuracy: 0.9711 - val_loss: 0.1518 - val_binary_accuracy: 0.9543\n",
      "Epoch 6/30\n",
      "2578/2578 [==============================] - 5s 2ms/step - loss: 0.0798 - binary_accuracy: 0.9738 - val_loss: 0.1659 - val_binary_accuracy: 0.9534\n",
      "Epoch 7/30\n",
      "2578/2578 [==============================] - 5s 2ms/step - loss: 0.0733 - binary_accuracy: 0.9764 - val_loss: 0.1707 - val_binary_accuracy: 0.9553\n",
      "Epoch 8/30\n",
      "2578/2578 [==============================] - 5s 2ms/step - loss: 0.0662 - binary_accuracy: 0.9787 - val_loss: 0.1945 - val_binary_accuracy: 0.9531\n",
      "Epoch 9/30\n",
      "2578/2578 [==============================] - 5s 2ms/step - loss: 0.0574 - binary_accuracy: 0.9814 - val_loss: 0.2271 - val_binary_accuracy: 0.9475\n",
      "Epoch 10/30\n",
      "2578/2578 [==============================] - 5s 2ms/step - loss: 0.0549 - binary_accuracy: 0.9826 - val_loss: 0.1984 - val_binary_accuracy: 0.9508\n",
      "Epoch 11/30\n",
      "2578/2578 [==============================] - 5s 2ms/step - loss: 0.0502 - binary_accuracy: 0.9842 - val_loss: 0.2289 - val_binary_accuracy: 0.9515\n",
      "Epoch 12/30\n",
      "2578/2578 [==============================] - 5s 2ms/step - loss: 0.0501 - binary_accuracy: 0.9843 - val_loss: 0.2101 - val_binary_accuracy: 0.9515\n",
      "Epoch 13/30\n",
      "2578/2578 [==============================] - 5s 2ms/step - loss: 0.0449 - binary_accuracy: 0.9860 - val_loss: 0.2663 - val_binary_accuracy: 0.9479\n",
      "Epoch 14/30\n",
      "2578/2578 [==============================] - 5s 2ms/step - loss: 0.0390 - binary_accuracy: 0.9876 - val_loss: 0.2577 - val_binary_accuracy: 0.9492\n",
      "Epoch 15/30\n",
      "2578/2578 [==============================] - 5s 2ms/step - loss: 0.0400 - binary_accuracy: 0.9875 - val_loss: 0.2377 - val_binary_accuracy: 0.9504\n",
      "Epoch 16/30\n",
      "2578/2578 [==============================] - 5s 2ms/step - loss: 0.0345 - binary_accuracy: 0.9895 - val_loss: 0.2739 - val_binary_accuracy: 0.9506\n",
      "Epoch 17/30\n",
      "2578/2578 [==============================] - 5s 2ms/step - loss: 0.0354 - binary_accuracy: 0.9899 - val_loss: 0.2849 - val_binary_accuracy: 0.9504\n",
      "Epoch 18/30\n",
      "2578/2578 [==============================] - 5s 2ms/step - loss: 0.0341 - binary_accuracy: 0.9893 - val_loss: 0.2917 - val_binary_accuracy: 0.9484\n",
      "Epoch 19/30\n",
      "2578/2578 [==============================] - 5s 2ms/step - loss: 0.0314 - binary_accuracy: 0.9903 - val_loss: 0.3104 - val_binary_accuracy: 0.9458\n",
      "Epoch 20/30\n",
      "2578/2578 [==============================] - 5s 2ms/step - loss: 0.0335 - binary_accuracy: 0.9900 - val_loss: 0.3245 - val_binary_accuracy: 0.9494\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2578/2578 [==============================] - 5s 2ms/step - loss: 0.0292 - binary_accuracy: 0.9912 - val_loss: 0.3063 - val_binary_accuracy: 0.9492\n",
      "Epoch 22/30\n",
      "2578/2578 [==============================] - 5s 2ms/step - loss: 0.0298 - binary_accuracy: 0.9914 - val_loss: 0.2798 - val_binary_accuracy: 0.9495\n",
      "Epoch 23/30\n",
      "2578/2578 [==============================] - 5s 2ms/step - loss: 0.0239 - binary_accuracy: 0.9927 - val_loss: 0.3571 - val_binary_accuracy: 0.9489\n",
      "Epoch 24/30\n",
      "2578/2578 [==============================] - 5s 2ms/step - loss: 0.0258 - binary_accuracy: 0.9924 - val_loss: 0.3424 - val_binary_accuracy: 0.9483\n",
      "Epoch 25/30\n",
      "2578/2578 [==============================] - 5s 2ms/step - loss: 0.0261 - binary_accuracy: 0.9925 - val_loss: 0.3315 - val_binary_accuracy: 0.9472\n",
      "Epoch 26/30\n",
      "2578/2578 [==============================] - 5s 2ms/step - loss: 0.0255 - binary_accuracy: 0.9924 - val_loss: 0.4052 - val_binary_accuracy: 0.9458\n",
      "Epoch 27/30\n",
      "2578/2578 [==============================] - 5s 2ms/step - loss: 0.0236 - binary_accuracy: 0.9927 - val_loss: 0.3524 - val_binary_accuracy: 0.9494\n",
      "Epoch 28/30\n",
      "2578/2578 [==============================] - 5s 2ms/step - loss: 0.0271 - binary_accuracy: 0.9924 - val_loss: 0.3288 - val_binary_accuracy: 0.9481\n",
      "Epoch 29/30\n",
      "2578/2578 [==============================] - 5s 2ms/step - loss: 0.0232 - binary_accuracy: 0.9931 - val_loss: 0.3954 - val_binary_accuracy: 0.9465\n",
      "Epoch 30/30\n",
      "2578/2578 [==============================] - 5s 2ms/step - loss: 0.0239 - binary_accuracy: 0.9932 - val_loss: 0.3762 - val_binary_accuracy: 0.9476\n",
      "436/436 [==============================] - 0s 265us/step\n",
      "Fold 3 :\n",
      "\n",
      "Train on 2582 samples, validate on 432 samples\n",
      "Epoch 1/30\n",
      "2582/2582 [==============================] - 7s 3ms/step - loss: 0.1694 - binary_accuracy: 0.9460 - val_loss: 0.1414 - val_binary_accuracy: 0.9543\n",
      "Epoch 2/30\n",
      "2582/2582 [==============================] - 5s 2ms/step - loss: 0.1358 - binary_accuracy: 0.9553 - val_loss: 0.1320 - val_binary_accuracy: 0.9555\n",
      "Epoch 3/30\n",
      "2582/2582 [==============================] - 5s 2ms/step - loss: 0.1172 - binary_accuracy: 0.9619 - val_loss: 0.1290 - val_binary_accuracy: 0.9601\n",
      "Epoch 4/30\n",
      "2582/2582 [==============================] - 5s 2ms/step - loss: 0.1018 - binary_accuracy: 0.9673 - val_loss: 0.1348 - val_binary_accuracy: 0.9601\n",
      "Epoch 5/30\n",
      "2582/2582 [==============================] - 5s 2ms/step - loss: 0.0926 - binary_accuracy: 0.9704 - val_loss: 0.1485 - val_binary_accuracy: 0.9586\n",
      "Epoch 6/30\n",
      "2582/2582 [==============================] - 5s 2ms/step - loss: 0.0832 - binary_accuracy: 0.9728 - val_loss: 0.1457 - val_binary_accuracy: 0.9609\n",
      "Epoch 7/30\n",
      "2582/2582 [==============================] - 5s 2ms/step - loss: 0.0750 - binary_accuracy: 0.9763 - val_loss: 0.1404 - val_binary_accuracy: 0.9603\n",
      "Epoch 8/30\n",
      "2582/2582 [==============================] - 5s 2ms/step - loss: 0.0690 - binary_accuracy: 0.9781 - val_loss: 0.1565 - val_binary_accuracy: 0.9600\n",
      "Epoch 9/30\n",
      "2582/2582 [==============================] - 5s 2ms/step - loss: 0.0643 - binary_accuracy: 0.9790 - val_loss: 0.1903 - val_binary_accuracy: 0.9542\n",
      "Epoch 10/30\n",
      "2582/2582 [==============================] - 5s 2ms/step - loss: 0.0594 - binary_accuracy: 0.9815 - val_loss: 0.1731 - val_binary_accuracy: 0.9615\n",
      "Epoch 11/30\n",
      "2582/2582 [==============================] - 5s 2ms/step - loss: 0.0546 - binary_accuracy: 0.9826 - val_loss: 0.1902 - val_binary_accuracy: 0.9586\n",
      "Epoch 12/30\n",
      "2582/2582 [==============================] - 5s 2ms/step - loss: 0.0531 - binary_accuracy: 0.9835 - val_loss: 0.2240 - val_binary_accuracy: 0.9552\n",
      "Epoch 13/30\n",
      "2582/2582 [==============================] - 5s 2ms/step - loss: 0.0535 - binary_accuracy: 0.9837 - val_loss: 0.1950 - val_binary_accuracy: 0.9579\n",
      "Epoch 14/30\n",
      "2582/2582 [==============================] - 5s 2ms/step - loss: 0.0498 - binary_accuracy: 0.9847 - val_loss: 0.2015 - val_binary_accuracy: 0.9560\n",
      "Epoch 15/30\n",
      "2582/2582 [==============================] - 5s 2ms/step - loss: 0.0436 - binary_accuracy: 0.9862 - val_loss: 0.2200 - val_binary_accuracy: 0.9569\n",
      "Epoch 16/30\n",
      "2582/2582 [==============================] - 5s 2ms/step - loss: 0.0414 - binary_accuracy: 0.9866 - val_loss: 0.2161 - val_binary_accuracy: 0.9621\n",
      "Epoch 17/30\n",
      "2582/2582 [==============================] - 5s 2ms/step - loss: 0.0388 - binary_accuracy: 0.9878 - val_loss: 0.2397 - val_binary_accuracy: 0.9596\n",
      "Epoch 18/30\n",
      "2582/2582 [==============================] - 5s 2ms/step - loss: 0.0382 - binary_accuracy: 0.9887 - val_loss: 0.2754 - val_binary_accuracy: 0.9565\n",
      "Epoch 19/30\n",
      "2582/2582 [==============================] - 5s 2ms/step - loss: 0.0356 - binary_accuracy: 0.9891 - val_loss: 0.2296 - val_binary_accuracy: 0.9623\n",
      "Epoch 20/30\n",
      "2582/2582 [==============================] - 5s 2ms/step - loss: 0.0377 - binary_accuracy: 0.9885 - val_loss: 0.2642 - val_binary_accuracy: 0.9582\n",
      "Epoch 21/30\n",
      "2582/2582 [==============================] - 5s 2ms/step - loss: 0.0324 - binary_accuracy: 0.9904 - val_loss: 0.2691 - val_binary_accuracy: 0.9601\n",
      "Epoch 22/30\n",
      "2582/2582 [==============================] - 5s 2ms/step - loss: 0.0337 - binary_accuracy: 0.9891 - val_loss: 0.2497 - val_binary_accuracy: 0.9579\n",
      "Epoch 23/30\n",
      "2582/2582 [==============================] - 5s 2ms/step - loss: 0.0308 - binary_accuracy: 0.9906 - val_loss: 0.2840 - val_binary_accuracy: 0.9552\n",
      "Epoch 24/30\n",
      "2582/2582 [==============================] - 5s 2ms/step - loss: 0.0341 - binary_accuracy: 0.9900 - val_loss: 0.2794 - val_binary_accuracy: 0.9550\n",
      "Epoch 25/30\n",
      "2582/2582 [==============================] - 5s 2ms/step - loss: 0.0293 - binary_accuracy: 0.9914 - val_loss: 0.2657 - val_binary_accuracy: 0.9586\n",
      "Epoch 26/30\n",
      "2582/2582 [==============================] - 5s 2ms/step - loss: 0.0267 - binary_accuracy: 0.9915 - val_loss: 0.2508 - val_binary_accuracy: 0.9590\n",
      "Epoch 27/30\n",
      "2582/2582 [==============================] - 5s 2ms/step - loss: 0.0253 - binary_accuracy: 0.9921 - val_loss: 0.2871 - val_binary_accuracy: 0.9583\n",
      "Epoch 28/30\n",
      "2582/2582 [==============================] - 5s 2ms/step - loss: 0.0273 - binary_accuracy: 0.9915 - val_loss: 0.2453 - val_binary_accuracy: 0.9608\n",
      "Epoch 29/30\n",
      "2582/2582 [==============================] - 5s 2ms/step - loss: 0.0253 - binary_accuracy: 0.9918 - val_loss: 0.3393 - val_binary_accuracy: 0.9585\n",
      "Epoch 30/30\n",
      "2582/2582 [==============================] - 5s 2ms/step - loss: 0.0262 - binary_accuracy: 0.9920 - val_loss: 0.2949 - val_binary_accuracy: 0.9565\n",
      "432/432 [==============================] - 0s 263us/step\n",
      "Fold 4 :\n",
      "\n",
      "Train on 2583 samples, validate on 431 samples\n",
      "Epoch 1/30\n",
      "2583/2583 [==============================] - 8s 3ms/step - loss: 0.1681 - binary_accuracy: 0.9461 - val_loss: 0.1484 - val_binary_accuracy: 0.9520\n",
      "Epoch 2/30\n",
      "2583/2583 [==============================] - 5s 2ms/step - loss: 0.1355 - binary_accuracy: 0.9561 - val_loss: 0.1251 - val_binary_accuracy: 0.9598\n",
      "Epoch 3/30\n",
      "2583/2583 [==============================] - 5s 2ms/step - loss: 0.1156 - binary_accuracy: 0.9629 - val_loss: 0.1291 - val_binary_accuracy: 0.9580\n",
      "Epoch 4/30\n",
      "2583/2583 [==============================] - 5s 2ms/step - loss: 0.1035 - binary_accuracy: 0.9667 - val_loss: 0.1325 - val_binary_accuracy: 0.9600\n",
      "Epoch 5/30\n",
      "2583/2583 [==============================] - 5s 2ms/step - loss: 0.0932 - binary_accuracy: 0.9700 - val_loss: 0.1434 - val_binary_accuracy: 0.9589\n",
      "Epoch 6/30\n",
      "2583/2583 [==============================] - 5s 2ms/step - loss: 0.0836 - binary_accuracy: 0.9730 - val_loss: 0.1490 - val_binary_accuracy: 0.9585\n",
      "Epoch 7/30\n",
      "2583/2583 [==============================] - 5s 2ms/step - loss: 0.0759 - binary_accuracy: 0.9749 - val_loss: 0.1557 - val_binary_accuracy: 0.9599\n",
      "Epoch 8/30\n",
      "2583/2583 [==============================] - 5s 2ms/step - loss: 0.0709 - binary_accuracy: 0.9767 - val_loss: 0.1537 - val_binary_accuracy: 0.9612\n",
      "Epoch 9/30\n",
      "2583/2583 [==============================] - 5s 2ms/step - loss: 0.0618 - binary_accuracy: 0.9795 - val_loss: 0.1727 - val_binary_accuracy: 0.9606\n",
      "Epoch 10/30\n",
      "2583/2583 [==============================] - 5s 2ms/step - loss: 0.0607 - binary_accuracy: 0.9804 - val_loss: 0.1620 - val_binary_accuracy: 0.9575\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2583/2583 [==============================] - 5s 2ms/step - loss: 0.0536 - binary_accuracy: 0.9822 - val_loss: 0.1839 - val_binary_accuracy: 0.9582\n",
      "Epoch 12/30\n",
      "2583/2583 [==============================] - 5s 2ms/step - loss: 0.0509 - binary_accuracy: 0.9836 - val_loss: 0.1731 - val_binary_accuracy: 0.9591\n",
      "Epoch 13/30\n",
      "2583/2583 [==============================] - 5s 2ms/step - loss: 0.0484 - binary_accuracy: 0.9843 - val_loss: 0.2085 - val_binary_accuracy: 0.9599\n",
      "Epoch 14/30\n",
      "2583/2583 [==============================] - 5s 2ms/step - loss: 0.0450 - binary_accuracy: 0.9854 - val_loss: 0.2290 - val_binary_accuracy: 0.9581TA: 0s - loss: 0.0441 - binary_a\n",
      "Epoch 15/30\n",
      "2583/2583 [==============================] - 5s 2ms/step - loss: 0.0421 - binary_accuracy: 0.9859 - val_loss: 0.2192 - val_binary_accuracy: 0.9588\n",
      "Epoch 16/30\n",
      "2583/2583 [==============================] - 5s 2ms/step - loss: 0.0401 - binary_accuracy: 0.9871 - val_loss: 0.2273 - val_binary_accuracy: 0.9594\n",
      "Epoch 17/30\n",
      "2583/2583 [==============================] - 5s 2ms/step - loss: 0.0400 - binary_accuracy: 0.9874 - val_loss: 0.2211 - val_binary_accuracy: 0.9584\n",
      "Epoch 18/30\n",
      "2583/2583 [==============================] - 5s 2ms/step - loss: 0.0360 - binary_accuracy: 0.9884 - val_loss: 0.2239 - val_binary_accuracy: 0.9589\n",
      "Epoch 19/30\n",
      "2583/2583 [==============================] - 5s 2ms/step - loss: 0.0370 - binary_accuracy: 0.9884 - val_loss: 0.2013 - val_binary_accuracy: 0.9591\n",
      "Epoch 20/30\n",
      "2583/2583 [==============================] - 5s 2ms/step - loss: 0.0337 - binary_accuracy: 0.9891 - val_loss: 0.2475 - val_binary_accuracy: 0.9598\n",
      "Epoch 21/30\n",
      "2583/2583 [==============================] - 5s 2ms/step - loss: 0.0318 - binary_accuracy: 0.9903 - val_loss: 0.2498 - val_binary_accuracy: 0.9568\n",
      "Epoch 22/30\n",
      "2583/2583 [==============================] - 5s 2ms/step - loss: 0.0312 - binary_accuracy: 0.9905 - val_loss: 0.2561 - val_binary_accuracy: 0.9572\n",
      "Epoch 23/30\n",
      "2583/2583 [==============================] - 5s 2ms/step - loss: 0.0316 - binary_accuracy: 0.9900 - val_loss: 0.2391 - val_binary_accuracy: 0.9598\n",
      "Epoch 24/30\n",
      "2583/2583 [==============================] - 5s 2ms/step - loss: 0.0270 - binary_accuracy: 0.9914 - val_loss: 0.2778 - val_binary_accuracy: 0.9581\n",
      "Epoch 25/30\n",
      "2583/2583 [==============================] - 5s 2ms/step - loss: 0.0291 - binary_accuracy: 0.9906 - val_loss: 0.2389 - val_binary_accuracy: 0.9598\n",
      "Epoch 26/30\n",
      "2583/2583 [==============================] - 5s 2ms/step - loss: 0.0263 - binary_accuracy: 0.9913 - val_loss: 0.2828 - val_binary_accuracy: 0.9598\n",
      "Epoch 27/30\n",
      "2583/2583 [==============================] - 5s 2ms/step - loss: 0.0265 - binary_accuracy: 0.9920 - val_loss: 0.2821 - val_binary_accuracy: 0.9585\n",
      "Epoch 28/30\n",
      "2583/2583 [==============================] - 5s 2ms/step - loss: 0.0249 - binary_accuracy: 0.9923 - val_loss: 0.2725 - val_binary_accuracy: 0.9584\n",
      "Epoch 29/30\n",
      "2583/2583 [==============================] - 5s 2ms/step - loss: 0.0254 - binary_accuracy: 0.9918 - val_loss: 0.2761 - val_binary_accuracy: 0.9582\n",
      "Epoch 30/30\n",
      "2583/2583 [==============================] - 5s 2ms/step - loss: 0.0243 - binary_accuracy: 0.9922 - val_loss: 0.2875 - val_binary_accuracy: 0.9578\n",
      "431/431 [==============================] - 0s 266us/step\n",
      "Fold 5 :\n",
      "\n",
      "Train on 2586 samples, validate on 428 samples\n",
      "Epoch 1/30\n",
      "2586/2586 [==============================] - 8s 3ms/step - loss: 0.1689 - binary_accuracy: 0.9458 - val_loss: 0.1590 - val_binary_accuracy: 0.9489\n",
      "Epoch 2/30\n",
      "2586/2586 [==============================] - 5s 2ms/step - loss: 0.1355 - binary_accuracy: 0.9549 - val_loss: 0.1393 - val_binary_accuracy: 0.9550\n",
      "Epoch 3/30\n",
      "2586/2586 [==============================] - 5s 2ms/step - loss: 0.1178 - binary_accuracy: 0.9615 - val_loss: 0.1322 - val_binary_accuracy: 0.9589\n",
      "Epoch 4/30\n",
      "2586/2586 [==============================] - 5s 2ms/step - loss: 0.1048 - binary_accuracy: 0.9669 - val_loss: 0.1313 - val_binary_accuracy: 0.9578\n",
      "Epoch 5/30\n",
      "2586/2586 [==============================] - 5s 2ms/step - loss: 0.0943 - binary_accuracy: 0.9702 - val_loss: 0.1361 - val_binary_accuracy: 0.9595\n",
      "Epoch 6/30\n",
      "2586/2586 [==============================] - 5s 2ms/step - loss: 0.0876 - binary_accuracy: 0.9722 - val_loss: 0.1454 - val_binary_accuracy: 0.9590\n",
      "Epoch 7/30\n",
      "2586/2586 [==============================] - 5s 2ms/step - loss: 0.0762 - binary_accuracy: 0.9753 - val_loss: 0.1628 - val_binary_accuracy: 0.9592\n",
      "Epoch 8/30\n",
      "2586/2586 [==============================] - 5s 2ms/step - loss: 0.0685 - binary_accuracy: 0.9777 - val_loss: 0.1601 - val_binary_accuracy: 0.9582\n",
      "Epoch 9/30\n",
      "2586/2586 [==============================] - 5s 2ms/step - loss: 0.0638 - binary_accuracy: 0.9796 - val_loss: 0.1720 - val_binary_accuracy: 0.9607\n",
      "Epoch 10/30\n",
      "2586/2586 [==============================] - 5s 2ms/step - loss: 0.0601 - binary_accuracy: 0.9808 - val_loss: 0.1925 - val_binary_accuracy: 0.9574\n",
      "Epoch 11/30\n",
      "2586/2586 [==============================] - 5s 2ms/step - loss: 0.0594 - binary_accuracy: 0.9809 - val_loss: 0.1676 - val_binary_accuracy: 0.9608\n",
      "Epoch 12/30\n",
      "2586/2586 [==============================] - 5s 2ms/step - loss: 0.0524 - binary_accuracy: 0.9828 - val_loss: 0.2025 - val_binary_accuracy: 0.9586\n",
      "Epoch 13/30\n",
      "2586/2586 [==============================] - 5s 2ms/step - loss: 0.0483 - binary_accuracy: 0.9850 - val_loss: 0.2054 - val_binary_accuracy: 0.9595\n",
      "Epoch 14/30\n",
      "2586/2586 [==============================] - 5s 2ms/step - loss: 0.0454 - binary_accuracy: 0.9858 - val_loss: 0.2070 - val_binary_accuracy: 0.9608\n",
      "Epoch 15/30\n",
      "2586/2586 [==============================] - 5s 2ms/step - loss: 0.0439 - binary_accuracy: 0.9864 - val_loss: 0.2254 - val_binary_accuracy: 0.9592\n",
      "Epoch 16/30\n",
      "2586/2586 [==============================] - 5s 2ms/step - loss: 0.0422 - binary_accuracy: 0.9873 - val_loss: 0.2270 - val_binary_accuracy: 0.9589\n",
      "Epoch 17/30\n",
      "2586/2586 [==============================] - 5s 2ms/step - loss: 0.0398 - binary_accuracy: 0.9874 - val_loss: 0.2339 - val_binary_accuracy: 0.9591\n",
      "Epoch 18/30\n",
      "2586/2586 [==============================] - 5s 2ms/step - loss: 0.0413 - binary_accuracy: 0.9879 - val_loss: 0.2278 - val_binary_accuracy: 0.9579\n",
      "Epoch 19/30\n",
      "2586/2586 [==============================] - 5s 2ms/step - loss: 0.0380 - binary_accuracy: 0.9885 - val_loss: 0.2300 - val_binary_accuracy: 0.9585\n",
      "Epoch 20/30\n",
      "2586/2586 [==============================] - 5s 2ms/step - loss: 0.0389 - binary_accuracy: 0.9881 - val_loss: 0.2586 - val_binary_accuracy: 0.9583\n",
      "Epoch 21/30\n",
      "2586/2586 [==============================] - 6s 2ms/step - loss: 0.0309 - binary_accuracy: 0.9902 - val_loss: 0.2642 - val_binary_accuracy: 0.9586\n",
      "Epoch 22/30\n",
      "2586/2586 [==============================] - 6s 2ms/step - loss: 0.0305 - binary_accuracy: 0.9904 - val_loss: 0.2535 - val_binary_accuracy: 0.9579\n",
      "Epoch 23/30\n",
      "2586/2586 [==============================] - 6s 2ms/step - loss: 0.0284 - binary_accuracy: 0.9906 - val_loss: 0.2598 - val_binary_accuracy: 0.9590\n",
      "Epoch 24/30\n",
      "2586/2586 [==============================] - 7s 3ms/step - loss: 0.0310 - binary_accuracy: 0.9902 - val_loss: 0.2756 - val_binary_accuracy: 0.9574\n",
      "Epoch 25/30\n",
      "2586/2586 [==============================] - 7s 3ms/step - loss: 0.0285 - binary_accuracy: 0.9906 - val_loss: 0.2782 - val_binary_accuracy: 0.9578\n",
      "Epoch 26/30\n",
      "2586/2586 [==============================] - 6s 2ms/step - loss: 0.0287 - binary_accuracy: 0.9909 - val_loss: 0.2936 - val_binary_accuracy: 0.9587\n",
      "Epoch 27/30\n",
      "2586/2586 [==============================] - 6s 2ms/step - loss: 0.0283 - binary_accuracy: 0.9914 - val_loss: 0.2715 - val_binary_accuracy: 0.9576\n",
      "Epoch 28/30\n",
      "2586/2586 [==============================] - 5s 2ms/step - loss: 0.0261 - binary_accuracy: 0.9918 - val_loss: 0.3007 - val_binary_accuracy: 0.9570\n",
      "Epoch 29/30\n",
      "2586/2586 [==============================] - 5s 2ms/step - loss: 0.0268 - binary_accuracy: 0.9915 - val_loss: 0.2988 - val_binary_accuracy: 0.9582\n",
      "Epoch 30/30\n",
      "2586/2586 [==============================] - 6s 2ms/step - loss: 0.0267 - binary_accuracy: 0.9916 - val_loss: 0.3327 - val_binary_accuracy: 0.9559\n",
      "428/428 [==============================] - 0s 329us/step\n",
      "Fold 6 :\n",
      "\n",
      "Train on 2589 samples, validate on 425 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2589/2589 [==============================] - 8s 3ms/step - loss: 0.1673 - binary_accuracy: 0.9461 - val_loss: 0.1461 - val_binary_accuracy: 0.9535\n",
      "Epoch 2/30\n",
      "2589/2589 [==============================] - 5s 2ms/step - loss: 0.1361 - binary_accuracy: 0.9549 - val_loss: 0.1277 - val_binary_accuracy: 0.9569\n",
      "Epoch 3/30\n",
      "2589/2589 [==============================] - 5s 2ms/step - loss: 0.1165 - binary_accuracy: 0.9620 - val_loss: 0.1189 - val_binary_accuracy: 0.9608\n",
      "Epoch 4/30\n",
      "2589/2589 [==============================] - 5s 2ms/step - loss: 0.1035 - binary_accuracy: 0.9670 - val_loss: 0.1212 - val_binary_accuracy: 0.9608\n",
      "Epoch 5/30\n",
      "2589/2589 [==============================] - 5s 2ms/step - loss: 0.0936 - binary_accuracy: 0.9707 - val_loss: 0.1346 - val_binary_accuracy: 0.9595\n",
      "Epoch 6/30\n",
      "2589/2589 [==============================] - 5s 2ms/step - loss: 0.0863 - binary_accuracy: 0.9724 - val_loss: 0.1328 - val_binary_accuracy: 0.9605\n",
      "Epoch 7/30\n",
      "2589/2589 [==============================] - 5s 2ms/step - loss: 0.0813 - binary_accuracy: 0.9739 - val_loss: 0.1337 - val_binary_accuracy: 0.9609\n",
      "Epoch 8/30\n",
      "2589/2589 [==============================] - 5s 2ms/step - loss: 0.0741 - binary_accuracy: 0.9752 - val_loss: 0.1473 - val_binary_accuracy: 0.9618\n",
      "Epoch 9/30\n",
      "2589/2589 [==============================] - 6s 2ms/step - loss: 0.0715 - binary_accuracy: 0.9771 - val_loss: 0.1648 - val_binary_accuracy: 0.9620\n",
      "Epoch 10/30\n",
      "2589/2589 [==============================] - 6s 2ms/step - loss: 0.0607 - binary_accuracy: 0.9806 - val_loss: 0.1657 - val_binary_accuracy: 0.9627\n",
      "Epoch 11/30\n",
      "2589/2589 [==============================] - 5s 2ms/step - loss: 0.0567 - binary_accuracy: 0.9818 - val_loss: 0.1486 - val_binary_accuracy: 0.9625\n",
      "Epoch 12/30\n",
      "2589/2589 [==============================] - 5s 2ms/step - loss: 0.0541 - binary_accuracy: 0.9825 - val_loss: 0.1616 - val_binary_accuracy: 0.9639\n",
      "Epoch 13/30\n",
      "2589/2589 [==============================] - 5s 2ms/step - loss: 0.0513 - binary_accuracy: 0.9840 - val_loss: 0.1719 - val_binary_accuracy: 0.9609\n",
      "Epoch 14/30\n",
      "2589/2589 [==============================] - 5s 2ms/step - loss: 0.0478 - binary_accuracy: 0.9846 - val_loss: 0.1800 - val_binary_accuracy: 0.9639\n",
      "Epoch 15/30\n",
      "2589/2589 [==============================] - 5s 2ms/step - loss: 0.0419 - binary_accuracy: 0.9870 - val_loss: 0.1965 - val_binary_accuracy: 0.9609\n",
      "Epoch 16/30\n",
      "2589/2589 [==============================] - 5s 2ms/step - loss: 0.0443 - binary_accuracy: 0.9859 - val_loss: 0.1839 - val_binary_accuracy: 0.9605\n",
      "Epoch 17/30\n",
      "2589/2589 [==============================] - 5s 2ms/step - loss: 0.0376 - binary_accuracy: 0.9888 - val_loss: 0.2084 - val_binary_accuracy: 0.9600\n",
      "Epoch 18/30\n",
      "2589/2589 [==============================] - 5s 2ms/step - loss: 0.0356 - binary_accuracy: 0.9892 - val_loss: 0.2481 - val_binary_accuracy: 0.9608\n",
      "Epoch 19/30\n",
      "2589/2589 [==============================] - 5s 2ms/step - loss: 0.0343 - binary_accuracy: 0.9896 - val_loss: 0.2336 - val_binary_accuracy: 0.9578\n",
      "Epoch 20/30\n",
      "2589/2589 [==============================] - 5s 2ms/step - loss: 0.0313 - binary_accuracy: 0.9899 - val_loss: 0.2546 - val_binary_accuracy: 0.9561\n",
      "Epoch 21/30\n",
      "2589/2589 [==============================] - 5s 2ms/step - loss: 0.0318 - binary_accuracy: 0.9905 - val_loss: 0.2299 - val_binary_accuracy: 0.9600\n",
      "Epoch 22/30\n",
      "2589/2589 [==============================] - 5s 2ms/step - loss: 0.0309 - binary_accuracy: 0.9900 - val_loss: 0.2569 - val_binary_accuracy: 0.9590\n",
      "Epoch 23/30\n",
      "2589/2589 [==============================] - 5s 2ms/step - loss: 0.0333 - binary_accuracy: 0.9899 - val_loss: 0.2568 - val_binary_accuracy: 0.9597\n",
      "Epoch 24/30\n",
      "2589/2589 [==============================] - 5s 2ms/step - loss: 0.0281 - binary_accuracy: 0.9912 - val_loss: 0.2685 - val_binary_accuracy: 0.9609\n",
      "Epoch 25/30\n",
      "2589/2589 [==============================] - 5s 2ms/step - loss: 0.0318 - binary_accuracy: 0.9903 - val_loss: 0.2492 - val_binary_accuracy: 0.9624\n",
      "Epoch 26/30\n",
      "2589/2589 [==============================] - 5s 2ms/step - loss: 0.0269 - binary_accuracy: 0.9918 - val_loss: 0.2857 - val_binary_accuracy: 0.9599\n",
      "Epoch 27/30\n",
      "2589/2589 [==============================] - 5s 2ms/step - loss: 0.0287 - binary_accuracy: 0.9914 - val_loss: 0.2507 - val_binary_accuracy: 0.9593\n",
      "Epoch 28/30\n",
      "2589/2589 [==============================] - 5s 2ms/step - loss: 0.0267 - binary_accuracy: 0.9918 - val_loss: 0.2601 - val_binary_accuracy: 0.9596\n",
      "Epoch 29/30\n",
      "2589/2589 [==============================] - 5s 2ms/step - loss: 0.0276 - binary_accuracy: 0.9915 - val_loss: 0.2562 - val_binary_accuracy: 0.9604\n",
      "Epoch 30/30\n",
      "2589/2589 [==============================] - 5s 2ms/step - loss: 0.0237 - binary_accuracy: 0.9923 - val_loss: 0.2868 - val_binary_accuracy: 0.9591\n",
      "425/425 [==============================] - 0s 311us/step\n",
      "Fold 7 :\n",
      "\n",
      "Train on 2590 samples, validate on 424 samples\n",
      "Epoch 1/30\n",
      "2590/2590 [==============================] - 9s 3ms/step - loss: 0.1699 - binary_accuracy: 0.9457 - val_loss: 0.1499 - val_binary_accuracy: 0.9494\n",
      "Epoch 2/30\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.1388 - binary_accuracy: 0.9540 - val_loss: 0.1369 - val_binary_accuracy: 0.9553\n",
      "Epoch 3/30\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1184 - binary_accuracy: 0.9604 - val_loss: 0.1229 - val_binary_accuracy: 0.9599\n",
      "Epoch 4/30\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.1074 - binary_accuracy: 0.9659 - val_loss: 0.1227 - val_binary_accuracy: 0.9600\n",
      "Epoch 5/30\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0966 - binary_accuracy: 0.9695 - val_loss: 0.1236 - val_binary_accuracy: 0.9589\n",
      "Epoch 6/30\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0884 - binary_accuracy: 0.9715 - val_loss: 0.1231 - val_binary_accuracy: 0.9621\n",
      "Epoch 7/30\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0791 - binary_accuracy: 0.9745 - val_loss: 0.1257 - val_binary_accuracy: 0.9632\n",
      "Epoch 8/30\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0722 - binary_accuracy: 0.9769 - val_loss: 0.1361 - val_binary_accuracy: 0.9624\n",
      "Epoch 9/30\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0642 - binary_accuracy: 0.9788 - val_loss: 0.1527 - val_binary_accuracy: 0.9612\n",
      "Epoch 10/30\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0614 - binary_accuracy: 0.9799 - val_loss: 0.1407 - val_binary_accuracy: 0.9653\n",
      "Epoch 11/30\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0527 - binary_accuracy: 0.9824 - val_loss: 0.1805 - val_binary_accuracy: 0.9607\n",
      "Epoch 12/30\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0536 - binary_accuracy: 0.9825 - val_loss: 0.1675 - val_binary_accuracy: 0.9640\n",
      "Epoch 13/30\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0465 - binary_accuracy: 0.9846 - val_loss: 0.1672 - val_binary_accuracy: 0.9640\n",
      "Epoch 14/30\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0449 - binary_accuracy: 0.9858 - val_loss: 0.1746 - val_binary_accuracy: 0.9628\n",
      "Epoch 15/30\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0425 - binary_accuracy: 0.9863 - val_loss: 0.1635 - val_binary_accuracy: 0.9583s: 0.0387 - binary_accuracy: - ETA: 2s - loss: 0.03\n",
      "Epoch 16/30\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0414 - binary_accuracy: 0.9870 - val_loss: 0.1883 - val_binary_accuracy: 0.9599\n",
      "Epoch 17/30\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0362 - binary_accuracy: 0.9887 - val_loss: 0.1844 - val_binary_accuracy: 0.9606\n",
      "Epoch 18/30\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0340 - binary_accuracy: 0.9887 - val_loss: 0.2241 - val_binary_accuracy: 0.9615\n",
      "Epoch 19/30\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0332 - binary_accuracy: 0.9896 - val_loss: 0.2062 - val_binary_accuracy: 0.9599\n",
      "Epoch 20/30\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0338 - binary_accuracy: 0.9895 - val_loss: 0.2168 - val_binary_accuracy: 0.9591\n",
      "Epoch 21/30\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0304 - binary_accuracy: 0.9901 - val_loss: 0.2090 - val_binary_accuracy: 0.9615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0366 - binary_accuracy: 0.9894 - val_loss: 0.2184 - val_binary_accuracy: 0.9612\n",
      "Epoch 23/30\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0311 - binary_accuracy: 0.9903 - val_loss: 0.2329 - val_binary_accuracy: 0.9620\n",
      "Epoch 24/30\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0284 - binary_accuracy: 0.9914 - val_loss: 0.2491 - val_binary_accuracy: 0.9604\n",
      "Epoch 25/30\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0275 - binary_accuracy: 0.9915 - val_loss: 0.2435 - val_binary_accuracy: 0.9604\n",
      "Epoch 26/30\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0266 - binary_accuracy: 0.9916 - val_loss: 0.2516 - val_binary_accuracy: 0.9627\n",
      "Epoch 27/30\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0250 - binary_accuracy: 0.9924 - val_loss: 0.2556 - val_binary_accuracy: 0.9619\n",
      "Epoch 28/30\n",
      "2590/2590 [==============================] - 6s 2ms/step - loss: 0.0248 - binary_accuracy: 0.9925 - val_loss: 0.2225 - val_binary_accuracy: 0.9629\n",
      "Epoch 29/30\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0245 - binary_accuracy: 0.9924 - val_loss: 0.2955 - val_binary_accuracy: 0.9590\n",
      "Epoch 30/30\n",
      "2590/2590 [==============================] - 5s 2ms/step - loss: 0.0283 - binary_accuracy: 0.9915 - val_loss: 0.2337 - val_binary_accuracy: 0.9625\n",
      "424/424 [==============================] - 0s 288us/step\n"
     ]
    }
   ],
   "source": [
    "#k=7, fungsi aktivasi=ReLU, nilai dropout=0.4\n",
    "kf = StratifiedKFold(n_splits=7, random_state=None, shuffle=False)\n",
    "val_loss_cv = []\n",
    "val_acc_cv = []\n",
    "j = 0\n",
    "for train_index, test_index in kf.split(X,z):\n",
    "    j+=1\n",
    "    print(f\"Fold {j} :\")\n",
    "    print(\"\")\n",
    "    X_train,X_test = X.iloc[train_index,:],X.iloc[test_index,:]\n",
    "    y_train,y_test = y.iloc[train_index,:],y.iloc[test_index,:]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim=X_train.shape[1], units=463,\n",
    "                     kernel_initializer='normal', bias_initializer='zeros'))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    for i in range(0, 6):\n",
    "        model.add(Dense(units=463, kernel_initializer='normal',\n",
    "                         bias_initializer='zeros'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(.4))\n",
    "\n",
    "    model.add(Dense(units=18))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
    "    model.fit(X_train, y_train,batch_size=24,epochs=30,verbose=1,validation_data=(X_test, y_test))\n",
    "    score = model.evaluate(X_test, y_test, verbose=1)\n",
    "    val_loss_cv.append(score[0])\n",
    "    val_acc_cv.append(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss_cv : [0.3427068980317138, 0.3761633530669256, 0.29490436723938696, 0.28751820471059975, 0.33268050724100845, 0.28682597076191624, 0.23374059740102515]\n",
      "mean_val_loss_cv : 0.3077914140646537\n",
      "val_acc_cv : [0.9502790360690252, 0.9476299548367841, 0.9565329066029301, 0.9578499361146631, 0.9558670676757242, 0.9590849601521212, 0.9625261954541476]\n",
      "mean_val_acc_cv : 0.9556814367007708\n"
     ]
    }
   ],
   "source": [
    "print(f\"val_loss_cv : {val_loss_cv}\")\n",
    "print(f\"mean_val_loss_cv : {np.mean(val_loss_cv)}\")\n",
    "print(f\"val_acc_cv : {val_acc_cv}\")\n",
    "print(f\"mean_val_acc_cv : {np.mean(val_acc_cv)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=8.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 :\n",
      "\n",
      "Train on 2629 samples, validate on 385 samples\n",
      "Epoch 1/30\n",
      "2629/2629 [==============================] - 9s 3ms/step - loss: 0.1682 - binary_accuracy: 0.9469 - val_loss: 0.1467 - val_binary_accuracy: 0.9534\n",
      "Epoch 2/30\n",
      "2629/2629 [==============================] - 6s 2ms/step - loss: 0.1366 - binary_accuracy: 0.9554 - val_loss: 0.1285 - val_binary_accuracy: 0.9564\n",
      "Epoch 3/30\n",
      "2629/2629 [==============================] - 5s 2ms/step - loss: 0.1158 - binary_accuracy: 0.9627 - val_loss: 0.1294 - val_binary_accuracy: 0.9579\n",
      "Epoch 4/30\n",
      "2629/2629 [==============================] - 5s 2ms/step - loss: 0.1046 - binary_accuracy: 0.9667 - val_loss: 0.1368 - val_binary_accuracy: 0.9573\n",
      "Epoch 5/30\n",
      "2629/2629 [==============================] - 5s 2ms/step - loss: 0.0914 - binary_accuracy: 0.9710 - val_loss: 0.1295 - val_binary_accuracy: 0.9597\n",
      "Epoch 6/30\n",
      "2629/2629 [==============================] - 5s 2ms/step - loss: 0.0836 - binary_accuracy: 0.9728 - val_loss: 0.1470 - val_binary_accuracy: 0.9579\n",
      "Epoch 7/30\n",
      "2629/2629 [==============================] - 6s 2ms/step - loss: 0.0741 - binary_accuracy: 0.9757 - val_loss: 0.1479 - val_binary_accuracy: 0.9584\n",
      "Epoch 8/30\n",
      "2629/2629 [==============================] - 5s 2ms/step - loss: 0.0688 - binary_accuracy: 0.9777 - val_loss: 0.1715 - val_binary_accuracy: 0.9566\n",
      "Epoch 9/30\n",
      "2629/2629 [==============================] - 5s 2ms/step - loss: 0.0615 - binary_accuracy: 0.9801 - val_loss: 0.1596 - val_binary_accuracy: 0.9573\n",
      "Epoch 10/30\n",
      "2629/2629 [==============================] - 5s 2ms/step - loss: 0.0535 - binary_accuracy: 0.9828 - val_loss: 0.1803 - val_binary_accuracy: 0.9566\n",
      "Epoch 11/30\n",
      "2629/2629 [==============================] - 5s 2ms/step - loss: 0.0514 - binary_accuracy: 0.9829 - val_loss: 0.1806 - val_binary_accuracy: 0.9560\n",
      "Epoch 12/30\n",
      "2629/2629 [==============================] - 5s 2ms/step - loss: 0.0507 - binary_accuracy: 0.9838 - val_loss: 0.1952 - val_binary_accuracy: 0.9553\n",
      "Epoch 13/30\n",
      "2629/2629 [==============================] - 5s 2ms/step - loss: 0.0473 - binary_accuracy: 0.9853 - val_loss: 0.1720 - val_binary_accuracy: 0.9528\n",
      "Epoch 14/30\n",
      "2629/2629 [==============================] - 5s 2ms/step - loss: 0.0415 - binary_accuracy: 0.9867 - val_loss: 0.1919 - val_binary_accuracy: 0.9566\n",
      "Epoch 15/30\n",
      "2629/2629 [==============================] - 5s 2ms/step - loss: 0.0394 - binary_accuracy: 0.9876 - val_loss: 0.2463 - val_binary_accuracy: 0.9528\n",
      "Epoch 16/30\n",
      "2629/2629 [==============================] - 5s 2ms/step - loss: 0.0349 - binary_accuracy: 0.9885 - val_loss: 0.2101 - val_binary_accuracy: 0.9545\n",
      "Epoch 17/30\n",
      "2629/2629 [==============================] - 5s 2ms/step - loss: 0.0364 - binary_accuracy: 0.9885 - val_loss: 0.2495 - val_binary_accuracy: 0.9544\n",
      "Epoch 18/30\n",
      "2629/2629 [==============================] - 5s 2ms/step - loss: 0.0349 - binary_accuracy: 0.9893 - val_loss: 0.2850 - val_binary_accuracy: 0.9548\n",
      "Epoch 19/30\n",
      "2629/2629 [==============================] - 5s 2ms/step - loss: 0.0330 - binary_accuracy: 0.9898 - val_loss: 0.2563 - val_binary_accuracy: 0.9511\n",
      "Epoch 20/30\n",
      "2629/2629 [==============================] - 5s 2ms/step - loss: 0.0306 - binary_accuracy: 0.9904 - val_loss: 0.2544 - val_binary_accuracy: 0.9537\n",
      "Epoch 21/30\n",
      "2629/2629 [==============================] - 5s 2ms/step - loss: 0.0287 - binary_accuracy: 0.9907 - val_loss: 0.2685 - val_binary_accuracy: 0.9532\n",
      "Epoch 22/30\n",
      "2629/2629 [==============================] - 5s 2ms/step - loss: 0.0305 - binary_accuracy: 0.9907 - val_loss: 0.2987 - val_binary_accuracy: 0.9534\n",
      "Epoch 23/30\n",
      "2629/2629 [==============================] - 5s 2ms/step - loss: 0.0284 - binary_accuracy: 0.9910 - val_loss: 0.3053 - val_binary_accuracy: 0.9524\n",
      "Epoch 24/30\n",
      "2629/2629 [==============================] - 6s 2ms/step - loss: 0.0270 - binary_accuracy: 0.9921 - val_loss: 0.3071 - val_binary_accuracy: 0.9522\n",
      "Epoch 25/30\n",
      "2629/2629 [==============================] - 6s 2ms/step - loss: 0.0269 - binary_accuracy: 0.9918 - val_loss: 0.3077 - val_binary_accuracy: 0.9551\n",
      "Epoch 26/30\n",
      "2629/2629 [==============================] - 5s 2ms/step - loss: 0.0274 - binary_accuracy: 0.9920 - val_loss: 0.2770 - val_binary_accuracy: 0.9556\n",
      "Epoch 27/30\n",
      "2629/2629 [==============================] - 5s 2ms/step - loss: 0.0271 - binary_accuracy: 0.9917 - val_loss: 0.2864 - val_binary_accuracy: 0.9538\n",
      "Epoch 28/30\n",
      "2629/2629 [==============================] - 5s 2ms/step - loss: 0.0277 - binary_accuracy: 0.9921 - val_loss: 0.2815 - val_binary_accuracy: 0.9527\n",
      "Epoch 29/30\n",
      "2629/2629 [==============================] - 5s 2ms/step - loss: 0.0276 - binary_accuracy: 0.9915 - val_loss: 0.2600 - val_binary_accuracy: 0.9564\n",
      "Epoch 30/30\n",
      "2629/2629 [==============================] - 5s 2ms/step - loss: 0.0224 - binary_accuracy: 0.9932 - val_loss: 0.3244 - val_binary_accuracy: 0.9527\n",
      "385/385 [==============================] - 0s 324us/step\n",
      "Fold 2 :\n",
      "\n",
      "Train on 2635 samples, validate on 379 samples\n",
      "Epoch 1/30\n",
      "2635/2635 [==============================] - 9s 3ms/step - loss: 0.1705 - binary_accuracy: 0.9455 - val_loss: 0.1587 - val_binary_accuracy: 0.9462\n",
      "Epoch 2/30\n",
      "2635/2635 [==============================] - 5s 2ms/step - loss: 0.1372 - binary_accuracy: 0.9539 - val_loss: 0.1417 - val_binary_accuracy: 0.9529\n",
      "Epoch 3/30\n",
      "2635/2635 [==============================] - 5s 2ms/step - loss: 0.1139 - binary_accuracy: 0.9640 - val_loss: 0.1474 - val_binary_accuracy: 0.9553\n",
      "Epoch 4/30\n",
      "2635/2635 [==============================] - 5s 2ms/step - loss: 0.1014 - binary_accuracy: 0.9676 - val_loss: 0.1738 - val_binary_accuracy: 0.9515\n",
      "Epoch 5/30\n",
      "2635/2635 [==============================] - 5s 2ms/step - loss: 0.0892 - binary_accuracy: 0.9717 - val_loss: 0.1573 - val_binary_accuracy: 0.9524\n",
      "Epoch 6/30\n",
      "2635/2635 [==============================] - 5s 2ms/step - loss: 0.0802 - binary_accuracy: 0.9743 - val_loss: 0.1642 - val_binary_accuracy: 0.9541\n",
      "Epoch 7/30\n",
      "2635/2635 [==============================] - 5s 2ms/step - loss: 0.0774 - binary_accuracy: 0.9754 - val_loss: 0.1581 - val_binary_accuracy: 0.9549\n",
      "Epoch 8/30\n",
      "2635/2635 [==============================] - 5s 2ms/step - loss: 0.0664 - binary_accuracy: 0.9791 - val_loss: 0.1850 - val_binary_accuracy: 0.9529\n",
      "Epoch 9/30\n",
      "2635/2635 [==============================] - 5s 2ms/step - loss: 0.0603 - binary_accuracy: 0.9808 - val_loss: 0.1916 - val_binary_accuracy: 0.9527\n",
      "Epoch 10/30\n",
      "2635/2635 [==============================] - 5s 2ms/step - loss: 0.0550 - binary_accuracy: 0.9827 - val_loss: 0.2181 - val_binary_accuracy: 0.9499\n",
      "Epoch 11/30\n",
      "2635/2635 [==============================] - 5s 2ms/step - loss: 0.0499 - binary_accuracy: 0.9841 - val_loss: 0.2366 - val_binary_accuracy: 0.9487\n",
      "Epoch 12/30\n",
      "2635/2635 [==============================] - 5s 2ms/step - loss: 0.0456 - binary_accuracy: 0.9853 - val_loss: 0.2846 - val_binary_accuracy: 0.9496\n",
      "Epoch 13/30\n",
      "2635/2635 [==============================] - 5s 2ms/step - loss: 0.0420 - binary_accuracy: 0.9868 - val_loss: 0.2456 - val_binary_accuracy: 0.9485\n",
      "Epoch 14/30\n",
      "2635/2635 [==============================] - 5s 2ms/step - loss: 0.0442 - binary_accuracy: 0.9863 - val_loss: 0.2460 - val_binary_accuracy: 0.9535\n",
      "Epoch 15/30\n",
      "2635/2635 [==============================] - 5s 2ms/step - loss: 0.0394 - binary_accuracy: 0.9873 - val_loss: 0.2837 - val_binary_accuracy: 0.9505\n",
      "Epoch 16/30\n",
      "2635/2635 [==============================] - 5s 2ms/step - loss: 0.0378 - binary_accuracy: 0.9886 - val_loss: 0.2862 - val_binary_accuracy: 0.9516\n",
      "Epoch 17/30\n",
      "2635/2635 [==============================] - 5s 2ms/step - loss: 0.0369 - binary_accuracy: 0.9892 - val_loss: 0.2547 - val_binary_accuracy: 0.9515\n",
      "Epoch 18/30\n",
      "2635/2635 [==============================] - 5s 2ms/step - loss: 0.0325 - binary_accuracy: 0.9899 - val_loss: 0.3218 - val_binary_accuracy: 0.9484\n",
      "Epoch 19/30\n",
      "2635/2635 [==============================] - 5s 2ms/step - loss: 0.0314 - binary_accuracy: 0.9903 - val_loss: 0.2751 - val_binary_accuracy: 0.9524\n",
      "Epoch 20/30\n",
      "2635/2635 [==============================] - 6s 2ms/step - loss: 0.0293 - binary_accuracy: 0.9908 - val_loss: 0.2956 - val_binary_accuracy: 0.9496\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2635/2635 [==============================] - 5s 2ms/step - loss: 0.0319 - binary_accuracy: 0.9902 - val_loss: 0.2553 - val_binary_accuracy: 0.9518\n",
      "Epoch 22/30\n",
      "2635/2635 [==============================] - 5s 2ms/step - loss: 0.0315 - binary_accuracy: 0.9907 - val_loss: 0.3049 - val_binary_accuracy: 0.9509\n",
      "Epoch 23/30\n",
      "2635/2635 [==============================] - 5s 2ms/step - loss: 0.0277 - binary_accuracy: 0.9913 - val_loss: 0.3295 - val_binary_accuracy: 0.9480\n",
      "Epoch 24/30\n",
      "2635/2635 [==============================] - 5s 2ms/step - loss: 0.0254 - binary_accuracy: 0.9924 - val_loss: 0.3292 - val_binary_accuracy: 0.9459\n",
      "Epoch 25/30\n",
      "2635/2635 [==============================] - 5s 2ms/step - loss: 0.0268 - binary_accuracy: 0.9918 - val_loss: 0.3493 - val_binary_accuracy: 0.9496\n",
      "Epoch 26/30\n",
      "2635/2635 [==============================] - 5s 2ms/step - loss: 0.0245 - binary_accuracy: 0.9925 - val_loss: 0.2716 - val_binary_accuracy: 0.9521\n",
      "Epoch 27/30\n",
      "2635/2635 [==============================] - 5s 2ms/step - loss: 0.0248 - binary_accuracy: 0.9927 - val_loss: 0.3253 - val_binary_accuracy: 0.9491\n",
      "Epoch 28/30\n",
      "2635/2635 [==============================] - 5s 2ms/step - loss: 0.0231 - binary_accuracy: 0.9929 - val_loss: 0.3373 - val_binary_accuracy: 0.9480\n",
      "Epoch 29/30\n",
      "2635/2635 [==============================] - 5s 2ms/step - loss: 0.0236 - binary_accuracy: 0.9930 - val_loss: 0.3351 - val_binary_accuracy: 0.9516\n",
      "Epoch 30/30\n",
      "2635/2635 [==============================] - 5s 2ms/step - loss: 0.0209 - binary_accuracy: 0.9933 - val_loss: 0.3643 - val_binary_accuracy: 0.9507\n",
      "379/379 [==============================] - 0s 308us/step\n",
      "Fold 3 :\n",
      "\n",
      "Train on 2637 samples, validate on 377 samples\n",
      "Epoch 1/30\n",
      "2637/2637 [==============================] - 9s 3ms/step - loss: 0.1697 - binary_accuracy: 0.9461 - val_loss: 0.1532 - val_binary_accuracy: 0.9499\n",
      "Epoch 2/30\n",
      "2637/2637 [==============================] - 5s 2ms/step - loss: 0.1364 - binary_accuracy: 0.9553 - val_loss: 0.1337 - val_binary_accuracy: 0.9542\n",
      "Epoch 3/30\n",
      "2637/2637 [==============================] - 5s 2ms/step - loss: 0.1188 - binary_accuracy: 0.9613 - val_loss: 0.1266 - val_binary_accuracy: 0.9584\n",
      "Epoch 4/30\n",
      "2637/2637 [==============================] - 5s 2ms/step - loss: 0.1051 - binary_accuracy: 0.9660 - val_loss: 0.1191 - val_binary_accuracy: 0.9579\n",
      "Epoch 5/30\n",
      "2637/2637 [==============================] - 5s 2ms/step - loss: 0.0946 - binary_accuracy: 0.9700 - val_loss: 0.1329 - val_binary_accuracy: 0.9574\n",
      "Epoch 6/30\n",
      "2637/2637 [==============================] - 5s 2ms/step - loss: 0.0837 - binary_accuracy: 0.9727 - val_loss: 0.1388 - val_binary_accuracy: 0.9561\n",
      "Epoch 7/30\n",
      "2637/2637 [==============================] - 5s 2ms/step - loss: 0.0771 - binary_accuracy: 0.9753 - val_loss: 0.1433 - val_binary_accuracy: 0.9567\n",
      "Epoch 8/30\n",
      "2637/2637 [==============================] - 5s 2ms/step - loss: 0.0670 - binary_accuracy: 0.9788 - val_loss: 0.1505 - val_binary_accuracy: 0.9577\n",
      "Epoch 9/30\n",
      "2637/2637 [==============================] - 5s 2ms/step - loss: 0.0671 - binary_accuracy: 0.9792 - val_loss: 0.1621 - val_binary_accuracy: 0.9564\n",
      "Epoch 10/30\n",
      "2637/2637 [==============================] - 5s 2ms/step - loss: 0.0561 - binary_accuracy: 0.9823 - val_loss: 0.1611 - val_binary_accuracy: 0.9576s: 0.0530\n",
      "Epoch 11/30\n",
      "2637/2637 [==============================] - 5s 2ms/step - loss: 0.0518 - binary_accuracy: 0.9836 - val_loss: 0.1897 - val_binary_accuracy: 0.9587\n",
      "Epoch 12/30\n",
      "2637/2637 [==============================] - 5s 2ms/step - loss: 0.0486 - binary_accuracy: 0.9843 - val_loss: 0.1977 - val_binary_accuracy: 0.9571\n",
      "Epoch 13/30\n",
      "2637/2637 [==============================] - 5s 2ms/step - loss: 0.0479 - binary_accuracy: 0.9847 - val_loss: 0.1974 - val_binary_accuracy: 0.9565\n",
      "Epoch 14/30\n",
      "2637/2637 [==============================] - 5s 2ms/step - loss: 0.0453 - binary_accuracy: 0.9862 - val_loss: 0.2217 - val_binary_accuracy: 0.9551\n",
      "Epoch 15/30\n",
      "2637/2637 [==============================] - 5s 2ms/step - loss: 0.0439 - binary_accuracy: 0.9870 - val_loss: 0.2079 - val_binary_accuracy: 0.9568\n",
      "Epoch 16/30\n",
      "2637/2637 [==============================] - 5s 2ms/step - loss: 0.0388 - binary_accuracy: 0.9882 - val_loss: 0.2209 - val_binary_accuracy: 0.9546\n",
      "Epoch 17/30\n",
      "2637/2637 [==============================] - 5s 2ms/step - loss: 0.0354 - binary_accuracy: 0.9886 - val_loss: 0.2519 - val_binary_accuracy: 0.9567\n",
      "Epoch 18/30\n",
      "2637/2637 [==============================] - 5s 2ms/step - loss: 0.0351 - binary_accuracy: 0.9887 - val_loss: 0.2269 - val_binary_accuracy: 0.9570\n",
      "Epoch 19/30\n",
      "2637/2637 [==============================] - 5s 2ms/step - loss: 0.0324 - binary_accuracy: 0.9902 - val_loss: 0.2100 - val_binary_accuracy: 0.9562\n",
      "Epoch 20/30\n",
      "2637/2637 [==============================] - 5s 2ms/step - loss: 0.0297 - binary_accuracy: 0.9908 - val_loss: 0.2655 - val_binary_accuracy: 0.9548\n",
      "Epoch 21/30\n",
      "2637/2637 [==============================] - 5s 2ms/step - loss: 0.0328 - binary_accuracy: 0.9902 - val_loss: 0.2713 - val_binary_accuracy: 0.9534\n",
      "Epoch 22/30\n",
      "2637/2637 [==============================] - 5s 2ms/step - loss: 0.0283 - binary_accuracy: 0.9910 - val_loss: 0.2556 - val_binary_accuracy: 0.9549\n",
      "Epoch 23/30\n",
      "2637/2637 [==============================] - 5s 2ms/step - loss: 0.0309 - binary_accuracy: 0.9905 - val_loss: 0.2261 - val_binary_accuracy: 0.9540\n",
      "Epoch 24/30\n",
      "2637/2637 [==============================] - 5s 2ms/step - loss: 0.0282 - binary_accuracy: 0.9915 - val_loss: 0.2799 - val_binary_accuracy: 0.9561\n",
      "Epoch 25/30\n",
      "2637/2637 [==============================] - 5s 2ms/step - loss: 0.0279 - binary_accuracy: 0.9915 - val_loss: 0.2882 - val_binary_accuracy: 0.9555\n",
      "Epoch 26/30\n",
      "2637/2637 [==============================] - 5s 2ms/step - loss: 0.0287 - binary_accuracy: 0.9913 - val_loss: 0.2719 - val_binary_accuracy: 0.9559\n",
      "Epoch 27/30\n",
      "2637/2637 [==============================] - 5s 2ms/step - loss: 0.0271 - binary_accuracy: 0.9919 - val_loss: 0.2515 - val_binary_accuracy: 0.9567\n",
      "Epoch 28/30\n",
      "2637/2637 [==============================] - 5s 2ms/step - loss: 0.0255 - binary_accuracy: 0.9930 - val_loss: 0.2943 - val_binary_accuracy: 0.9542\n",
      "Epoch 29/30\n",
      "2637/2637 [==============================] - 5s 2ms/step - loss: 0.0280 - binary_accuracy: 0.9914 - val_loss: 0.2271 - val_binary_accuracy: 0.9573\n",
      "Epoch 30/30\n",
      "2637/2637 [==============================] - 5s 2ms/step - loss: 0.0227 - binary_accuracy: 0.9930 - val_loss: 0.2916 - val_binary_accuracy: 0.9556\n",
      "377/377 [==============================] - 0s 335us/step\n",
      "Fold 4 :\n",
      "\n",
      "Train on 2638 samples, validate on 376 samples\n",
      "Epoch 1/30\n",
      "2638/2638 [==============================] - 9s 3ms/step - loss: 0.1686 - binary_accuracy: 0.9459 - val_loss: 0.1475 - val_binary_accuracy: 0.9483\n",
      "Epoch 2/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.1353 - binary_accuracy: 0.9543 - val_loss: 0.1265 - val_binary_accuracy: 0.9572\n",
      "Epoch 3/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.1186 - binary_accuracy: 0.9611 - val_loss: 0.1230 - val_binary_accuracy: 0.9604\n",
      "Epoch 4/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.1045 - binary_accuracy: 0.9666 - val_loss: 0.1262 - val_binary_accuracy: 0.9601\n",
      "Epoch 5/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0943 - binary_accuracy: 0.9690 - val_loss: 0.1333 - val_binary_accuracy: 0.9607\n",
      "Epoch 6/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0851 - binary_accuracy: 0.9718 - val_loss: 0.1503 - val_binary_accuracy: 0.9629\n",
      "Epoch 7/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0771 - binary_accuracy: 0.9754 - val_loss: 0.1520 - val_binary_accuracy: 0.9611\n",
      "Epoch 8/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0726 - binary_accuracy: 0.9769 - val_loss: 0.1486 - val_binary_accuracy: 0.9628\n",
      "Epoch 9/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0642 - binary_accuracy: 0.9791 - val_loss: 0.1713 - val_binary_accuracy: 0.9619\n",
      "Epoch 10/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0597 - binary_accuracy: 0.9805 - val_loss: 0.1575 - val_binary_accuracy: 0.9632\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0563 - binary_accuracy: 0.9821 - val_loss: 0.1723 - val_binary_accuracy: 0.9641\n",
      "Epoch 12/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0522 - binary_accuracy: 0.9832 - val_loss: 0.1816 - val_binary_accuracy: 0.9639\n",
      "Epoch 13/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0493 - binary_accuracy: 0.9839 - val_loss: 0.1695 - val_binary_accuracy: 0.9622\n",
      "Epoch 14/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0456 - binary_accuracy: 0.9855 - val_loss: 0.1964 - val_binary_accuracy: 0.9620\n",
      "Epoch 15/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0434 - binary_accuracy: 0.9869 - val_loss: 0.2193 - val_binary_accuracy: 0.9645\n",
      "Epoch 16/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0425 - binary_accuracy: 0.9867 - val_loss: 0.1890 - val_binary_accuracy: 0.9605\n",
      "Epoch 17/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0417 - binary_accuracy: 0.9869 - val_loss: 0.2007 - val_binary_accuracy: 0.9634\n",
      "Epoch 18/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0366 - binary_accuracy: 0.9881 - val_loss: 0.2370 - val_binary_accuracy: 0.9639\n",
      "Epoch 19/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0353 - binary_accuracy: 0.9889 - val_loss: 0.2055 - val_binary_accuracy: 0.9617\n",
      "Epoch 20/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0344 - binary_accuracy: 0.9896 - val_loss: 0.2044 - val_binary_accuracy: 0.9625\n",
      "Epoch 21/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0303 - binary_accuracy: 0.9904 - val_loss: 0.2702 - val_binary_accuracy: 0.9648\n",
      "Epoch 22/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0331 - binary_accuracy: 0.9899 - val_loss: 0.2177 - val_binary_accuracy: 0.9631\n",
      "Epoch 23/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0311 - binary_accuracy: 0.9908 - val_loss: 0.2558 - val_binary_accuracy: 0.9634\n",
      "Epoch 24/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0299 - binary_accuracy: 0.9908 - val_loss: 0.2397 - val_binary_accuracy: 0.9638\n",
      "Epoch 25/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0295 - binary_accuracy: 0.9907 - val_loss: 0.2245 - val_binary_accuracy: 0.9648\n",
      "Epoch 26/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0259 - binary_accuracy: 0.9917 - val_loss: 0.2317 - val_binary_accuracy: 0.9638\n",
      "Epoch 27/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0272 - binary_accuracy: 0.9917 - val_loss: 0.2500 - val_binary_accuracy: 0.9642\n",
      "Epoch 28/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0307 - binary_accuracy: 0.9906 - val_loss: 0.2109 - val_binary_accuracy: 0.9625\n",
      "Epoch 29/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0258 - binary_accuracy: 0.9917 - val_loss: 0.2322 - val_binary_accuracy: 0.9605\n",
      "Epoch 30/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0266 - binary_accuracy: 0.9916 - val_loss: 0.2469 - val_binary_accuracy: 0.9625\n",
      "376/376 [==============================] - 0s 311us/step\n",
      "Fold 5 :\n",
      "\n",
      "Train on 2638 samples, validate on 376 samples\n",
      "Epoch 1/30\n",
      "2638/2638 [==============================] - 9s 3ms/step - loss: 0.1669 - binary_accuracy: 0.9463 - val_loss: 0.1506 - val_binary_accuracy: 0.9514\n",
      "Epoch 2/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.1329 - binary_accuracy: 0.9556 - val_loss: 0.1374 - val_binary_accuracy: 0.9542\n",
      "Epoch 3/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.1160 - binary_accuracy: 0.9608 - val_loss: 0.1470 - val_binary_accuracy: 0.9555\n",
      "Epoch 4/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.1023 - binary_accuracy: 0.9669 - val_loss: 0.1473 - val_binary_accuracy: 0.9570\n",
      "Epoch 5/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0918 - binary_accuracy: 0.9704 - val_loss: 0.1486 - val_binary_accuracy: 0.9557\n",
      "Epoch 6/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0828 - binary_accuracy: 0.9732 - val_loss: 0.1591 - val_binary_accuracy: 0.9542\n",
      "Epoch 7/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0768 - binary_accuracy: 0.9750 - val_loss: 0.1594 - val_binary_accuracy: 0.9570\n",
      "Epoch 8/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0714 - binary_accuracy: 0.9770 - val_loss: 0.1582 - val_binary_accuracy: 0.9591\n",
      "Epoch 9/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0634 - binary_accuracy: 0.9788 - val_loss: 0.1615 - val_binary_accuracy: 0.9583\n",
      "Epoch 10/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0597 - binary_accuracy: 0.9809 - val_loss: 0.1559 - val_binary_accuracy: 0.9608\n",
      "Epoch 11/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0526 - binary_accuracy: 0.9832 - val_loss: 0.1810 - val_binary_accuracy: 0.9586\n",
      "Epoch 12/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0507 - binary_accuracy: 0.9839 - val_loss: 0.1884 - val_binary_accuracy: 0.9572\n",
      "Epoch 13/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0509 - binary_accuracy: 0.9838 - val_loss: 0.1860 - val_binary_accuracy: 0.9579\n",
      "Epoch 14/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0446 - binary_accuracy: 0.9854 - val_loss: 0.1827 - val_binary_accuracy: 0.9592\n",
      "Epoch 15/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0441 - binary_accuracy: 0.9863 - val_loss: 0.1898 - val_binary_accuracy: 0.9585\n",
      "Epoch 16/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0401 - binary_accuracy: 0.9871 - val_loss: 0.2227 - val_binary_accuracy: 0.9538\n",
      "Epoch 17/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0375 - binary_accuracy: 0.9884 - val_loss: 0.1998 - val_binary_accuracy: 0.9573\n",
      "Epoch 18/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0366 - binary_accuracy: 0.9887 - val_loss: 0.2261 - val_binary_accuracy: 0.9583\n",
      "Epoch 19/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0335 - binary_accuracy: 0.9889 - val_loss: 0.2088 - val_binary_accuracy: 0.9582\n",
      "Epoch 20/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0313 - binary_accuracy: 0.9903 - val_loss: 0.2388 - val_binary_accuracy: 0.9572\n",
      "Epoch 21/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0323 - binary_accuracy: 0.9894 - val_loss: 0.2591 - val_binary_accuracy: 0.9557\n",
      "Epoch 22/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0313 - binary_accuracy: 0.9906 - val_loss: 0.2296 - val_binary_accuracy: 0.9548\n",
      "Epoch 23/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0329 - binary_accuracy: 0.9904 - val_loss: 0.2411 - val_binary_accuracy: 0.9555\n",
      "Epoch 24/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0313 - binary_accuracy: 0.9904 - val_loss: 0.2473 - val_binary_accuracy: 0.9567\n",
      "Epoch 25/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0290 - binary_accuracy: 0.9915 - val_loss: 0.2829 - val_binary_accuracy: 0.9549\n",
      "Epoch 26/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0257 - binary_accuracy: 0.9922 - val_loss: 0.2944 - val_binary_accuracy: 0.9561\n",
      "Epoch 27/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0289 - binary_accuracy: 0.9916 - val_loss: 0.2396 - val_binary_accuracy: 0.9570\n",
      "Epoch 28/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0260 - binary_accuracy: 0.9922 - val_loss: 0.2975 - val_binary_accuracy: 0.9546\n",
      "Epoch 29/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0261 - binary_accuracy: 0.9922 - val_loss: 0.2525 - val_binary_accuracy: 0.9549\n",
      "Epoch 30/30\n",
      "2638/2638 [==============================] - 5s 2ms/step - loss: 0.0212 - binary_accuracy: 0.9932 - val_loss: 0.2889 - val_binary_accuracy: 0.9543\n",
      "376/376 [==============================] - 0s 325us/step\n",
      "Fold 6 :\n",
      "\n",
      "Train on 2639 samples, validate on 375 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2639/2639 [==============================] - 9s 3ms/step - loss: 0.1670 - binary_accuracy: 0.9464 - val_loss: 0.1448 - val_binary_accuracy: 0.9507\n",
      "Epoch 2/30\n",
      "2639/2639 [==============================] - 5s 2ms/step - loss: 0.1371 - binary_accuracy: 0.9544 - val_loss: 0.1277 - val_binary_accuracy: 0.9570\n",
      "Epoch 3/30\n",
      "2639/2639 [==============================] - 5s 2ms/step - loss: 0.1155 - binary_accuracy: 0.9611 - val_loss: 0.1327 - val_binary_accuracy: 0.9582\n",
      "Epoch 4/30\n",
      "2639/2639 [==============================] - 5s 2ms/step - loss: 0.1028 - binary_accuracy: 0.9660 - val_loss: 0.1215 - val_binary_accuracy: 0.9616\n",
      "Epoch 5/30\n",
      "2639/2639 [==============================] - 5s 2ms/step - loss: 0.0971 - binary_accuracy: 0.9690 - val_loss: 0.1401 - val_binary_accuracy: 0.9615\n",
      "Epoch 6/30\n",
      "2639/2639 [==============================] - 5s 2ms/step - loss: 0.0871 - binary_accuracy: 0.9717 - val_loss: 0.1415 - val_binary_accuracy: 0.9630\n",
      "Epoch 7/30\n",
      "2639/2639 [==============================] - 5s 2ms/step - loss: 0.0799 - binary_accuracy: 0.9740 - val_loss: 0.1460 - val_binary_accuracy: 0.9594\n",
      "Epoch 8/30\n",
      "2639/2639 [==============================] - 5s 2ms/step - loss: 0.0702 - binary_accuracy: 0.9772 - val_loss: 0.1611 - val_binary_accuracy: 0.9606\n",
      "Epoch 9/30\n",
      "2639/2639 [==============================] - 5s 2ms/step - loss: 0.0661 - binary_accuracy: 0.9785 - val_loss: 0.1830 - val_binary_accuracy: 0.9604\n",
      "Epoch 10/30\n",
      "2639/2639 [==============================] - 5s 2ms/step - loss: 0.0583 - binary_accuracy: 0.9812 - val_loss: 0.1710 - val_binary_accuracy: 0.9618\n",
      "Epoch 11/30\n",
      "2639/2639 [==============================] - 5s 2ms/step - loss: 0.0557 - binary_accuracy: 0.9818 - val_loss: 0.1762 - val_binary_accuracy: 0.9607\n",
      "Epoch 12/30\n",
      "2639/2639 [==============================] - 5s 2ms/step - loss: 0.0503 - binary_accuracy: 0.9843 - val_loss: 0.1952 - val_binary_accuracy: 0.9613\n",
      "Epoch 13/30\n",
      "2639/2639 [==============================] - 5s 2ms/step - loss: 0.0433 - binary_accuracy: 0.9860 - val_loss: 0.2081 - val_binary_accuracy: 0.9606\n",
      "Epoch 14/30\n",
      "2639/2639 [==============================] - 5s 2ms/step - loss: 0.0441 - binary_accuracy: 0.9857 - val_loss: 0.2048 - val_binary_accuracy: 0.9618\n",
      "Epoch 15/30\n",
      "2639/2639 [==============================] - 6s 2ms/step - loss: 0.0443 - binary_accuracy: 0.9860 - val_loss: 0.2207 - val_binary_accuracy: 0.9607\n",
      "Epoch 16/30\n",
      "2639/2639 [==============================] - 6s 2ms/step - loss: 0.0410 - binary_accuracy: 0.9873 - val_loss: 0.1961 - val_binary_accuracy: 0.9599\n",
      "Epoch 17/30\n",
      "2639/2639 [==============================] - 6s 2ms/step - loss: 0.0393 - binary_accuracy: 0.9879 - val_loss: 0.2034 - val_binary_accuracy: 0.9612\n",
      "Epoch 18/30\n",
      "2639/2639 [==============================] - 6s 2ms/step - loss: 0.0396 - binary_accuracy: 0.9883 - val_loss: 0.2349 - val_binary_accuracy: 0.9609\n",
      "Epoch 19/30\n",
      "2639/2639 [==============================] - 6s 2ms/step - loss: 0.0356 - binary_accuracy: 0.9888 - val_loss: 0.2369 - val_binary_accuracy: 0.9616\n",
      "Epoch 20/30\n",
      "2639/2639 [==============================] - 5s 2ms/step - loss: 0.0317 - binary_accuracy: 0.9900 - val_loss: 0.2193 - val_binary_accuracy: 0.9603\n",
      "Epoch 21/30\n",
      "2639/2639 [==============================] - 5s 2ms/step - loss: 0.0291 - binary_accuracy: 0.9908 - val_loss: 0.2679 - val_binary_accuracy: 0.9625\n",
      "Epoch 22/30\n",
      "2639/2639 [==============================] - 5s 2ms/step - loss: 0.0291 - binary_accuracy: 0.9906 - val_loss: 0.2646 - val_binary_accuracy: 0.9600\n",
      "Epoch 23/30\n",
      "2639/2639 [==============================] - 5s 2ms/step - loss: 0.0312 - binary_accuracy: 0.9905 - val_loss: 0.2547 - val_binary_accuracy: 0.9596\n",
      "Epoch 24/30\n",
      "2639/2639 [==============================] - 6s 2ms/step - loss: 0.0282 - binary_accuracy: 0.9912 - val_loss: 0.2793 - val_binary_accuracy: 0.9604\n",
      "Epoch 25/30\n",
      "2639/2639 [==============================] - 6s 2ms/step - loss: 0.0274 - binary_accuracy: 0.9908 - val_loss: 0.2751 - val_binary_accuracy: 0.9613\n",
      "Epoch 26/30\n",
      "2639/2639 [==============================] - 5s 2ms/step - loss: 0.0320 - binary_accuracy: 0.9902 - val_loss: 0.2648 - val_binary_accuracy: 0.9606\n",
      "Epoch 27/30\n",
      "2639/2639 [==============================] - 5s 2ms/step - loss: 0.0303 - binary_accuracy: 0.9907 - val_loss: 0.2572 - val_binary_accuracy: 0.9622\n",
      "Epoch 28/30\n",
      "2639/2639 [==============================] - 7s 3ms/step - loss: 0.0286 - binary_accuracy: 0.9916 - val_loss: 0.2754 - val_binary_accuracy: 0.9610\n",
      "Epoch 29/30\n",
      "2639/2639 [==============================] - 6s 2ms/step - loss: 0.0290 - binary_accuracy: 0.9917 - val_loss: 0.2623 - val_binary_accuracy: 0.9606\n",
      "Epoch 30/30\n",
      "2639/2639 [==============================] - 6s 2ms/step - loss: 0.0256 - binary_accuracy: 0.9919 - val_loss: 0.2948 - val_binary_accuracy: 0.9615\n",
      "375/375 [==============================] - 0s 404us/step\n",
      "Fold 7 :\n",
      "\n",
      "Train on 2641 samples, validate on 373 samples\n",
      "Epoch 1/30\n",
      "2641/2641 [==============================] - 11s 4ms/step - loss: 0.1689 - binary_accuracy: 0.9457 - val_loss: 0.1488 - val_binary_accuracy: 0.9516\n",
      "Epoch 2/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.1357 - binary_accuracy: 0.9554 - val_loss: 0.1153 - val_binary_accuracy: 0.9617\n",
      "Epoch 3/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.1173 - binary_accuracy: 0.9622 - val_loss: 0.1212 - val_binary_accuracy: 0.9586\n",
      "Epoch 4/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.1026 - binary_accuracy: 0.9673 - val_loss: 0.1196 - val_binary_accuracy: 0.9617\n",
      "Epoch 5/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.0951 - binary_accuracy: 0.9694 - val_loss: 0.1221 - val_binary_accuracy: 0.9614\n",
      "Epoch 6/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.0858 - binary_accuracy: 0.9718 - val_loss: 0.1328 - val_binary_accuracy: 0.9604\n",
      "Epoch 7/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.0788 - binary_accuracy: 0.9743 - val_loss: 0.1594 - val_binary_accuracy: 0.9608\n",
      "Epoch 8/30\n",
      "2641/2641 [==============================] - ETA: 0s - loss: 0.0742 - binary_accuracy: 0.976 - 6s 2ms/step - loss: 0.0741 - binary_accuracy: 0.9767 - val_loss: 0.1527 - val_binary_accuracy: 0.9625\n",
      "Epoch 9/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.0664 - binary_accuracy: 0.9783 - val_loss: 0.1536 - val_binary_accuracy: 0.9622\n",
      "Epoch 10/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.0596 - binary_accuracy: 0.9803 - val_loss: 0.1703 - val_binary_accuracy: 0.9613\n",
      "Epoch 11/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.0564 - binary_accuracy: 0.9816 - val_loss: 0.1804 - val_binary_accuracy: 0.9619\n",
      "Epoch 12/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.0556 - binary_accuracy: 0.9819 - val_loss: 0.1876 - val_binary_accuracy: 0.9625\n",
      "Epoch 13/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.0504 - binary_accuracy: 0.9847 - val_loss: 0.2016 - val_binary_accuracy: 0.9611\n",
      "Epoch 14/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.0471 - binary_accuracy: 0.9854 - val_loss: 0.1871 - val_binary_accuracy: 0.9614\n",
      "Epoch 15/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.0399 - binary_accuracy: 0.9873 - val_loss: 0.2262 - val_binary_accuracy: 0.9622\n",
      "Epoch 16/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.0421 - binary_accuracy: 0.9869 - val_loss: 0.2293 - val_binary_accuracy: 0.9628\n",
      "Epoch 17/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.0381 - binary_accuracy: 0.9884 - val_loss: 0.2584 - val_binary_accuracy: 0.9601\n",
      "Epoch 18/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.0348 - binary_accuracy: 0.9887 - val_loss: 0.2589 - val_binary_accuracy: 0.9608\n",
      "Epoch 19/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.0357 - binary_accuracy: 0.9888 - val_loss: 0.2505 - val_binary_accuracy: 0.9626\n",
      "Epoch 20/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.0337 - binary_accuracy: 0.9891 - val_loss: 0.2572 - val_binary_accuracy: 0.9628\n",
      "Epoch 21/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.0352 - binary_accuracy: 0.9895 - val_loss: 0.2792 - val_binary_accuracy: 0.9602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30\n",
      "2641/2641 [==============================] - 5s 2ms/step - loss: 0.0327 - binary_accuracy: 0.9899 - val_loss: 0.2582 - val_binary_accuracy: 0.9599\n",
      "Epoch 23/30\n",
      "2641/2641 [==============================] - 5s 2ms/step - loss: 0.0303 - binary_accuracy: 0.9910 - val_loss: 0.2423 - val_binary_accuracy: 0.9595\n",
      "Epoch 24/30\n",
      "2641/2641 [==============================] - 5s 2ms/step - loss: 0.0288 - binary_accuracy: 0.9907 - val_loss: 0.2879 - val_binary_accuracy: 0.9620\n",
      "Epoch 25/30\n",
      "2641/2641 [==============================] - 5s 2ms/step - loss: 0.0315 - binary_accuracy: 0.9911 - val_loss: 0.2695 - val_binary_accuracy: 0.9608\n",
      "Epoch 26/30\n",
      "2641/2641 [==============================] - 5s 2ms/step - loss: 0.0271 - binary_accuracy: 0.9912 - val_loss: 0.2670 - val_binary_accuracy: 0.9605\n",
      "Epoch 27/30\n",
      "2641/2641 [==============================] - 5s 2ms/step - loss: 0.0267 - binary_accuracy: 0.9918 - val_loss: 0.2511 - val_binary_accuracy: 0.9577\n",
      "Epoch 28/30\n",
      "2641/2641 [==============================] - 5s 2ms/step - loss: 0.0255 - binary_accuracy: 0.9918 - val_loss: 0.3042 - val_binary_accuracy: 0.9581\n",
      "Epoch 29/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.0285 - binary_accuracy: 0.9918 - val_loss: 0.2582 - val_binary_accuracy: 0.9602\n",
      "Epoch 30/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.0249 - binary_accuracy: 0.9922 - val_loss: 0.3081 - val_binary_accuracy: 0.9586\n",
      "373/373 [==============================] - 0s 296us/step\n",
      "Fold 8 :\n",
      "\n",
      "Train on 2641 samples, validate on 373 samples\n",
      "Epoch 1/30\n",
      "2641/2641 [==============================] - 10s 4ms/step - loss: 0.1688 - binary_accuracy: 0.9456 - val_loss: 0.1505 - val_binary_accuracy: 0.9511\n",
      "Epoch 2/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.1393 - binary_accuracy: 0.9544 - val_loss: 0.1259 - val_binary_accuracy: 0.9577\n",
      "Epoch 3/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.1171 - binary_accuracy: 0.9619 - val_loss: 0.1247 - val_binary_accuracy: 0.9595\n",
      "Epoch 4/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.1059 - binary_accuracy: 0.9660 - val_loss: 0.1286 - val_binary_accuracy: 0.9595\n",
      "Epoch 5/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.0964 - binary_accuracy: 0.9687 - val_loss: 0.1268 - val_binary_accuracy: 0.9629\n",
      "Epoch 6/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.0859 - binary_accuracy: 0.9721 - val_loss: 0.1310 - val_binary_accuracy: 0.9626\n",
      "Epoch 7/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.0787 - binary_accuracy: 0.9740 - val_loss: 0.1343 - val_binary_accuracy: 0.9620\n",
      "Epoch 8/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.0736 - binary_accuracy: 0.9754 - val_loss: 0.1343 - val_binary_accuracy: 0.9632\n",
      "Epoch 9/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.0695 - binary_accuracy: 0.9772 - val_loss: 0.1570 - val_binary_accuracy: 0.9610\n",
      "Epoch 10/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.0605 - binary_accuracy: 0.9804 - val_loss: 0.1520 - val_binary_accuracy: 0.9626\n",
      "Epoch 11/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.0574 - binary_accuracy: 0.9815 - val_loss: 0.1513 - val_binary_accuracy: 0.9608\n",
      "Epoch 12/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.0523 - binary_accuracy: 0.9828 - val_loss: 0.1546 - val_binary_accuracy: 0.9619\n",
      "Epoch 13/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.0501 - binary_accuracy: 0.9840 - val_loss: 0.1775 - val_binary_accuracy: 0.9635\n",
      "Epoch 14/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.0458 - binary_accuracy: 0.9852 - val_loss: 0.1702 - val_binary_accuracy: 0.9611\n",
      "Epoch 15/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.0434 - binary_accuracy: 0.9860 - val_loss: 0.1771 - val_binary_accuracy: 0.9629\n",
      "Epoch 16/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.0412 - binary_accuracy: 0.9867 - val_loss: 0.1915 - val_binary_accuracy: 0.9611\n",
      "Epoch 17/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.0404 - binary_accuracy: 0.9874 - val_loss: 0.1742 - val_binary_accuracy: 0.9620\n",
      "Epoch 18/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.0350 - binary_accuracy: 0.9890 - val_loss: 0.2083 - val_binary_accuracy: 0.9604\n",
      "Epoch 19/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.0344 - binary_accuracy: 0.9894 - val_loss: 0.1949 - val_binary_accuracy: 0.9611\n",
      "Epoch 20/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.0335 - binary_accuracy: 0.9892 - val_loss: 0.2132 - val_binary_accuracy: 0.9604\n",
      "Epoch 21/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.0343 - binary_accuracy: 0.9897 - val_loss: 0.2005 - val_binary_accuracy: 0.9619\n",
      "Epoch 22/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.0352 - binary_accuracy: 0.9891 - val_loss: 0.2059 - val_binary_accuracy: 0.9611\n",
      "Epoch 23/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.0317 - binary_accuracy: 0.9905 - val_loss: 0.2076 - val_binary_accuracy: 0.9610\n",
      "Epoch 24/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.0268 - binary_accuracy: 0.9912 - val_loss: 0.2435 - val_binary_accuracy: 0.9617\n",
      "Epoch 25/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.0283 - binary_accuracy: 0.9912 - val_loss: 0.2328 - val_binary_accuracy: 0.9599\n",
      "Epoch 26/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.0265 - binary_accuracy: 0.9918 - val_loss: 0.2204 - val_binary_accuracy: 0.9605\n",
      "Epoch 27/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.0271 - binary_accuracy: 0.9915 - val_loss: 0.2365 - val_binary_accuracy: 0.9632\n",
      "Epoch 28/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.0259 - binary_accuracy: 0.9920 - val_loss: 0.2576 - val_binary_accuracy: 0.9604\n",
      "Epoch 29/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.0260 - binary_accuracy: 0.9923 - val_loss: 0.2375 - val_binary_accuracy: 0.9641\n",
      "Epoch 30/30\n",
      "2641/2641 [==============================] - 6s 2ms/step - loss: 0.0253 - binary_accuracy: 0.9922 - val_loss: 0.2311 - val_binary_accuracy: 0.9641\n",
      "373/373 [==============================] - 0s 314us/step\n"
     ]
    }
   ],
   "source": [
    "#k=8, fungsi aktivasi=ReLU, nilai dropout=0.4\n",
    "kf = StratifiedKFold(n_splits=8, random_state=None, shuffle=False)\n",
    "val_loss_cv = []\n",
    "val_acc_cv = []\n",
    "j = 0\n",
    "for train_index, test_index in kf.split(X,z):\n",
    "    j+=1\n",
    "    print(f\"Fold {j} :\")\n",
    "    print(\"\")\n",
    "    X_train,X_test = X.iloc[train_index,:],X.iloc[test_index,:]\n",
    "    y_train,y_test = y.iloc[train_index,:],y.iloc[test_index,:]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim=X_train.shape[1], units=463,\n",
    "                     kernel_initializer='normal', bias_initializer='zeros'))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    for i in range(0, 6):\n",
    "        model.add(Dense(units=463, kernel_initializer='normal',\n",
    "                         bias_initializer='zeros'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(.4))\n",
    "\n",
    "    model.add(Dense(units=18))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
    "    model.fit(X_train, y_train,batch_size=24,epochs=30,verbose=1,validation_data=(X_test, y_test))\n",
    "    score = model.evaluate(X_test, y_test, verbose=1)\n",
    "    val_loss_cv.append(score[0])\n",
    "    val_acc_cv.append(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss_cv : [0.324379429685605, 0.3642561526128673, 0.2915547774704445, 0.24693766489942023, 0.28886442647335375, 0.2948290330966314, 0.3081225204323955, 0.23113355084494674]\n",
      "mean_val_loss_cv : 0.29375969443945804\n",
      "val_acc_cv : [0.9526695443438246, 0.9507475581835946, 0.9556439681774109, 0.9624704591771389, 0.95434396444483, 0.9614814659754435, 0.9585939703294483, 0.9641048494356886]\n",
      "mean_val_acc_cv : 0.9575069725084224\n"
     ]
    }
   ],
   "source": [
    "print(f\"val_loss_cv : {val_loss_cv}\")\n",
    "print(f\"mean_val_loss_cv : {np.mean(val_loss_cv)}\")\n",
    "print(f\"val_acc_cv : {val_acc_cv}\")\n",
    "print(f\"mean_val_acc_cv : {np.mean(val_acc_cv)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=9.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 :\n",
      "\n",
      "Train on 2672 samples, validate on 342 samples\n",
      "Epoch 1/30\n",
      "2672/2672 [==============================] - 11s 4ms/step - loss: 0.1700 - binary_accuracy: 0.9457 - val_loss: 0.1502 - val_binary_accuracy: 0.9500\n",
      "Epoch 2/30\n",
      "2672/2672 [==============================] - 6s 2ms/step - loss: 0.1384 - binary_accuracy: 0.9540 - val_loss: 0.1303 - val_binary_accuracy: 0.9566\n",
      "Epoch 3/30\n",
      "2672/2672 [==============================] - 6s 2ms/step - loss: 0.1166 - binary_accuracy: 0.9617 - val_loss: 0.1306 - val_binary_accuracy: 0.9573\n",
      "Epoch 4/30\n",
      "2672/2672 [==============================] - 6s 2ms/step - loss: 0.1049 - binary_accuracy: 0.9665 - val_loss: 0.1252 - val_binary_accuracy: 0.9604\n",
      "Epoch 5/30\n",
      "2672/2672 [==============================] - 6s 2ms/step - loss: 0.0917 - binary_accuracy: 0.9707 - val_loss: 0.1382 - val_binary_accuracy: 0.9596\n",
      "Epoch 6/30\n",
      "2672/2672 [==============================] - 6s 2ms/step - loss: 0.0810 - binary_accuracy: 0.9744 - val_loss: 0.1443 - val_binary_accuracy: 0.9574\n",
      "Epoch 7/30\n",
      "2672/2672 [==============================] - 6s 2ms/step - loss: 0.0754 - binary_accuracy: 0.9757 - val_loss: 0.1500 - val_binary_accuracy: 0.9558\n",
      "Epoch 8/30\n",
      "2672/2672 [==============================] - 6s 2ms/step - loss: 0.0695 - binary_accuracy: 0.9779 - val_loss: 0.1464 - val_binary_accuracy: 0.9592\n",
      "Epoch 9/30\n",
      "2672/2672 [==============================] - 6s 2ms/step - loss: 0.0619 - binary_accuracy: 0.9794 - val_loss: 0.1513 - val_binary_accuracy: 0.9560\n",
      "Epoch 10/30\n",
      "2672/2672 [==============================] - 6s 2ms/step - loss: 0.0553 - binary_accuracy: 0.9821 - val_loss: 0.1599 - val_binary_accuracy: 0.9561\n",
      "Epoch 11/30\n",
      "2672/2672 [==============================] - 6s 2ms/step - loss: 0.0508 - binary_accuracy: 0.9839 - val_loss: 0.1635 - val_binary_accuracy: 0.9550\n",
      "Epoch 12/30\n",
      "2672/2672 [==============================] - 6s 2ms/step - loss: 0.0479 - binary_accuracy: 0.9848 - val_loss: 0.1788 - val_binary_accuracy: 0.9540\n",
      "Epoch 13/30\n",
      "2672/2672 [==============================] - 6s 2ms/step - loss: 0.0468 - binary_accuracy: 0.9854 - val_loss: 0.1943 - val_binary_accuracy: 0.9535\n",
      "Epoch 14/30\n",
      "2672/2672 [==============================] - 6s 2ms/step - loss: 0.0429 - binary_accuracy: 0.9871 - val_loss: 0.2301 - val_binary_accuracy: 0.9529\n",
      "Epoch 15/30\n",
      "2672/2672 [==============================] - 6s 2ms/step - loss: 0.0413 - binary_accuracy: 0.9872 - val_loss: 0.2180 - val_binary_accuracy: 0.9532\n",
      "Epoch 16/30\n",
      "2672/2672 [==============================] - 6s 2ms/step - loss: 0.0397 - binary_accuracy: 0.9878 - val_loss: 0.2156 - val_binary_accuracy: 0.9553\n",
      "Epoch 17/30\n",
      "2672/2672 [==============================] - 6s 2ms/step - loss: 0.0366 - binary_accuracy: 0.9885 - val_loss: 0.2499 - val_binary_accuracy: 0.9529\n",
      "Epoch 18/30\n",
      "2672/2672 [==============================] - 6s 2ms/step - loss: 0.0366 - binary_accuracy: 0.9887 - val_loss: 0.2335 - val_binary_accuracy: 0.9531\n",
      "Epoch 19/30\n",
      "2672/2672 [==============================] - 6s 2ms/step - loss: 0.0357 - binary_accuracy: 0.9892 - val_loss: 0.2640 - val_binary_accuracy: 0.9526\n",
      "Epoch 20/30\n",
      "2672/2672 [==============================] - 6s 2ms/step - loss: 0.0321 - binary_accuracy: 0.9902 - val_loss: 0.2515 - val_binary_accuracy: 0.9516\n",
      "Epoch 21/30\n",
      "2672/2672 [==============================] - 6s 2ms/step - loss: 0.0304 - binary_accuracy: 0.9902 - val_loss: 0.2258 - val_binary_accuracy: 0.9550\n",
      "Epoch 22/30\n",
      "2672/2672 [==============================] - 6s 2ms/step - loss: 0.0327 - binary_accuracy: 0.9892 - val_loss: 0.2424 - val_binary_accuracy: 0.9524\n",
      "Epoch 23/30\n",
      "2672/2672 [==============================] - 6s 2ms/step - loss: 0.0284 - binary_accuracy: 0.9912 - val_loss: 0.2449 - val_binary_accuracy: 0.9534\n",
      "Epoch 24/30\n",
      "2672/2672 [==============================] - 6s 2ms/step - loss: 0.0285 - binary_accuracy: 0.9911 - val_loss: 0.3455 - val_binary_accuracy: 0.9475\n",
      "Epoch 25/30\n",
      "2672/2672 [==============================] - 6s 2ms/step - loss: 0.0277 - binary_accuracy: 0.9914 - val_loss: 0.2540 - val_binary_accuracy: 0.9532\n",
      "Epoch 26/30\n",
      "2672/2672 [==============================] - 6s 2ms/step - loss: 0.0278 - binary_accuracy: 0.9915 - val_loss: 0.2671 - val_binary_accuracy: 0.9542\n",
      "Epoch 27/30\n",
      "2672/2672 [==============================] - 6s 2ms/step - loss: 0.0251 - binary_accuracy: 0.9919 - val_loss: 0.3141 - val_binary_accuracy: 0.9498\n",
      "Epoch 28/30\n",
      "2672/2672 [==============================] - 6s 2ms/step - loss: 0.0227 - binary_accuracy: 0.9930 - val_loss: 0.2714 - val_binary_accuracy: 0.9516\n",
      "Epoch 29/30\n",
      "2672/2672 [==============================] - 6s 2ms/step - loss: 0.0217 - binary_accuracy: 0.9930 - val_loss: 0.3445 - val_binary_accuracy: 0.9509\n",
      "Epoch 30/30\n",
      "2672/2672 [==============================] - 6s 2ms/step - loss: 0.0203 - binary_accuracy: 0.9934 - val_loss: 0.3594 - val_binary_accuracy: 0.9495\n",
      "342/342 [==============================] - 0s 1ms/step\n",
      "Fold 2 :\n",
      "\n",
      "Train on 2674 samples, validate on 340 samples\n",
      "Epoch 1/30\n",
      "2674/2674 [==============================] - 11s 4ms/step - loss: 0.1685 - binary_accuracy: 0.9460 - val_loss: 0.1485 - val_binary_accuracy: 0.9521\n",
      "Epoch 2/30\n",
      "2674/2674 [==============================] - 6s 2ms/step - loss: 0.1332 - binary_accuracy: 0.9564 - val_loss: 0.1438 - val_binary_accuracy: 0.9518\n",
      "Epoch 3/30\n",
      "2674/2674 [==============================] - 6s 2ms/step - loss: 0.1154 - binary_accuracy: 0.9632 - val_loss: 0.1511 - val_binary_accuracy: 0.9513\n",
      "Epoch 4/30\n",
      "2674/2674 [==============================] - 6s 2ms/step - loss: 0.1010 - binary_accuracy: 0.9673 - val_loss: 0.1476 - val_binary_accuracy: 0.9523\n",
      "Epoch 5/30\n",
      "2674/2674 [==============================] - 6s 2ms/step - loss: 0.0903 - binary_accuracy: 0.9706 - val_loss: 0.1523 - val_binary_accuracy: 0.9529\n",
      "Epoch 6/30\n",
      "2674/2674 [==============================] - 6s 2ms/step - loss: 0.0798 - binary_accuracy: 0.9747 - val_loss: 0.1721 - val_binary_accuracy: 0.9515\n",
      "Epoch 7/30\n",
      "2674/2674 [==============================] - 6s 2ms/step - loss: 0.0737 - binary_accuracy: 0.9766 - val_loss: 0.2020 - val_binary_accuracy: 0.9526\n",
      "Epoch 8/30\n",
      "2674/2674 [==============================] - 6s 2ms/step - loss: 0.0654 - binary_accuracy: 0.9793 - val_loss: 0.2007 - val_binary_accuracy: 0.9489\n",
      "Epoch 9/30\n",
      "2674/2674 [==============================] - 6s 2ms/step - loss: 0.0596 - binary_accuracy: 0.9817 - val_loss: 0.1922 - val_binary_accuracy: 0.9495\n",
      "Epoch 10/30\n",
      "2674/2674 [==============================] - 6s 2ms/step - loss: 0.0531 - binary_accuracy: 0.9830 - val_loss: 0.2105 - val_binary_accuracy: 0.9495\n",
      "Epoch 11/30\n",
      "2674/2674 [==============================] - 6s 2ms/step - loss: 0.0487 - binary_accuracy: 0.9843 - val_loss: 0.2498 - val_binary_accuracy: 0.9493\n",
      "Epoch 12/30\n",
      "2674/2674 [==============================] - 6s 2ms/step - loss: 0.0456 - binary_accuracy: 0.9857 - val_loss: 0.2657 - val_binary_accuracy: 0.9462\n",
      "Epoch 13/30\n",
      "2674/2674 [==============================] - 6s 2ms/step - loss: 0.0445 - binary_accuracy: 0.9864 - val_loss: 0.2434 - val_binary_accuracy: 0.9479\n",
      "Epoch 14/30\n",
      "2674/2674 [==============================] - 6s 2ms/step - loss: 0.0416 - binary_accuracy: 0.9874 - val_loss: 0.2686 - val_binary_accuracy: 0.9471\n",
      "Epoch 15/30\n",
      "2674/2674 [==============================] - 6s 2ms/step - loss: 0.0365 - binary_accuracy: 0.9882 - val_loss: 0.3046 - val_binary_accuracy: 0.9472\n",
      "Epoch 16/30\n",
      "2674/2674 [==============================] - 6s 2ms/step - loss: 0.0321 - binary_accuracy: 0.9900 - val_loss: 0.2874 - val_binary_accuracy: 0.9471\n",
      "Epoch 17/30\n",
      "2674/2674 [==============================] - 6s 2ms/step - loss: 0.0321 - binary_accuracy: 0.9896 - val_loss: 0.3517 - val_binary_accuracy: 0.9458\n",
      "Epoch 18/30\n",
      "2674/2674 [==============================] - 6s 2ms/step - loss: 0.0380 - binary_accuracy: 0.9885 - val_loss: 0.3078 - val_binary_accuracy: 0.9467\n",
      "Epoch 19/30\n",
      "2674/2674 [==============================] - 6s 2ms/step - loss: 0.0353 - binary_accuracy: 0.9897 - val_loss: 0.2847 - val_binary_accuracy: 0.9484\n",
      "Epoch 20/30\n",
      "2674/2674 [==============================] - 6s 2ms/step - loss: 0.0310 - binary_accuracy: 0.9905 - val_loss: 0.3780 - val_binary_accuracy: 0.9454\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2674/2674 [==============================] - 6s 2ms/step - loss: 0.0305 - binary_accuracy: 0.9910 - val_loss: 0.3364 - val_binary_accuracy: 0.9485\n",
      "Epoch 22/30\n",
      "2674/2674 [==============================] - 5s 2ms/step - loss: 0.0318 - binary_accuracy: 0.9905 - val_loss: 0.2817 - val_binary_accuracy: 0.9484\n",
      "Epoch 23/30\n",
      "2674/2674 [==============================] - 5s 2ms/step - loss: 0.0263 - binary_accuracy: 0.9921 - val_loss: 0.3120 - val_binary_accuracy: 0.9490\n",
      "Epoch 24/30\n",
      "2674/2674 [==============================] - 5s 2ms/step - loss: 0.0283 - binary_accuracy: 0.9917 - val_loss: 0.3332 - val_binary_accuracy: 0.9489\n",
      "Epoch 25/30\n",
      "2674/2674 [==============================] - 5s 2ms/step - loss: 0.0245 - binary_accuracy: 0.9924 - val_loss: 0.3456 - val_binary_accuracy: 0.9444\n",
      "Epoch 26/30\n",
      "2674/2674 [==============================] - 5s 2ms/step - loss: 0.0246 - binary_accuracy: 0.9927 - val_loss: 0.3532 - val_binary_accuracy: 0.9444\n",
      "Epoch 27/30\n",
      "2674/2674 [==============================] - 5s 2ms/step - loss: 0.0280 - binary_accuracy: 0.9921 - val_loss: 0.3539 - val_binary_accuracy: 0.9461\n",
      "Epoch 28/30\n",
      "2674/2674 [==============================] - 5s 2ms/step - loss: 0.0236 - binary_accuracy: 0.9927 - val_loss: 0.3885 - val_binary_accuracy: 0.9475\n",
      "Epoch 29/30\n",
      "2674/2674 [==============================] - 5s 2ms/step - loss: 0.0262 - binary_accuracy: 0.9925 - val_loss: 0.3737 - val_binary_accuracy: 0.9474\n",
      "Epoch 30/30\n",
      "2674/2674 [==============================] - 5s 2ms/step - loss: 0.0224 - binary_accuracy: 0.9929 - val_loss: 0.4096 - val_binary_accuracy: 0.9444\n",
      "340/340 [==============================] - 0s 310us/step\n",
      "Fold 3 :\n",
      "\n",
      "Train on 2675 samples, validate on 339 samples\n",
      "Epoch 1/30\n",
      "2675/2675 [==============================] - 11s 4ms/step - loss: 0.1724 - binary_accuracy: 0.9451 - val_loss: 0.1593 - val_binary_accuracy: 0.9443\n",
      "Epoch 2/30\n",
      "2675/2675 [==============================] - 6s 2ms/step - loss: 0.1393 - binary_accuracy: 0.9545 - val_loss: 0.1341 - val_binary_accuracy: 0.9539\n",
      "Epoch 3/30\n",
      "2675/2675 [==============================] - 6s 2ms/step - loss: 0.1191 - binary_accuracy: 0.9610 - val_loss: 0.1245 - val_binary_accuracy: 0.9594\n",
      "Epoch 4/30\n",
      "2675/2675 [==============================] - 6s 2ms/step - loss: 0.1077 - binary_accuracy: 0.9655 - val_loss: 0.1288 - val_binary_accuracy: 0.9577\n",
      "Epoch 5/30\n",
      "2675/2675 [==============================] - 6s 2ms/step - loss: 0.0935 - binary_accuracy: 0.9701 - val_loss: 0.1237 - val_binary_accuracy: 0.9607\n",
      "Epoch 6/30\n",
      "2675/2675 [==============================] - 6s 2ms/step - loss: 0.0832 - binary_accuracy: 0.9726 - val_loss: 0.1362 - val_binary_accuracy: 0.9621\n",
      "Epoch 7/30\n",
      "2675/2675 [==============================] - 6s 2ms/step - loss: 0.0748 - binary_accuracy: 0.9758 - val_loss: 0.1361 - val_binary_accuracy: 0.9636\n",
      "Epoch 8/30\n",
      "2675/2675 [==============================] - 6s 2ms/step - loss: 0.0681 - binary_accuracy: 0.9780 - val_loss: 0.1556 - val_binary_accuracy: 0.9564\n",
      "Epoch 9/30\n",
      "2675/2675 [==============================] - 6s 2ms/step - loss: 0.0648 - binary_accuracy: 0.9797 - val_loss: 0.1569 - val_binary_accuracy: 0.9572\n",
      "Epoch 10/30\n",
      "2675/2675 [==============================] - 6s 2ms/step - loss: 0.0569 - binary_accuracy: 0.9818 - val_loss: 0.1705 - val_binary_accuracy: 0.9579\n",
      "Epoch 11/30\n",
      "2675/2675 [==============================] - 6s 2ms/step - loss: 0.0537 - binary_accuracy: 0.9832 - val_loss: 0.1821 - val_binary_accuracy: 0.9576\n",
      "Epoch 12/30\n",
      "2675/2675 [==============================] - 6s 2ms/step - loss: 0.0499 - binary_accuracy: 0.9842 - val_loss: 0.1660 - val_binary_accuracy: 0.9587\n",
      "Epoch 13/30\n",
      "2675/2675 [==============================] - 6s 2ms/step - loss: 0.0447 - binary_accuracy: 0.9857 - val_loss: 0.1640 - val_binary_accuracy: 0.9607\n",
      "Epoch 14/30\n",
      "2675/2675 [==============================] - 6s 2ms/step - loss: 0.0428 - binary_accuracy: 0.9866 - val_loss: 0.2135 - val_binary_accuracy: 0.9549\n",
      "Epoch 15/30\n",
      "2675/2675 [==============================] - 6s 2ms/step - loss: 0.0384 - binary_accuracy: 0.9880 - val_loss: 0.2248 - val_binary_accuracy: 0.9580\n",
      "Epoch 16/30\n",
      "2675/2675 [==============================] - 6s 2ms/step - loss: 0.0400 - binary_accuracy: 0.9882 - val_loss: 0.1980 - val_binary_accuracy: 0.9562\n",
      "Epoch 17/30\n",
      "2675/2675 [==============================] - 6s 2ms/step - loss: 0.0375 - binary_accuracy: 0.9881 - val_loss: 0.2045 - val_binary_accuracy: 0.9584\n",
      "Epoch 18/30\n",
      "2675/2675 [==============================] - 6s 2ms/step - loss: 0.0366 - binary_accuracy: 0.9892 - val_loss: 0.2210 - val_binary_accuracy: 0.9572\n",
      "Epoch 19/30\n",
      "2675/2675 [==============================] - 6s 2ms/step - loss: 0.0353 - binary_accuracy: 0.9896 - val_loss: 0.1881 - val_binary_accuracy: 0.9558\n",
      "Epoch 20/30\n",
      "2675/2675 [==============================] - 6s 2ms/step - loss: 0.0339 - binary_accuracy: 0.9894 - val_loss: 0.2346 - val_binary_accuracy: 0.9551\n",
      "Epoch 21/30\n",
      "2675/2675 [==============================] - 6s 2ms/step - loss: 0.0342 - binary_accuracy: 0.9899 - val_loss: 0.2394 - val_binary_accuracy: 0.9585\n",
      "Epoch 22/30\n",
      "2675/2675 [==============================] - 6s 2ms/step - loss: 0.0317 - binary_accuracy: 0.9903 - val_loss: 0.2804 - val_binary_accuracy: 0.9538\n",
      "Epoch 23/30\n",
      "2675/2675 [==============================] - 6s 2ms/step - loss: 0.0270 - binary_accuracy: 0.9912 - val_loss: 0.2765 - val_binary_accuracy: 0.9526\n",
      "Epoch 24/30\n",
      "2675/2675 [==============================] - 6s 2ms/step - loss: 0.0256 - binary_accuracy: 0.9915 - val_loss: 0.2867 - val_binary_accuracy: 0.9548\n",
      "Epoch 25/30\n",
      "2675/2675 [==============================] - 6s 2ms/step - loss: 0.0285 - binary_accuracy: 0.9915 - val_loss: 0.3061 - val_binary_accuracy: 0.9564\n",
      "Epoch 26/30\n",
      "2675/2675 [==============================] - 6s 2ms/step - loss: 0.0274 - binary_accuracy: 0.9918 - val_loss: 0.2987 - val_binary_accuracy: 0.9544\n",
      "Epoch 27/30\n",
      "2675/2675 [==============================] - 6s 2ms/step - loss: 0.0265 - binary_accuracy: 0.9919 - val_loss: 0.2653 - val_binary_accuracy: 0.9566\n",
      "Epoch 28/30\n",
      "2675/2675 [==============================] - 6s 2ms/step - loss: 0.0237 - binary_accuracy: 0.9922 - val_loss: 0.2702 - val_binary_accuracy: 0.9551\n",
      "Epoch 29/30\n",
      "2675/2675 [==============================] - 6s 2ms/step - loss: 0.0235 - binary_accuracy: 0.9926 - val_loss: 0.3093 - val_binary_accuracy: 0.9526\n",
      "Epoch 30/30\n",
      "2675/2675 [==============================] - 6s 2ms/step - loss: 0.0279 - binary_accuracy: 0.9912 - val_loss: 0.2831 - val_binary_accuracy: 0.9589\n",
      "339/339 [==============================] - 0s 341us/step\n",
      "Fold 4 :\n",
      "\n",
      "Train on 2678 samples, validate on 336 samples\n",
      "Epoch 1/30\n",
      "2678/2678 [==============================] - 10s 4ms/step - loss: 0.1688 - binary_accuracy: 0.9458 - val_loss: 0.1350 - val_binary_accuracy: 0.9565\n",
      "Epoch 2/30\n",
      "2678/2678 [==============================] - 6s 2ms/step - loss: 0.1358 - binary_accuracy: 0.9545 - val_loss: 0.1266 - val_binary_accuracy: 0.9578\n",
      "Epoch 3/30\n",
      "2678/2678 [==============================] - 6s 2ms/step - loss: 0.1174 - binary_accuracy: 0.9621 - val_loss: 0.1258 - val_binary_accuracy: 0.9603\n",
      "Epoch 4/30\n",
      "2678/2678 [==============================] - 6s 2ms/step - loss: 0.1050 - binary_accuracy: 0.9667 - val_loss: 0.1239 - val_binary_accuracy: 0.9621\n",
      "Epoch 5/30\n",
      "2678/2678 [==============================] - 6s 2ms/step - loss: 0.0930 - binary_accuracy: 0.9704 - val_loss: 0.1232 - val_binary_accuracy: 0.9606\n",
      "Epoch 6/30\n",
      "2678/2678 [==============================] - 6s 2ms/step - loss: 0.0821 - binary_accuracy: 0.9738 - val_loss: 0.1476 - val_binary_accuracy: 0.9592\n",
      "Epoch 7/30\n",
      "2678/2678 [==============================] - 6s 2ms/step - loss: 0.0751 - binary_accuracy: 0.9755 - val_loss: 0.1342 - val_binary_accuracy: 0.9628\n",
      "Epoch 8/30\n",
      "2678/2678 [==============================] - 6s 2ms/step - loss: 0.0673 - binary_accuracy: 0.9781 - val_loss: 0.1692 - val_binary_accuracy: 0.9593\n",
      "Epoch 9/30\n",
      "2678/2678 [==============================] - 6s 2ms/step - loss: 0.0631 - binary_accuracy: 0.9795 - val_loss: 0.1614 - val_binary_accuracy: 0.9610\n",
      "Epoch 10/30\n",
      "2678/2678 [==============================] - 6s 2ms/step - loss: 0.0599 - binary_accuracy: 0.9801 - val_loss: 0.1513 - val_binary_accuracy: 0.9621\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2678/2678 [==============================] - 6s 2ms/step - loss: 0.0562 - binary_accuracy: 0.9816 - val_loss: 0.1580 - val_binary_accuracy: 0.9621\n",
      "Epoch 12/30\n",
      "2678/2678 [==============================] - 6s 2ms/step - loss: 0.0548 - binary_accuracy: 0.9820 - val_loss: 0.1884 - val_binary_accuracy: 0.9620\n",
      "Epoch 13/30\n",
      "2678/2678 [==============================] - 6s 2ms/step - loss: 0.0497 - binary_accuracy: 0.9839 - val_loss: 0.1726 - val_binary_accuracy: 0.9628\n",
      "Epoch 14/30\n",
      "2678/2678 [==============================] - 6s 2ms/step - loss: 0.0456 - binary_accuracy: 0.9858 - val_loss: 0.2173 - val_binary_accuracy: 0.9605\n",
      "Epoch 15/30\n",
      "2678/2678 [==============================] - 6s 2ms/step - loss: 0.0473 - binary_accuracy: 0.9848 - val_loss: 0.2044 - val_binary_accuracy: 0.9636\n",
      "Epoch 16/30\n",
      "2678/2678 [==============================] - 6s 2ms/step - loss: 0.0418 - binary_accuracy: 0.9863 - val_loss: 0.2117 - val_binary_accuracy: 0.9626\n",
      "Epoch 17/30\n",
      "2678/2678 [==============================] - 6s 2ms/step - loss: 0.0375 - binary_accuracy: 0.9875 - val_loss: 0.1989 - val_binary_accuracy: 0.9620\n",
      "Epoch 18/30\n",
      "2678/2678 [==============================] - 6s 2ms/step - loss: 0.0342 - binary_accuracy: 0.9886 - val_loss: 0.2113 - val_binary_accuracy: 0.9628\n",
      "Epoch 19/30\n",
      "2678/2678 [==============================] - 5s 2ms/step - loss: 0.0363 - binary_accuracy: 0.9885 - val_loss: 0.2082 - val_binary_accuracy: 0.9628\n",
      "Epoch 20/30\n",
      "2678/2678 [==============================] - 6s 2ms/step - loss: 0.0352 - binary_accuracy: 0.9887 - val_loss: 0.2173 - val_binary_accuracy: 0.9633\n",
      "Epoch 21/30\n",
      "2678/2678 [==============================] - 6s 2ms/step - loss: 0.0320 - binary_accuracy: 0.9901 - val_loss: 0.2222 - val_binary_accuracy: 0.9631\n",
      "Epoch 22/30\n",
      "2678/2678 [==============================] - 6s 2ms/step - loss: 0.0294 - binary_accuracy: 0.9907 - val_loss: 0.2386 - val_binary_accuracy: 0.9618\n",
      "Epoch 23/30\n",
      "2678/2678 [==============================] - 6s 2ms/step - loss: 0.0301 - binary_accuracy: 0.9905 - val_loss: 0.2289 - val_binary_accuracy: 0.9645\n",
      "Epoch 24/30\n",
      "2678/2678 [==============================] - 6s 2ms/step - loss: 0.0297 - binary_accuracy: 0.9907 - val_loss: 0.2506 - val_binary_accuracy: 0.9640\n",
      "Epoch 25/30\n",
      "2678/2678 [==============================] - 6s 2ms/step - loss: 0.0306 - binary_accuracy: 0.9905 - val_loss: 0.2052 - val_binary_accuracy: 0.9625\n",
      "Epoch 26/30\n",
      "2678/2678 [==============================] - 6s 2ms/step - loss: 0.0279 - binary_accuracy: 0.9912 - val_loss: 0.2381 - val_binary_accuracy: 0.9656\n",
      "Epoch 27/30\n",
      "2678/2678 [==============================] - 6s 2ms/step - loss: 0.0261 - binary_accuracy: 0.9919 - val_loss: 0.2396 - val_binary_accuracy: 0.9625\n",
      "Epoch 28/30\n",
      "2678/2678 [==============================] - 6s 2ms/step - loss: 0.0237 - binary_accuracy: 0.9924 - val_loss: 0.2540 - val_binary_accuracy: 0.9659\n",
      "Epoch 29/30\n",
      "2678/2678 [==============================] - 6s 2ms/step - loss: 0.0274 - binary_accuracy: 0.9915 - val_loss: 0.2395 - val_binary_accuracy: 0.9626\n",
      "Epoch 30/30\n",
      "2678/2678 [==============================] - 6s 2ms/step - loss: 0.0256 - binary_accuracy: 0.9916 - val_loss: 0.2418 - val_binary_accuracy: 0.9635\n",
      "336/336 [==============================] - 0s 335us/step\n",
      "Fold 5 :\n",
      "\n",
      "Train on 2680 samples, validate on 334 samples\n",
      "Epoch 1/30\n",
      "2680/2680 [==============================] - 10s 4ms/step - loss: 0.1696 - binary_accuracy: 0.9452 - val_loss: 0.1533 - val_binary_accuracy: 0.9473\n",
      "Epoch 2/30\n",
      "2680/2680 [==============================] - 6s 2ms/step - loss: 0.1395 - binary_accuracy: 0.9544 - val_loss: 0.1286 - val_binary_accuracy: 0.9563\n",
      "Epoch 3/30\n",
      "2680/2680 [==============================] - 6s 2ms/step - loss: 0.1181 - binary_accuracy: 0.9615 - val_loss: 0.1321 - val_binary_accuracy: 0.9568\n",
      "Epoch 4/30\n",
      "2680/2680 [==============================] - 6s 2ms/step - loss: 0.1061 - binary_accuracy: 0.9657 - val_loss: 0.1275 - val_binary_accuracy: 0.9601\n",
      "Epoch 5/30\n",
      "2680/2680 [==============================] - 6s 2ms/step - loss: 0.0940 - binary_accuracy: 0.9694 - val_loss: 0.1351 - val_binary_accuracy: 0.9602\n",
      "Epoch 6/30\n",
      "2680/2680 [==============================] - 6s 2ms/step - loss: 0.0845 - binary_accuracy: 0.9724 - val_loss: 0.1408 - val_binary_accuracy: 0.9612\n",
      "Epoch 7/30\n",
      "2680/2680 [==============================] - 6s 2ms/step - loss: 0.0792 - binary_accuracy: 0.9745 - val_loss: 0.1462 - val_binary_accuracy: 0.9579\n",
      "Epoch 8/30\n",
      "2680/2680 [==============================] - 6s 2ms/step - loss: 0.0710 - binary_accuracy: 0.9766 - val_loss: 0.1724 - val_binary_accuracy: 0.9606\n",
      "Epoch 9/30\n",
      "2680/2680 [==============================] - 6s 2ms/step - loss: 0.0662 - binary_accuracy: 0.9785 - val_loss: 0.1592 - val_binary_accuracy: 0.9594\n",
      "Epoch 10/30\n",
      "2680/2680 [==============================] - 6s 2ms/step - loss: 0.0611 - binary_accuracy: 0.9798 - val_loss: 0.1697 - val_binary_accuracy: 0.9589\n",
      "Epoch 11/30\n",
      "2680/2680 [==============================] - 6s 2ms/step - loss: 0.0585 - binary_accuracy: 0.9806 - val_loss: 0.1684 - val_binary_accuracy: 0.9592\n",
      "Epoch 12/30\n",
      "2680/2680 [==============================] - 6s 2ms/step - loss: 0.0512 - binary_accuracy: 0.9831 - val_loss: 0.1842 - val_binary_accuracy: 0.9584\n",
      "Epoch 13/30\n",
      "2680/2680 [==============================] - 6s 2ms/step - loss: 0.0482 - binary_accuracy: 0.9842 - val_loss: 0.1961 - val_binary_accuracy: 0.9566\n",
      "Epoch 14/30\n",
      "2680/2680 [==============================] - 6s 2ms/step - loss: 0.0434 - binary_accuracy: 0.9859 - val_loss: 0.1990 - val_binary_accuracy: 0.9609\n",
      "Epoch 15/30\n",
      "2680/2680 [==============================] - 6s 2ms/step - loss: 0.0390 - binary_accuracy: 0.9877 - val_loss: 0.2270 - val_binary_accuracy: 0.9599\n",
      "Epoch 16/30\n",
      "2680/2680 [==============================] - 6s 2ms/step - loss: 0.0390 - binary_accuracy: 0.9875 - val_loss: 0.2506 - val_binary_accuracy: 0.9574\n",
      "Epoch 17/30\n",
      "2680/2680 [==============================] - 6s 2ms/step - loss: 0.0392 - binary_accuracy: 0.9877 - val_loss: 0.2107 - val_binary_accuracy: 0.9589\n",
      "Epoch 18/30\n",
      "2680/2680 [==============================] - 6s 2ms/step - loss: 0.0345 - binary_accuracy: 0.9888 - val_loss: 0.2266 - val_binary_accuracy: 0.9578\n",
      "Epoch 19/30\n",
      "2680/2680 [==============================] - 6s 2ms/step - loss: 0.0339 - binary_accuracy: 0.9894 - val_loss: 0.2574 - val_binary_accuracy: 0.9573\n",
      "Epoch 20/30\n",
      "2680/2680 [==============================] - 6s 2ms/step - loss: 0.0342 - binary_accuracy: 0.9898 - val_loss: 0.2570 - val_binary_accuracy: 0.9574\n",
      "Epoch 21/30\n",
      "2680/2680 [==============================] - 6s 2ms/step - loss: 0.0314 - binary_accuracy: 0.9903 - val_loss: 0.2297 - val_binary_accuracy: 0.9604\n",
      "Epoch 22/30\n",
      "2680/2680 [==============================] - 6s 2ms/step - loss: 0.0281 - binary_accuracy: 0.9912 - val_loss: 0.2251 - val_binary_accuracy: 0.9602\n",
      "Epoch 23/30\n",
      "2680/2680 [==============================] - 6s 2ms/step - loss: 0.0295 - binary_accuracy: 0.9909 - val_loss: 0.2376 - val_binary_accuracy: 0.9596\n",
      "Epoch 24/30\n",
      "2680/2680 [==============================] - 6s 2ms/step - loss: 0.0299 - binary_accuracy: 0.9907 - val_loss: 0.2869 - val_binary_accuracy: 0.9569\n",
      "Epoch 25/30\n",
      "2680/2680 [==============================] - 6s 2ms/step - loss: 0.0286 - binary_accuracy: 0.9912 - val_loss: 0.2966 - val_binary_accuracy: 0.9563\n",
      "Epoch 26/30\n",
      "2680/2680 [==============================] - 6s 2ms/step - loss: 0.0261 - binary_accuracy: 0.9917 - val_loss: 0.3008 - val_binary_accuracy: 0.9578\n",
      "Epoch 27/30\n",
      "2680/2680 [==============================] - 6s 2ms/step - loss: 0.0286 - binary_accuracy: 0.9913 - val_loss: 0.2738 - val_binary_accuracy: 0.9571\n",
      "Epoch 28/30\n",
      "2680/2680 [==============================] - 6s 2ms/step - loss: 0.0281 - binary_accuracy: 0.9914 - val_loss: 0.2661 - val_binary_accuracy: 0.9559\n",
      "Epoch 29/30\n",
      "2680/2680 [==============================] - 6s 2ms/step - loss: 0.0268 - binary_accuracy: 0.9915 - val_loss: 0.2848 - val_binary_accuracy: 0.9587\n",
      "Epoch 30/30\n",
      "2680/2680 [==============================] - 6s 2ms/step - loss: 0.0259 - binary_accuracy: 0.9916 - val_loss: 0.2830 - val_binary_accuracy: 0.9571\n",
      "334/334 [==============================] - 0s 381us/step\n",
      "Fold 6 :\n",
      "\n",
      "Train on 2682 samples, validate on 332 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2682/2682 [==============================] - 10s 4ms/step - loss: 0.1678 - binary_accuracy: 0.9461 - val_loss: 0.1546 - val_binary_accuracy: 0.9506\n",
      "Epoch 2/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.1365 - binary_accuracy: 0.9551 - val_loss: 0.1316 - val_binary_accuracy: 0.9543\n",
      "Epoch 3/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.1158 - binary_accuracy: 0.9615 - val_loss: 0.1289 - val_binary_accuracy: 0.9580\n",
      "Epoch 4/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.1028 - binary_accuracy: 0.9670 - val_loss: 0.1520 - val_binary_accuracy: 0.9575\n",
      "Epoch 5/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0923 - binary_accuracy: 0.9704 - val_loss: 0.1529 - val_binary_accuracy: 0.9585\n",
      "Epoch 6/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0846 - binary_accuracy: 0.9725 - val_loss: 0.1548 - val_binary_accuracy: 0.9578\n",
      "Epoch 7/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0766 - binary_accuracy: 0.9747 - val_loss: 0.1640 - val_binary_accuracy: 0.9598\n",
      "Epoch 8/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0703 - binary_accuracy: 0.9775 - val_loss: 0.1580 - val_binary_accuracy: 0.9622\n",
      "Epoch 9/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0634 - binary_accuracy: 0.9801 - val_loss: 0.1534 - val_binary_accuracy: 0.9612\n",
      "Epoch 10/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0595 - binary_accuracy: 0.9810 - val_loss: 0.2075 - val_binary_accuracy: 0.9602\n",
      "Epoch 11/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0535 - binary_accuracy: 0.9832 - val_loss: 0.1837 - val_binary_accuracy: 0.9618\n",
      "Epoch 12/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0513 - binary_accuracy: 0.9835 - val_loss: 0.2113 - val_binary_accuracy: 0.9615\n",
      "Epoch 13/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0480 - binary_accuracy: 0.9850 - val_loss: 0.2121 - val_binary_accuracy: 0.9612\n",
      "Epoch 14/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0440 - binary_accuracy: 0.9862 - val_loss: 0.2078 - val_binary_accuracy: 0.9608\n",
      "Epoch 15/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0422 - binary_accuracy: 0.9871 - val_loss: 0.2201 - val_binary_accuracy: 0.9618\n",
      "Epoch 16/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0398 - binary_accuracy: 0.9877 - val_loss: 0.2071 - val_binary_accuracy: 0.9627\n",
      "Epoch 17/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0367 - binary_accuracy: 0.9885 - val_loss: 0.2138 - val_binary_accuracy: 0.9635\n",
      "Epoch 18/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0354 - binary_accuracy: 0.9890 - val_loss: 0.2029 - val_binary_accuracy: 0.9632\n",
      "Epoch 19/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0373 - binary_accuracy: 0.9884 - val_loss: 0.2270 - val_binary_accuracy: 0.9620\n",
      "Epoch 20/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0358 - binary_accuracy: 0.9891 - val_loss: 0.2202 - val_binary_accuracy: 0.9612\n",
      "Epoch 21/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0334 - binary_accuracy: 0.9895 - val_loss: 0.1850 - val_binary_accuracy: 0.9632\n",
      "Epoch 22/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0275 - binary_accuracy: 0.9914 - val_loss: 0.2394 - val_binary_accuracy: 0.9600\n",
      "Epoch 23/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0283 - binary_accuracy: 0.9911 - val_loss: 0.2585 - val_binary_accuracy: 0.9617\n",
      "Epoch 24/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0241 - binary_accuracy: 0.9923 - val_loss: 0.2650 - val_binary_accuracy: 0.9612\n",
      "Epoch 25/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0245 - binary_accuracy: 0.9922 - val_loss: 0.2469 - val_binary_accuracy: 0.9618\n",
      "Epoch 26/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0244 - binary_accuracy: 0.9922 - val_loss: 0.2579 - val_binary_accuracy: 0.9580\n",
      "Epoch 27/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0259 - binary_accuracy: 0.9917 - val_loss: 0.2600 - val_binary_accuracy: 0.9607\n",
      "Epoch 28/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0261 - binary_accuracy: 0.9920 - val_loss: 0.2497 - val_binary_accuracy: 0.9577\n",
      "Epoch 29/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0256 - binary_accuracy: 0.9924 - val_loss: 0.2540 - val_binary_accuracy: 0.9590\n",
      "Epoch 30/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0269 - binary_accuracy: 0.9920 - val_loss: 0.2698 - val_binary_accuracy: 0.9588\n",
      "332/332 [==============================] - 0s 377us/step\n",
      "Fold 7 :\n",
      "\n",
      "Train on 2682 samples, validate on 332 samples\n",
      "Epoch 1/30\n",
      "2682/2682 [==============================] - 11s 4ms/step - loss: 0.1670 - binary_accuracy: 0.9459 - val_loss: 0.1445 - val_binary_accuracy: 0.9536\n",
      "Epoch 2/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.1334 - binary_accuracy: 0.9560 - val_loss: 0.1344 - val_binary_accuracy: 0.9548\n",
      "Epoch 3/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.1145 - binary_accuracy: 0.9627 - val_loss: 0.1232 - val_binary_accuracy: 0.9613\n",
      "Epoch 4/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.1051 - binary_accuracy: 0.9663 - val_loss: 0.1378 - val_binary_accuracy: 0.9615\n",
      "Epoch 5/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0951 - binary_accuracy: 0.9702 - val_loss: 0.1470 - val_binary_accuracy: 0.9582\n",
      "Epoch 6/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0853 - binary_accuracy: 0.9725 - val_loss: 0.1396 - val_binary_accuracy: 0.9607\n",
      "Epoch 7/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0774 - binary_accuracy: 0.9752 - val_loss: 0.1528 - val_binary_accuracy: 0.9618\n",
      "Epoch 8/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0692 - binary_accuracy: 0.9776 - val_loss: 0.1680 - val_binary_accuracy: 0.9613\n",
      "Epoch 9/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0629 - binary_accuracy: 0.9796 - val_loss: 0.1683 - val_binary_accuracy: 0.9620\n",
      "Epoch 10/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0577 - binary_accuracy: 0.9808 - val_loss: 0.1834 - val_binary_accuracy: 0.9608\n",
      "Epoch 11/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0565 - binary_accuracy: 0.9814 - val_loss: 0.1689 - val_binary_accuracy: 0.9622\n",
      "Epoch 12/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0532 - binary_accuracy: 0.9838 - val_loss: 0.1752 - val_binary_accuracy: 0.9618\n",
      "Epoch 13/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0470 - binary_accuracy: 0.9854 - val_loss: 0.1913 - val_binary_accuracy: 0.9630\n",
      "Epoch 14/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0441 - binary_accuracy: 0.9855 - val_loss: 0.2210 - val_binary_accuracy: 0.9617\n",
      "Epoch 15/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0431 - binary_accuracy: 0.9866 - val_loss: 0.2428 - val_binary_accuracy: 0.9597\n",
      "Epoch 16/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0404 - binary_accuracy: 0.9870 - val_loss: 0.1959 - val_binary_accuracy: 0.9608\n",
      "Epoch 17/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0365 - binary_accuracy: 0.9885 - val_loss: 0.2494 - val_binary_accuracy: 0.9595\n",
      "Epoch 18/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0392 - binary_accuracy: 0.9880 - val_loss: 0.2103 - val_binary_accuracy: 0.9632\n",
      "Epoch 19/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0351 - binary_accuracy: 0.9893 - val_loss: 0.2234 - val_binary_accuracy: 0.9607\n",
      "Epoch 20/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0335 - binary_accuracy: 0.9899 - val_loss: 0.2241 - val_binary_accuracy: 0.9622\n",
      "Epoch 21/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0306 - binary_accuracy: 0.9903 - val_loss: 0.2234 - val_binary_accuracy: 0.9622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0285 - binary_accuracy: 0.9909 - val_loss: 0.2330 - val_binary_accuracy: 0.9610\n",
      "Epoch 23/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0322 - binary_accuracy: 0.9900 - val_loss: 0.2334 - val_binary_accuracy: 0.9632\n",
      "Epoch 24/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0285 - binary_accuracy: 0.9909 - val_loss: 0.2709 - val_binary_accuracy: 0.9632\n",
      "Epoch 25/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0249 - binary_accuracy: 0.9918 - val_loss: 0.2434 - val_binary_accuracy: 0.9630\n",
      "Epoch 26/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0254 - binary_accuracy: 0.9919 - val_loss: 0.2620 - val_binary_accuracy: 0.9615\n",
      "Epoch 27/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0224 - binary_accuracy: 0.9926 - val_loss: 0.2700 - val_binary_accuracy: 0.9605\n",
      "Epoch 28/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0229 - binary_accuracy: 0.9923 - val_loss: 0.2837 - val_binary_accuracy: 0.9623\n",
      "Epoch 29/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0230 - binary_accuracy: 0.9925 - val_loss: 0.2774 - val_binary_accuracy: 0.9600\n",
      "Epoch 30/30\n",
      "2682/2682 [==============================] - 6s 2ms/step - loss: 0.0252 - binary_accuracy: 0.9915 - val_loss: 0.2813 - val_binary_accuracy: 0.9618\n",
      "332/332 [==============================] - 0s 354us/step\n",
      "Fold 8 :\n",
      "\n",
      "Train on 2684 samples, validate on 330 samples\n",
      "Epoch 1/30\n",
      "2684/2684 [==============================] - 11s 4ms/step - loss: 0.1718 - binary_accuracy: 0.9460 - val_loss: 0.1485 - val_binary_accuracy: 0.9524\n",
      "Epoch 2/30\n",
      "2684/2684 [==============================] - 6s 2ms/step - loss: 0.1373 - binary_accuracy: 0.9548 - val_loss: 0.1315 - val_binary_accuracy: 0.9549\n",
      "Epoch 3/30\n",
      "2684/2684 [==============================] - 6s 2ms/step - loss: 0.1179 - binary_accuracy: 0.9620 - val_loss: 0.1203 - val_binary_accuracy: 0.9586\n",
      "Epoch 4/30\n",
      "2684/2684 [==============================] - 6s 2ms/step - loss: 0.1030 - binary_accuracy: 0.9671 - val_loss: 0.1261 - val_binary_accuracy: 0.9586\n",
      "Epoch 5/30\n",
      "2684/2684 [==============================] - 6s 2ms/step - loss: 0.0918 - binary_accuracy: 0.9707 - val_loss: 0.1261 - val_binary_accuracy: 0.9591\n",
      "Epoch 6/30\n",
      "2684/2684 [==============================] - 6s 2ms/step - loss: 0.0831 - binary_accuracy: 0.9731 - val_loss: 0.1343 - val_binary_accuracy: 0.9614\n",
      "Epoch 7/30\n",
      "2684/2684 [==============================] - 6s 2ms/step - loss: 0.0737 - binary_accuracy: 0.9761 - val_loss: 0.1631 - val_binary_accuracy: 0.9606\n",
      "Epoch 8/30\n",
      "2684/2684 [==============================] - 6s 2ms/step - loss: 0.0697 - binary_accuracy: 0.9779 - val_loss: 0.1575 - val_binary_accuracy: 0.9599\n",
      "Epoch 9/30\n",
      "2684/2684 [==============================] - 6s 2ms/step - loss: 0.0646 - binary_accuracy: 0.9789 - val_loss: 0.1643 - val_binary_accuracy: 0.9596\n",
      "Epoch 10/30\n",
      "2684/2684 [==============================] - 6s 2ms/step - loss: 0.0559 - binary_accuracy: 0.9819 - val_loss: 0.1858 - val_binary_accuracy: 0.9582\n",
      "Epoch 11/30\n",
      "2684/2684 [==============================] - 6s 2ms/step - loss: 0.0541 - binary_accuracy: 0.9830 - val_loss: 0.1839 - val_binary_accuracy: 0.9601\n",
      "Epoch 12/30\n",
      "2684/2684 [==============================] - 6s 2ms/step - loss: 0.0491 - binary_accuracy: 0.9846 - val_loss: 0.1828 - val_binary_accuracy: 0.9586\n",
      "Epoch 13/30\n",
      "2684/2684 [==============================] - 6s 2ms/step - loss: 0.0459 - binary_accuracy: 0.9853 - val_loss: 0.1799 - val_binary_accuracy: 0.9572\n",
      "Epoch 14/30\n",
      "2684/2684 [==============================] - 6s 2ms/step - loss: 0.0444 - binary_accuracy: 0.9858 - val_loss: 0.1876 - val_binary_accuracy: 0.9630\n",
      "Epoch 15/30\n",
      "2684/2684 [==============================] - 6s 2ms/step - loss: 0.0409 - binary_accuracy: 0.9872 - val_loss: 0.2053 - val_binary_accuracy: 0.9598\n",
      "Epoch 16/30\n",
      "2684/2684 [==============================] - 6s 2ms/step - loss: 0.0415 - binary_accuracy: 0.9870 - val_loss: 0.1710 - val_binary_accuracy: 0.9604\n",
      "Epoch 17/30\n",
      "2684/2684 [==============================] - 6s 2ms/step - loss: 0.0363 - binary_accuracy: 0.9888 - val_loss: 0.2336 - val_binary_accuracy: 0.9589\n",
      "Epoch 18/30\n",
      "2684/2684 [==============================] - 6s 2ms/step - loss: 0.0321 - binary_accuracy: 0.9899 - val_loss: 0.2090 - val_binary_accuracy: 0.9633\n",
      "Epoch 19/30\n",
      "2684/2684 [==============================] - 6s 2ms/step - loss: 0.0337 - binary_accuracy: 0.9894 - val_loss: 0.2223 - val_binary_accuracy: 0.9613\n",
      "Epoch 20/30\n",
      "2684/2684 [==============================] - 6s 2ms/step - loss: 0.0357 - binary_accuracy: 0.9896 - val_loss: 0.2305 - val_binary_accuracy: 0.9613\n",
      "Epoch 21/30\n",
      "2684/2684 [==============================] - 6s 2ms/step - loss: 0.0311 - binary_accuracy: 0.9903 - val_loss: 0.2294 - val_binary_accuracy: 0.9588\n",
      "Epoch 22/30\n",
      "2684/2684 [==============================] - 6s 2ms/step - loss: 0.0302 - binary_accuracy: 0.9905 - val_loss: 0.2181 - val_binary_accuracy: 0.9586\n",
      "Epoch 23/30\n",
      "2684/2684 [==============================] - 6s 2ms/step - loss: 0.0282 - binary_accuracy: 0.9912 - val_loss: 0.2168 - val_binary_accuracy: 0.9613\n",
      "Epoch 24/30\n",
      "2684/2684 [==============================] - 6s 2ms/step - loss: 0.0309 - binary_accuracy: 0.9910 - val_loss: 0.2244 - val_binary_accuracy: 0.9625\n",
      "Epoch 25/30\n",
      "2684/2684 [==============================] - 6s 2ms/step - loss: 0.0285 - binary_accuracy: 0.9914 - val_loss: 0.2565 - val_binary_accuracy: 0.9586\n",
      "Epoch 26/30\n",
      "2684/2684 [==============================] - 6s 2ms/step - loss: 0.0255 - binary_accuracy: 0.9918 - val_loss: 0.2785 - val_binary_accuracy: 0.9589\n",
      "Epoch 27/30\n",
      "2684/2684 [==============================] - ETA: 0s - loss: 0.0236 - binary_accuracy: 0.992 - 6s 2ms/step - loss: 0.0236 - binary_accuracy: 0.9925 - val_loss: 0.3001 - val_binary_accuracy: 0.9589\n",
      "Epoch 28/30\n",
      "2684/2684 [==============================] - 6s 2ms/step - loss: 0.0274 - binary_accuracy: 0.9922 - val_loss: 0.2803 - val_binary_accuracy: 0.9581\n",
      "Epoch 29/30\n",
      "2684/2684 [==============================] - 6s 2ms/step - loss: 0.0283 - binary_accuracy: 0.9917 - val_loss: 0.2450 - val_binary_accuracy: 0.9594\n",
      "Epoch 30/30\n",
      "2684/2684 [==============================] - 6s 2ms/step - loss: 0.0245 - binary_accuracy: 0.9923 - val_loss: 0.2484 - val_binary_accuracy: 0.9616\n",
      "330/330 [==============================] - 0s 360us/step\n",
      "Fold 9 :\n",
      "\n",
      "Train on 2685 samples, validate on 329 samples\n",
      "Epoch 1/30\n",
      "2685/2685 [==============================] - 11s 4ms/step - loss: 0.1713 - binary_accuracy: 0.9457 - val_loss: 0.1483 - val_binary_accuracy: 0.9522\n",
      "Epoch 2/30\n",
      "2685/2685 [==============================] - 6s 2ms/step - loss: 0.1395 - binary_accuracy: 0.9535 - val_loss: 0.1285 - val_binary_accuracy: 0.9590\n",
      "Epoch 3/30\n",
      "2685/2685 [==============================] - 6s 2ms/step - loss: 0.1208 - binary_accuracy: 0.9599 - val_loss: 0.1251 - val_binary_accuracy: 0.9595\n",
      "Epoch 4/30\n",
      "2685/2685 [==============================] - 6s 2ms/step - loss: 0.1073 - binary_accuracy: 0.9658 - val_loss: 0.1296 - val_binary_accuracy: 0.9617\n",
      "Epoch 5/30\n",
      "2685/2685 [==============================] - 6s 2ms/step - loss: 0.0950 - binary_accuracy: 0.9696 - val_loss: 0.1213 - val_binary_accuracy: 0.9642\n",
      "Epoch 6/30\n",
      "2685/2685 [==============================] - 6s 2ms/step - loss: 0.0882 - binary_accuracy: 0.9712 - val_loss: 0.1230 - val_binary_accuracy: 0.9634\n",
      "Epoch 7/30\n",
      "2685/2685 [==============================] - 6s 2ms/step - loss: 0.0785 - binary_accuracy: 0.9742 - val_loss: 0.1356 - val_binary_accuracy: 0.9634\n",
      "Epoch 8/30\n",
      "2685/2685 [==============================] - 6s 2ms/step - loss: 0.0742 - binary_accuracy: 0.9764 - val_loss: 0.1267 - val_binary_accuracy: 0.9645\n",
      "Epoch 9/30\n",
      "2685/2685 [==============================] - 6s 2ms/step - loss: 0.0651 - binary_accuracy: 0.9786 - val_loss: 0.1413 - val_binary_accuracy: 0.9652\n",
      "Epoch 10/30\n",
      "2685/2685 [==============================] - 6s 2ms/step - loss: 0.0592 - binary_accuracy: 0.9806 - val_loss: 0.1417 - val_binary_accuracy: 0.9644\n",
      "Epoch 11/30\n",
      "2685/2685 [==============================] - 6s 2ms/step - loss: 0.0571 - binary_accuracy: 0.9814 - val_loss: 0.1564 - val_binary_accuracy: 0.9630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n",
      "2685/2685 [==============================] - 6s 2ms/step - loss: 0.0516 - binary_accuracy: 0.9834 - val_loss: 0.1559 - val_binary_accuracy: 0.9642\n",
      "Epoch 13/30\n",
      "2685/2685 [==============================] - 6s 2ms/step - loss: 0.0495 - binary_accuracy: 0.9838 - val_loss: 0.1566 - val_binary_accuracy: 0.9661\n",
      "Epoch 14/30\n",
      "2685/2685 [==============================] - 6s 2ms/step - loss: 0.0470 - binary_accuracy: 0.9845 - val_loss: 0.1674 - val_binary_accuracy: 0.9635\n",
      "Epoch 15/30\n",
      "2685/2685 [==============================] - 6s 2ms/step - loss: 0.0425 - binary_accuracy: 0.9865 - val_loss: 0.1822 - val_binary_accuracy: 0.9650\n",
      "Epoch 16/30\n",
      "2685/2685 [==============================] - 6s 2ms/step - loss: 0.0392 - binary_accuracy: 0.9875 - val_loss: 0.1768 - val_binary_accuracy: 0.9642\n",
      "Epoch 17/30\n",
      "2685/2685 [==============================] - 6s 2ms/step - loss: 0.0401 - binary_accuracy: 0.9878 - val_loss: 0.1726 - val_binary_accuracy: 0.9644\n",
      "Epoch 18/30\n",
      "2685/2685 [==============================] - 6s 2ms/step - loss: 0.0366 - binary_accuracy: 0.9887 - val_loss: 0.1734 - val_binary_accuracy: 0.9654\n",
      "Epoch 19/30\n",
      "2685/2685 [==============================] - 6s 2ms/step - loss: 0.0353 - binary_accuracy: 0.9891 - val_loss: 0.2061 - val_binary_accuracy: 0.9622\n",
      "Epoch 20/30\n",
      "2685/2685 [==============================] - 6s 2ms/step - loss: 0.0373 - binary_accuracy: 0.9885 - val_loss: 0.1748 - val_binary_accuracy: 0.9649\n",
      "Epoch 21/30\n",
      "2685/2685 [==============================] - 6s 2ms/step - loss: 0.0326 - binary_accuracy: 0.9894 - val_loss: 0.2057 - val_binary_accuracy: 0.9637\n",
      "Epoch 22/30\n",
      "2685/2685 [==============================] - 6s 2ms/step - loss: 0.0345 - binary_accuracy: 0.9893 - val_loss: 0.2138 - val_binary_accuracy: 0.9610\n",
      "Epoch 23/30\n",
      "2685/2685 [==============================] - 6s 2ms/step - loss: 0.0294 - binary_accuracy: 0.9909 - val_loss: 0.2329 - val_binary_accuracy: 0.9617\n",
      "Epoch 24/30\n",
      "2685/2685 [==============================] - 6s 2ms/step - loss: 0.0296 - binary_accuracy: 0.9907 - val_loss: 0.2071 - val_binary_accuracy: 0.9625\n",
      "Epoch 25/30\n",
      "2685/2685 [==============================] - 6s 2ms/step - loss: 0.0302 - binary_accuracy: 0.9911 - val_loss: 0.2163 - val_binary_accuracy: 0.9635\n",
      "Epoch 26/30\n",
      "2685/2685 [==============================] - 6s 2ms/step - loss: 0.0307 - binary_accuracy: 0.9907 - val_loss: 0.2289 - val_binary_accuracy: 0.9649\n",
      "Epoch 27/30\n",
      "2685/2685 [==============================] - 6s 2ms/step - loss: 0.0283 - binary_accuracy: 0.9914 - val_loss: 0.2512 - val_binary_accuracy: 0.9623\n",
      "Epoch 28/30\n",
      "2685/2685 [==============================] - 6s 2ms/step - loss: 0.0291 - binary_accuracy: 0.9912 - val_loss: 0.2193 - val_binary_accuracy: 0.9630\n",
      "Epoch 29/30\n",
      "2685/2685 [==============================] - 6s 2ms/step - loss: 0.0288 - binary_accuracy: 0.9912 - val_loss: 0.2262 - val_binary_accuracy: 0.9612\n",
      "Epoch 30/30\n",
      "2685/2685 [==============================] - 6s 2ms/step - loss: 0.0272 - binary_accuracy: 0.9915 - val_loss: 0.2575 - val_binary_accuracy: 0.9630\n",
      "329/329 [==============================] - 0s 359us/step\n"
     ]
    }
   ],
   "source": [
    "#k=9, fungsi aktivasi=ReLU, nilai dropout=0.4\n",
    "kf = StratifiedKFold(n_splits=9, random_state=None, shuffle=False)\n",
    "val_loss_cv = []\n",
    "val_acc_cv = []\n",
    "j = 0\n",
    "for train_index, test_index in kf.split(X,z):\n",
    "    j+=1\n",
    "    print(f\"Fold {j} :\")\n",
    "    print(\"\")\n",
    "    X_train,X_test = X.iloc[train_index,:],X.iloc[test_index,:]\n",
    "    y_train,y_test = y.iloc[train_index,:],y.iloc[test_index,:]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim=X_train.shape[1], units=463,\n",
    "                     kernel_initializer='normal', bias_initializer='zeros'))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    for i in range(0, 6):\n",
    "        model.add(Dense(units=463, kernel_initializer='normal',\n",
    "                         bias_initializer='zeros'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(.4))\n",
    "\n",
    "    model.add(Dense(units=18))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
    "    model.fit(X_train, y_train,batch_size=24,epochs=30,verbose=1,validation_data=(X_test, y_test))\n",
    "    score = model.evaluate(X_test, y_test, verbose=1)\n",
    "    val_loss_cv.append(score[0])\n",
    "    val_acc_cv.append(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss_cv : [0.35941958357716164, 0.4095561690190259, 0.2831033976380452, 0.24179353955246152, 0.28296504602460804, 0.2698107873700529, 0.2812571958246001, 0.24842348818977675, 0.2574888779399605]\n",
      "mean_val_loss_cv : 0.2926464539039658\n",
      "val_acc_cv : [0.9494801728348983, 0.9444444305756513, 0.9588659349444342, 0.9634589921860468, 0.9570858132339524, 0.9588353317904185, 0.9618473677750093, 0.9616161574016918, 0.9630192462071822]\n",
      "mean_val_acc_cv : 0.9576281607721427\n"
     ]
    }
   ],
   "source": [
    "print(f\"val_loss_cv : {val_loss_cv}\")\n",
    "print(f\"mean_val_loss_cv : {np.mean(val_loss_cv)}\")\n",
    "print(f\"val_acc_cv : {val_acc_cv}\")\n",
    "print(f\"mean_val_acc_cv : {np.mean(val_acc_cv)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 :\n",
      "\n",
      "Train on 2704 samples, validate on 310 samples\n",
      "Epoch 1/30\n",
      "2704/2704 [==============================] - 13s 5ms/step - loss: 0.1688 - binary_accuracy: 0.9461 - val_loss: 0.1454 - val_binary_accuracy: 0.9534\n",
      "Epoch 2/30\n",
      "2704/2704 [==============================] - 6s 2ms/step - loss: 0.1418 - binary_accuracy: 0.9541 - val_loss: 0.1365 - val_binary_accuracy: 0.9552\n",
      "Epoch 3/30\n",
      "2704/2704 [==============================] - 6s 2ms/step - loss: 0.1192 - binary_accuracy: 0.9609 - val_loss: 0.1232 - val_binary_accuracy: 0.9604\n",
      "Epoch 4/30\n",
      "2704/2704 [==============================] - 6s 2ms/step - loss: 0.1041 - binary_accuracy: 0.9663 - val_loss: 0.1263 - val_binary_accuracy: 0.9591\n",
      "Epoch 5/30\n",
      "2704/2704 [==============================] - 7s 2ms/step - loss: 0.0927 - binary_accuracy: 0.9695 - val_loss: 0.1311 - val_binary_accuracy: 0.9606\n",
      "Epoch 6/30\n",
      "2704/2704 [==============================] - 6s 2ms/step - loss: 0.0843 - binary_accuracy: 0.9726 - val_loss: 0.1493 - val_binary_accuracy: 0.9590\n",
      "Epoch 7/30\n",
      "2704/2704 [==============================] - 6s 2ms/step - loss: 0.0756 - binary_accuracy: 0.9757 - val_loss: 0.1389 - val_binary_accuracy: 0.9573\n",
      "Epoch 8/30\n",
      "2704/2704 [==============================] - 6s 2ms/step - loss: 0.0715 - binary_accuracy: 0.9773 - val_loss: 0.1368 - val_binary_accuracy: 0.9591\n",
      "Epoch 9/30\n",
      "2704/2704 [==============================] - 6s 2ms/step - loss: 0.0621 - binary_accuracy: 0.9801 - val_loss: 0.1835 - val_binary_accuracy: 0.9554\n",
      "Epoch 10/30\n",
      "2704/2704 [==============================] - 6s 2ms/step - loss: 0.0619 - binary_accuracy: 0.9811 - val_loss: 0.1749 - val_binary_accuracy: 0.9556\n",
      "Epoch 11/30\n",
      "2704/2704 [==============================] - 6s 2ms/step - loss: 0.0534 - binary_accuracy: 0.9829 - val_loss: 0.1701 - val_binary_accuracy: 0.9579\n",
      "Epoch 12/30\n",
      "2704/2704 [==============================] - 6s 2ms/step - loss: 0.0483 - binary_accuracy: 0.9843 - val_loss: 0.1937 - val_binary_accuracy: 0.9556\n",
      "Epoch 13/30\n",
      "2704/2704 [==============================] - 6s 2ms/step - loss: 0.0457 - binary_accuracy: 0.9852 - val_loss: 0.2189 - val_binary_accuracy: 0.9550\n",
      "Epoch 14/30\n",
      "2704/2704 [==============================] - 6s 2ms/step - loss: 0.0453 - binary_accuracy: 0.9858 - val_loss: 0.2132 - val_binary_accuracy: 0.9543\n",
      "Epoch 15/30\n",
      "2704/2704 [==============================] - 6s 2ms/step - loss: 0.0380 - binary_accuracy: 0.9877 - val_loss: 0.2139 - val_binary_accuracy: 0.9527\n",
      "Epoch 16/30\n",
      "2704/2704 [==============================] - 6s 2ms/step - loss: 0.0402 - binary_accuracy: 0.9872 - val_loss: 0.2081 - val_binary_accuracy: 0.9565\n",
      "Epoch 17/30\n",
      "2704/2704 [==============================] - 6s 2ms/step - loss: 0.0379 - binary_accuracy: 0.9878 - val_loss: 0.2231 - val_binary_accuracy: 0.9547\n",
      "Epoch 18/30\n",
      "2704/2704 [==============================] - 6s 2ms/step - loss: 0.0362 - binary_accuracy: 0.9887 - val_loss: 0.2154 - val_binary_accuracy: 0.9561\n",
      "Epoch 19/30\n",
      "2704/2704 [==============================] - 6s 2ms/step - loss: 0.0308 - binary_accuracy: 0.9899 - val_loss: 0.2564 - val_binary_accuracy: 0.9520\n",
      "Epoch 20/30\n",
      "2704/2704 [==============================] - 6s 2ms/step - loss: 0.0319 - binary_accuracy: 0.9903 - val_loss: 0.2407 - val_binary_accuracy: 0.9541\n",
      "Epoch 21/30\n",
      "2704/2704 [==============================] - 6s 2ms/step - loss: 0.0325 - binary_accuracy: 0.9896 - val_loss: 0.2835 - val_binary_accuracy: 0.9504\n",
      "Epoch 22/30\n",
      "2704/2704 [==============================] - 6s 2ms/step - loss: 0.0309 - binary_accuracy: 0.9904 - val_loss: 0.2686 - val_binary_accuracy: 0.9548\n",
      "Epoch 23/30\n",
      "2704/2704 [==============================] - 6s 2ms/step - loss: 0.0270 - binary_accuracy: 0.9915 - val_loss: 0.3291 - val_binary_accuracy: 0.9516\n",
      "Epoch 24/30\n",
      "2704/2704 [==============================] - 6s 2ms/step - loss: 0.0289 - binary_accuracy: 0.9914 - val_loss: 0.2713 - val_binary_accuracy: 0.9529\n",
      "Epoch 25/30\n",
      "2704/2704 [==============================] - 6s 2ms/step - loss: 0.0267 - binary_accuracy: 0.9919 - val_loss: 0.2857 - val_binary_accuracy: 0.9554\n",
      "Epoch 26/30\n",
      "2704/2704 [==============================] - 6s 2ms/step - loss: 0.0277 - binary_accuracy: 0.9915 - val_loss: 0.2865 - val_binary_accuracy: 0.9539\n",
      "Epoch 27/30\n",
      "2704/2704 [==============================] - 6s 2ms/step - loss: 0.0259 - binary_accuracy: 0.9922 - val_loss: 0.3269 - val_binary_accuracy: 0.9538\n",
      "Epoch 28/30\n",
      "2704/2704 [==============================] - 6s 2ms/step - loss: 0.0289 - binary_accuracy: 0.9918 - val_loss: 0.2513 - val_binary_accuracy: 0.9541\n",
      "Epoch 29/30\n",
      "2704/2704 [==============================] - 6s 2ms/step - loss: 0.0287 - binary_accuracy: 0.9917 - val_loss: 0.2931 - val_binary_accuracy: 0.9522\n",
      "Epoch 30/30\n",
      "2704/2704 [==============================] - 6s 2ms/step - loss: 0.0260 - binary_accuracy: 0.9920 - val_loss: 0.2822 - val_binary_accuracy: 0.9525\n",
      "310/310 [==============================] - 0s 911us/step\n",
      "Fold 2 :\n",
      "\n",
      "Train on 2706 samples, validate on 308 samples\n",
      "Epoch 1/30\n",
      "2706/2706 [==============================] - 13s 5ms/step - loss: 0.1680 - binary_accuracy: 0.9461 - val_loss: 0.1476 - val_binary_accuracy: 0.9520\n",
      "Epoch 2/30\n",
      "2706/2706 [==============================] - 7s 2ms/step - loss: 0.1338 - binary_accuracy: 0.9558 - val_loss: 0.1457 - val_binary_accuracy: 0.9509\n",
      "Epoch 3/30\n",
      "2706/2706 [==============================] - 7s 2ms/step - loss: 0.1129 - binary_accuracy: 0.9635 - val_loss: 0.1414 - val_binary_accuracy: 0.9545\n",
      "Epoch 4/30\n",
      "2706/2706 [==============================] - 7s 2ms/step - loss: 0.1014 - binary_accuracy: 0.9673 - val_loss: 0.1426 - val_binary_accuracy: 0.9536\n",
      "Epoch 5/30\n",
      "2706/2706 [==============================] - 7s 2ms/step - loss: 0.0888 - binary_accuracy: 0.9718 - val_loss: 0.1635 - val_binary_accuracy: 0.9529\n",
      "Epoch 6/30\n",
      "2706/2706 [==============================] - 7s 2ms/step - loss: 0.0813 - binary_accuracy: 0.9736 - val_loss: 0.1515 - val_binary_accuracy: 0.9560\n",
      "Epoch 7/30\n",
      "2706/2706 [==============================] - 7s 2ms/step - loss: 0.0709 - binary_accuracy: 0.9770 - val_loss: 0.1632 - val_binary_accuracy: 0.9535\n",
      "Epoch 8/30\n",
      "2706/2706 [==============================] - 7s 2ms/step - loss: 0.0663 - binary_accuracy: 0.9786 - val_loss: 0.1786 - val_binary_accuracy: 0.9524\n",
      "Epoch 9/30\n",
      "2706/2706 [==============================] - 6s 2ms/step - loss: 0.0590 - binary_accuracy: 0.9807 - val_loss: 0.1968 - val_binary_accuracy: 0.9504\n",
      "Epoch 10/30\n",
      "2706/2706 [==============================] - 7s 2ms/step - loss: 0.0535 - binary_accuracy: 0.9828 - val_loss: 0.2480 - val_binary_accuracy: 0.9481\n",
      "Epoch 11/30\n",
      "2706/2706 [==============================] - 7s 2ms/step - loss: 0.0508 - binary_accuracy: 0.9838 - val_loss: 0.1823 - val_binary_accuracy: 0.9527\n",
      "Epoch 12/30\n",
      "2706/2706 [==============================] - 7s 2ms/step - loss: 0.0475 - binary_accuracy: 0.9849 - val_loss: 0.2514 - val_binary_accuracy: 0.9481\n",
      "Epoch 13/30\n",
      "2706/2706 [==============================] - 7s 2ms/step - loss: 0.0448 - binary_accuracy: 0.9859 - val_loss: 0.2078 - val_binary_accuracy: 0.9491\n",
      "Epoch 14/30\n",
      "2706/2706 [==============================] - 7s 2ms/step - loss: 0.0407 - binary_accuracy: 0.9868 - val_loss: 0.2694 - val_binary_accuracy: 0.9484\n",
      "Epoch 15/30\n",
      "2706/2706 [==============================] - 7s 2ms/step - loss: 0.0388 - binary_accuracy: 0.9884 - val_loss: 0.2266 - val_binary_accuracy: 0.9486\n",
      "Epoch 16/30\n",
      "2706/2706 [==============================] - 7s 3ms/step - loss: 0.0355 - binary_accuracy: 0.9884 - val_loss: 0.3396 - val_binary_accuracy: 0.9459\n",
      "Epoch 17/30\n",
      "2706/2706 [==============================] - 7s 2ms/step - loss: 0.0402 - binary_accuracy: 0.9880 - val_loss: 0.2594 - val_binary_accuracy: 0.9481\n",
      "Epoch 18/30\n",
      "2706/2706 [==============================] - 7s 2ms/step - loss: 0.0362 - binary_accuracy: 0.9888 - val_loss: 0.2978 - val_binary_accuracy: 0.9481\n",
      "Epoch 19/30\n",
      "2706/2706 [==============================] - 7s 2ms/step - loss: 0.0335 - binary_accuracy: 0.9900 - val_loss: 0.3608 - val_binary_accuracy: 0.9461\n",
      "Epoch 20/30\n",
      "2706/2706 [==============================] - 7s 2ms/step - loss: 0.0307 - binary_accuracy: 0.9906 - val_loss: 0.3042 - val_binary_accuracy: 0.9497\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2706/2706 [==============================] - 6s 2ms/step - loss: 0.0310 - binary_accuracy: 0.9906 - val_loss: 0.2799 - val_binary_accuracy: 0.9513\n",
      "Epoch 22/30\n",
      "2706/2706 [==============================] - 6s 2ms/step - loss: 0.0288 - binary_accuracy: 0.9913 - val_loss: 0.3350 - val_binary_accuracy: 0.9457\n",
      "Epoch 23/30\n",
      "2706/2706 [==============================] - 6s 2ms/step - loss: 0.0312 - binary_accuracy: 0.9906 - val_loss: 0.3062 - val_binary_accuracy: 0.9481\n",
      "Epoch 24/30\n",
      "2706/2706 [==============================] - 6s 2ms/step - loss: 0.0262 - binary_accuracy: 0.9913 - val_loss: 0.3737 - val_binary_accuracy: 0.9448\n",
      "Epoch 25/30\n",
      "2706/2706 [==============================] - 6s 2ms/step - loss: 0.0233 - binary_accuracy: 0.9931 - val_loss: 0.4063 - val_binary_accuracy: 0.9475\n",
      "Epoch 26/30\n",
      "2706/2706 [==============================] - 6s 2ms/step - loss: 0.0237 - binary_accuracy: 0.9929 - val_loss: 0.3560 - val_binary_accuracy: 0.9481\n",
      "Epoch 27/30\n",
      "2706/2706 [==============================] - 6s 2ms/step - loss: 0.0253 - binary_accuracy: 0.9930 - val_loss: 0.3248 - val_binary_accuracy: 0.9484\n",
      "Epoch 28/30\n",
      "2706/2706 [==============================] - 6s 2ms/step - loss: 0.0233 - binary_accuracy: 0.9931 - val_loss: 0.3777 - val_binary_accuracy: 0.9468\n",
      "Epoch 29/30\n",
      "2706/2706 [==============================] - 6s 2ms/step - loss: 0.0241 - binary_accuracy: 0.9927 - val_loss: 0.4037 - val_binary_accuracy: 0.9459\n",
      "Epoch 30/30\n",
      "2706/2706 [==============================] - 6s 2ms/step - loss: 0.0268 - binary_accuracy: 0.9919 - val_loss: 0.3620 - val_binary_accuracy: 0.9473\n",
      "308/308 [==============================] - 0s 384us/step\n",
      "Fold 3 :\n",
      "\n",
      "Train on 2711 samples, validate on 303 samples\n",
      "Epoch 1/30\n",
      "2711/2711 [==============================] - 12s 4ms/step - loss: 0.1679 - binary_accuracy: 0.9470 - val_loss: 0.1358 - val_binary_accuracy: 0.9534\n",
      "Epoch 2/30\n",
      "2711/2711 [==============================] - 6s 2ms/step - loss: 0.1315 - binary_accuracy: 0.9568 - val_loss: 0.1319 - val_binary_accuracy: 0.9589\n",
      "Epoch 3/30\n",
      "2711/2711 [==============================] - 6s 2ms/step - loss: 0.1165 - binary_accuracy: 0.9620 - val_loss: 0.1206 - val_binary_accuracy: 0.9591\n",
      "Epoch 4/30\n",
      "2711/2711 [==============================] - 6s 2ms/step - loss: 0.1040 - binary_accuracy: 0.9676 - val_loss: 0.1186 - val_binary_accuracy: 0.9604\n",
      "Epoch 5/30\n",
      "2711/2711 [==============================] - 6s 2ms/step - loss: 0.0918 - binary_accuracy: 0.9712 - val_loss: 0.1319 - val_binary_accuracy: 0.9578\n",
      "Epoch 6/30\n",
      "2711/2711 [==============================] - 6s 2ms/step - loss: 0.0820 - binary_accuracy: 0.9734 - val_loss: 0.1275 - val_binary_accuracy: 0.9608\n",
      "Epoch 7/30\n",
      "2711/2711 [==============================] - 6s 2ms/step - loss: 0.0727 - binary_accuracy: 0.9764 - val_loss: 0.1531 - val_binary_accuracy: 0.9580\n",
      "Epoch 8/30\n",
      "2711/2711 [==============================] - 6s 2ms/step - loss: 0.0690 - binary_accuracy: 0.9777 - val_loss: 0.1831 - val_binary_accuracy: 0.9582\n",
      "Epoch 9/30\n",
      "2711/2711 [==============================] - 6s 2ms/step - loss: 0.0604 - binary_accuracy: 0.9804 - val_loss: 0.1819 - val_binary_accuracy: 0.9549\n",
      "Epoch 10/30\n",
      "2711/2711 [==============================] - 6s 2ms/step - loss: 0.0588 - binary_accuracy: 0.9811 - val_loss: 0.1889 - val_binary_accuracy: 0.9556\n",
      "Epoch 11/30\n",
      "2711/2711 [==============================] - 6s 2ms/step - loss: 0.0525 - binary_accuracy: 0.9834 - val_loss: 0.1917 - val_binary_accuracy: 0.9576\n",
      "Epoch 12/30\n",
      "2711/2711 [==============================] - 6s 2ms/step - loss: 0.0506 - binary_accuracy: 0.9841 - val_loss: 0.1916 - val_binary_accuracy: 0.9565\n",
      "Epoch 13/30\n",
      "2711/2711 [==============================] - 6s 2ms/step - loss: 0.0454 - binary_accuracy: 0.9859 - val_loss: 0.2102 - val_binary_accuracy: 0.9573\n",
      "Epoch 14/30\n",
      "2711/2711 [==============================] - 6s 2ms/step - loss: 0.0418 - binary_accuracy: 0.9867 - val_loss: 0.2129 - val_binary_accuracy: 0.9575\n",
      "Epoch 15/30\n",
      "2711/2711 [==============================] - 6s 2ms/step - loss: 0.0374 - binary_accuracy: 0.9883 - val_loss: 0.2253 - val_binary_accuracy: 0.9584\n",
      "Epoch 16/30\n",
      "2711/2711 [==============================] - 6s 2ms/step - loss: 0.0364 - binary_accuracy: 0.9893 - val_loss: 0.2538 - val_binary_accuracy: 0.9571\n",
      "Epoch 17/30\n",
      "2711/2711 [==============================] - 6s 2ms/step - loss: 0.0345 - binary_accuracy: 0.9894 - val_loss: 0.2340 - val_binary_accuracy: 0.9598\n",
      "Epoch 18/30\n",
      "2711/2711 [==============================] - 6s 2ms/step - loss: 0.0360 - binary_accuracy: 0.9894 - val_loss: 0.2479 - val_binary_accuracy: 0.9567\n",
      "Epoch 19/30\n",
      "2711/2711 [==============================] - 6s 2ms/step - loss: 0.0297 - binary_accuracy: 0.9905 - val_loss: 0.2730 - val_binary_accuracy: 0.9571\n",
      "Epoch 20/30\n",
      "2711/2711 [==============================] - 6s 2ms/step - loss: 0.0336 - binary_accuracy: 0.9902 - val_loss: 0.2665 - val_binary_accuracy: 0.9547\n",
      "Epoch 21/30\n",
      "2711/2711 [==============================] - 6s 2ms/step - loss: 0.0300 - binary_accuracy: 0.9908 - val_loss: 0.2735 - val_binary_accuracy: 0.9573\n",
      "Epoch 22/30\n",
      "2711/2711 [==============================] - 6s 2ms/step - loss: 0.0258 - binary_accuracy: 0.9921 - val_loss: 0.3163 - val_binary_accuracy: 0.9558\n",
      "Epoch 23/30\n",
      "2711/2711 [==============================] - 6s 2ms/step - loss: 0.0297 - binary_accuracy: 0.9914 - val_loss: 0.3318 - val_binary_accuracy: 0.9551\n",
      "Epoch 24/30\n",
      "2711/2711 [==============================] - 6s 2ms/step - loss: 0.0301 - binary_accuracy: 0.9907 - val_loss: 0.3069 - val_binary_accuracy: 0.9560\n",
      "Epoch 25/30\n",
      "2711/2711 [==============================] - 6s 2ms/step - loss: 0.0257 - binary_accuracy: 0.9919 - val_loss: 0.2807 - val_binary_accuracy: 0.9554\n",
      "Epoch 26/30\n",
      "2711/2711 [==============================] - 6s 2ms/step - loss: 0.0269 - binary_accuracy: 0.9921 - val_loss: 0.2827 - val_binary_accuracy: 0.9560\n",
      "Epoch 27/30\n",
      "2711/2711 [==============================] - 6s 2ms/step - loss: 0.0259 - binary_accuracy: 0.9922 - val_loss: 0.3249 - val_binary_accuracy: 0.9565\n",
      "Epoch 28/30\n",
      "2711/2711 [==============================] - 6s 2ms/step - loss: 0.0253 - binary_accuracy: 0.9926 - val_loss: 0.3011 - val_binary_accuracy: 0.9573\n",
      "Epoch 29/30\n",
      "2711/2711 [==============================] - 6s 2ms/step - loss: 0.0230 - binary_accuracy: 0.9931 - val_loss: 0.3379 - val_binary_accuracy: 0.9573\n",
      "Epoch 30/30\n",
      "2711/2711 [==============================] - 6s 2ms/step - loss: 0.0258 - binary_accuracy: 0.9926 - val_loss: 0.3026 - val_binary_accuracy: 0.9573\n",
      "303/303 [==============================] - 0s 378us/step\n",
      "Fold 4 :\n",
      "\n",
      "Train on 2713 samples, validate on 301 samples\n",
      "Epoch 1/30\n",
      "2713/2713 [==============================] - 12s 5ms/step - loss: 0.1705 - binary_accuracy: 0.9460 - val_loss: 0.1491 - val_binary_accuracy: 0.9513\n",
      "Epoch 2/30\n",
      "2713/2713 [==============================] - 7s 2ms/step - loss: 0.1396 - binary_accuracy: 0.9539 - val_loss: 0.1437 - val_binary_accuracy: 0.9507\n",
      "Epoch 3/30\n",
      "2713/2713 [==============================] - 7s 2ms/step - loss: 0.1179 - binary_accuracy: 0.9615 - val_loss: 0.1302 - val_binary_accuracy: 0.9575\n",
      "Epoch 4/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.1058 - binary_accuracy: 0.9666 - val_loss: 0.1332 - val_binary_accuracy: 0.9601\n",
      "Epoch 5/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0990 - binary_accuracy: 0.9685 - val_loss: 0.1267 - val_binary_accuracy: 0.9599\n",
      "Epoch 6/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0854 - binary_accuracy: 0.9723 - val_loss: 0.1439 - val_binary_accuracy: 0.9583\n",
      "Epoch 7/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0795 - binary_accuracy: 0.9743 - val_loss: 0.1473 - val_binary_accuracy: 0.9551\n",
      "Epoch 8/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0727 - binary_accuracy: 0.9772 - val_loss: 0.1412 - val_binary_accuracy: 0.9588\n",
      "Epoch 9/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0657 - binary_accuracy: 0.9786 - val_loss: 0.1507 - val_binary_accuracy: 0.9594\n",
      "Epoch 10/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0612 - binary_accuracy: 0.9807 - val_loss: 0.1745 - val_binary_accuracy: 0.9555\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0590 - binary_accuracy: 0.9810 - val_loss: 0.1465 - val_binary_accuracy: 0.9618\n",
      "Epoch 12/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0552 - binary_accuracy: 0.9830 - val_loss: 0.1632 - val_binary_accuracy: 0.9596\n",
      "Epoch 13/30\n",
      "2713/2713 [==============================] - ETA: 0s - loss: 0.0495 - binary_accuracy: 0.984 - 6s 2ms/step - loss: 0.0494 - binary_accuracy: 0.9842 - val_loss: 0.1882 - val_binary_accuracy: 0.9592\n",
      "Epoch 14/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0468 - binary_accuracy: 0.9854 - val_loss: 0.1991 - val_binary_accuracy: 0.9594\n",
      "Epoch 15/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0453 - binary_accuracy: 0.9858 - val_loss: 0.1786 - val_binary_accuracy: 0.9581\n",
      "Epoch 16/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0421 - binary_accuracy: 0.9866 - val_loss: 0.2040 - val_binary_accuracy: 0.9566\n",
      "Epoch 17/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0404 - binary_accuracy: 0.9873 - val_loss: 0.1881 - val_binary_accuracy: 0.9618\n",
      "Epoch 18/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0410 - binary_accuracy: 0.9879 - val_loss: 0.2148 - val_binary_accuracy: 0.9585\n",
      "Epoch 19/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0401 - binary_accuracy: 0.9877 - val_loss: 0.2138 - val_binary_accuracy: 0.9607\n",
      "Epoch 20/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0363 - binary_accuracy: 0.9889 - val_loss: 0.2111 - val_binary_accuracy: 0.9598\n",
      "Epoch 21/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0390 - binary_accuracy: 0.9884 - val_loss: 0.2469 - val_binary_accuracy: 0.9572\n",
      "Epoch 22/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0361 - binary_accuracy: 0.9887 - val_loss: 0.2260 - val_binary_accuracy: 0.9587\n",
      "Epoch 23/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0329 - binary_accuracy: 0.9897 - val_loss: 0.2341 - val_binary_accuracy: 0.9577\n",
      "Epoch 24/30\n",
      "2713/2713 [==============================] - ETA: 0s - loss: 0.0301 - binary_accuracy: 0.990 - 6s 2ms/step - loss: 0.0301 - binary_accuracy: 0.9906 - val_loss: 0.2873 - val_binary_accuracy: 0.9540\n",
      "Epoch 25/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0284 - binary_accuracy: 0.9909 - val_loss: 0.2846 - val_binary_accuracy: 0.9592\n",
      "Epoch 26/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0257 - binary_accuracy: 0.9916 - val_loss: 0.2782 - val_binary_accuracy: 0.9594\n",
      "Epoch 27/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0276 - binary_accuracy: 0.9914 - val_loss: 0.2721 - val_binary_accuracy: 0.9550\n",
      "Epoch 28/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0283 - binary_accuracy: 0.9912 - val_loss: 0.2565 - val_binary_accuracy: 0.9570\n",
      "Epoch 29/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0248 - binary_accuracy: 0.9920 - val_loss: 0.2689 - val_binary_accuracy: 0.9574\n",
      "Epoch 30/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0234 - binary_accuracy: 0.9923 - val_loss: 0.2854 - val_binary_accuracy: 0.9568\n",
      "301/301 [==============================] - 0s 396us/step\n",
      "Fold 5 :\n",
      "\n",
      "Train on 2713 samples, validate on 301 samples\n",
      "Epoch 1/30\n",
      "2713/2713 [==============================] - 12s 4ms/step - loss: 0.1681 - binary_accuracy: 0.9455 - val_loss: 0.1448 - val_binary_accuracy: 0.9504\n",
      "Epoch 2/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.1350 - binary_accuracy: 0.9556 - val_loss: 0.1212 - val_binary_accuracy: 0.9611\n",
      "Epoch 3/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.1158 - binary_accuracy: 0.9628 - val_loss: 0.1200 - val_binary_accuracy: 0.9609\n",
      "Epoch 4/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.1048 - binary_accuracy: 0.9666 - val_loss: 0.1194 - val_binary_accuracy: 0.9633\n",
      "Epoch 5/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0936 - binary_accuracy: 0.9703 - val_loss: 0.1218 - val_binary_accuracy: 0.9629\n",
      "Epoch 6/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0841 - binary_accuracy: 0.9722 - val_loss: 0.1430 - val_binary_accuracy: 0.9629\n",
      "Epoch 7/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0759 - binary_accuracy: 0.9760 - val_loss: 0.1398 - val_binary_accuracy: 0.9629\n",
      "Epoch 8/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0688 - binary_accuracy: 0.9778 - val_loss: 0.1426 - val_binary_accuracy: 0.9660\n",
      "Epoch 9/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0615 - binary_accuracy: 0.9792 - val_loss: 0.1470 - val_binary_accuracy: 0.9642\n",
      "Epoch 10/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0603 - binary_accuracy: 0.9805 - val_loss: 0.1470 - val_binary_accuracy: 0.9623\n",
      "Epoch 11/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0524 - binary_accuracy: 0.9827 - val_loss: 0.1675 - val_binary_accuracy: 0.9638\n",
      "Epoch 12/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0536 - binary_accuracy: 0.9827 - val_loss: 0.1683 - val_binary_accuracy: 0.9655\n",
      "Epoch 13/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0480 - binary_accuracy: 0.9845 - val_loss: 0.1706 - val_binary_accuracy: 0.9657\n",
      "Epoch 14/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0426 - binary_accuracy: 0.9861 - val_loss: 0.1539 - val_binary_accuracy: 0.9671\n",
      "Epoch 15/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0434 - binary_accuracy: 0.9864 - val_loss: 0.2040 - val_binary_accuracy: 0.9651\n",
      "Epoch 16/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0420 - binary_accuracy: 0.9877 - val_loss: 0.1535 - val_binary_accuracy: 0.9677\n",
      "Epoch 17/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0377 - binary_accuracy: 0.9885 - val_loss: 0.1816 - val_binary_accuracy: 0.9690\n",
      "Epoch 18/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0385 - binary_accuracy: 0.9880 - val_loss: 0.2025 - val_binary_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0354 - binary_accuracy: 0.9889 - val_loss: 0.1969 - val_binary_accuracy: 0.9683\n",
      "Epoch 20/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0291 - binary_accuracy: 0.9906 - val_loss: 0.2052 - val_binary_accuracy: 0.9694\n",
      "Epoch 21/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0300 - binary_accuracy: 0.9905 - val_loss: 0.1989 - val_binary_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0306 - binary_accuracy: 0.9904 - val_loss: 0.1838 - val_binary_accuracy: 0.9690\n",
      "Epoch 23/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0287 - binary_accuracy: 0.9910 - val_loss: 0.2017 - val_binary_accuracy: 0.9655\n",
      "Epoch 24/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0300 - binary_accuracy: 0.9911 - val_loss: 0.2414 - val_binary_accuracy: 0.9666\n",
      "Epoch 25/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0289 - binary_accuracy: 0.9917 - val_loss: 0.2390 - val_binary_accuracy: 0.9660\n",
      "Epoch 26/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0282 - binary_accuracy: 0.9912 - val_loss: 0.1956 - val_binary_accuracy: 0.9701\n",
      "Epoch 27/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0259 - binary_accuracy: 0.9920 - val_loss: 0.2180 - val_binary_accuracy: 0.9679\n",
      "Epoch 28/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0277 - binary_accuracy: 0.9915 - val_loss: 0.2205 - val_binary_accuracy: 0.9681\n",
      "Epoch 29/30\n",
      "2713/2713 [==============================] - 7s 2ms/step - loss: 0.0248 - binary_accuracy: 0.9923 - val_loss: 0.2085 - val_binary_accuracy: 0.9686\n",
      "Epoch 30/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0256 - binary_accuracy: 0.9921 - val_loss: 0.1984 - val_binary_accuracy: 0.9695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301/301 [==============================] - 0s 388us/step\n",
      "Fold 6 :\n",
      "\n",
      "Train on 2713 samples, validate on 301 samples\n",
      "Epoch 1/30\n",
      "2713/2713 [==============================] - 12s 4ms/step - loss: 0.1682 - binary_accuracy: 0.9468 - val_loss: 0.1516 - val_binary_accuracy: 0.9494\n",
      "Epoch 2/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.1346 - binary_accuracy: 0.9556 - val_loss: 0.1354 - val_binary_accuracy: 0.9570\n",
      "Epoch 3/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.1149 - binary_accuracy: 0.9628 - val_loss: 0.1356 - val_binary_accuracy: 0.9553\n",
      "Epoch 4/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.1042 - binary_accuracy: 0.9660 - val_loss: 0.1350 - val_binary_accuracy: 0.9585\n",
      "Epoch 5/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0939 - binary_accuracy: 0.9700 - val_loss: 0.1437 - val_binary_accuracy: 0.9574\n",
      "Epoch 6/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0860 - binary_accuracy: 0.9724 - val_loss: 0.1392 - val_binary_accuracy: 0.9590\n",
      "Epoch 7/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0802 - binary_accuracy: 0.9732 - val_loss: 0.1595 - val_binary_accuracy: 0.9587\n",
      "Epoch 8/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0700 - binary_accuracy: 0.9766 - val_loss: 0.1608 - val_binary_accuracy: 0.9561\n",
      "Epoch 9/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0660 - binary_accuracy: 0.9785 - val_loss: 0.1600 - val_binary_accuracy: 0.9598\n",
      "Epoch 10/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0573 - binary_accuracy: 0.9809 - val_loss: 0.1596 - val_binary_accuracy: 0.9575\n",
      "Epoch 11/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0570 - binary_accuracy: 0.9821 - val_loss: 0.1546 - val_binary_accuracy: 0.9579\n",
      "Epoch 12/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0534 - binary_accuracy: 0.9829 - val_loss: 0.1716 - val_binary_accuracy: 0.9579\n",
      "Epoch 13/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0464 - binary_accuracy: 0.9851 - val_loss: 0.1921 - val_binary_accuracy: 0.9561\n",
      "Epoch 14/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0424 - binary_accuracy: 0.9864 - val_loss: 0.1907 - val_binary_accuracy: 0.9564\n",
      "Epoch 15/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0395 - binary_accuracy: 0.9874 - val_loss: 0.1930 - val_binary_accuracy: 0.9566\n",
      "Epoch 16/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0386 - binary_accuracy: 0.9877 - val_loss: 0.2267 - val_binary_accuracy: 0.9553\n",
      "Epoch 17/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0365 - binary_accuracy: 0.9885 - val_loss: 0.2137 - val_binary_accuracy: 0.9564\n",
      "Epoch 18/30\n",
      "2713/2713 [==============================] - 7s 2ms/step - loss: 0.0459 - binary_accuracy: 0.9857 - val_loss: 0.2280 - val_binary_accuracy: 0.9553\n",
      "Epoch 19/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0364 - binary_accuracy: 0.9892 - val_loss: 0.2257 - val_binary_accuracy: 0.9550\n",
      "Epoch 20/30\n",
      "2713/2713 [==============================] - 6s 2ms/step - loss: 0.0332 - binary_accuracy: 0.9901 - val_loss: 0.2323 - val_binary_accuracy: 0.9564\n",
      "Epoch 21/30\n",
      "2713/2713 [==============================] - 7s 3ms/step - loss: 0.0331 - binary_accuracy: 0.9897 - val_loss: 0.2629 - val_binary_accuracy: 0.9546\n",
      "Epoch 22/30\n",
      "2713/2713 [==============================] - 7s 3ms/step - loss: 0.0313 - binary_accuracy: 0.9903 - val_loss: 0.2210 - val_binary_accuracy: 0.9570\n",
      "Epoch 23/30\n",
      "2713/2713 [==============================] - 7s 3ms/step - loss: 0.0281 - binary_accuracy: 0.9912 - val_loss: 0.2332 - val_binary_accuracy: 0.9559\n",
      "Epoch 24/30\n",
      "2713/2713 [==============================] - 7s 3ms/step - loss: 0.0288 - binary_accuracy: 0.9912 - val_loss: 0.2278 - val_binary_accuracy: 0.9555\n",
      "Epoch 25/30\n",
      "2713/2713 [==============================] - 7s 2ms/step - loss: 0.0292 - binary_accuracy: 0.9911 - val_loss: 0.2341 - val_binary_accuracy: 0.9590\n",
      "Epoch 26/30\n",
      "2713/2713 [==============================] - 7s 3ms/step - loss: 0.0275 - binary_accuracy: 0.9914 - val_loss: 0.2571 - val_binary_accuracy: 0.9574\n",
      "Epoch 27/30\n",
      "2713/2713 [==============================] - 7s 3ms/step - loss: 0.0279 - binary_accuracy: 0.9914 - val_loss: 0.2884 - val_binary_accuracy: 0.9544\n",
      "Epoch 28/30\n",
      "2713/2713 [==============================] - 7s 3ms/step - loss: 0.0328 - binary_accuracy: 0.9904 - val_loss: 0.2421 - val_binary_accuracy: 0.9561\n",
      "Epoch 29/30\n",
      "2713/2713 [==============================] - 8s 3ms/step - loss: 0.0289 - binary_accuracy: 0.9914 - val_loss: 0.2716 - val_binary_accuracy: 0.9561\n",
      "Epoch 30/30\n",
      "2713/2713 [==============================] - 8s 3ms/step - loss: 0.0273 - binary_accuracy: 0.9914 - val_loss: 0.2645 - val_binary_accuracy: 0.9577\n",
      "301/301 [==============================] - 0s 408us/step\n",
      "Fold 7 :\n",
      "\n",
      "Train on 2714 samples, validate on 300 samples\n",
      "Epoch 1/30\n",
      "2714/2714 [==============================] - 14s 5ms/step - loss: 0.1699 - binary_accuracy: 0.9458 - val_loss: 0.1558 - val_binary_accuracy: 0.9485\n",
      "Epoch 2/30\n",
      "2714/2714 [==============================] - 7s 2ms/step - loss: 0.1399 - binary_accuracy: 0.9542 - val_loss: 0.1313 - val_binary_accuracy: 0.9559\n",
      "Epoch 3/30\n",
      "2714/2714 [==============================] - 7s 2ms/step - loss: 0.1188 - binary_accuracy: 0.9617 - val_loss: 0.1306 - val_binary_accuracy: 0.9583\n",
      "Epoch 4/30\n",
      "2714/2714 [==============================] - 7s 2ms/step - loss: 0.1082 - binary_accuracy: 0.9652 - val_loss: 0.1469 - val_binary_accuracy: 0.9578\n",
      "Epoch 5/30\n",
      "2714/2714 [==============================] - 7s 3ms/step - loss: 0.0953 - binary_accuracy: 0.9694 - val_loss: 0.1291 - val_binary_accuracy: 0.9591\n",
      "Epoch 6/30\n",
      "2714/2714 [==============================] - 7s 2ms/step - loss: 0.0856 - binary_accuracy: 0.9725 - val_loss: 0.1330 - val_binary_accuracy: 0.9593\n",
      "Epoch 7/30\n",
      "2714/2714 [==============================] - 7s 3ms/step - loss: 0.0791 - binary_accuracy: 0.9744 - val_loss: 0.1506 - val_binary_accuracy: 0.9604\n",
      "Epoch 8/30\n",
      "2714/2714 [==============================] - 7s 2ms/step - loss: 0.0731 - binary_accuracy: 0.9763 - val_loss: 0.1595 - val_binary_accuracy: 0.9598\n",
      "Epoch 9/30\n",
      "2714/2714 [==============================] - 7s 2ms/step - loss: 0.0675 - binary_accuracy: 0.9778 - val_loss: 0.1571 - val_binary_accuracy: 0.9606\n",
      "Epoch 10/30\n",
      "2714/2714 [==============================] - 7s 2ms/step - loss: 0.0589 - binary_accuracy: 0.9809 - val_loss: 0.1890 - val_binary_accuracy: 0.9596\n",
      "Epoch 11/30\n",
      "2714/2714 [==============================] - 7s 2ms/step - loss: 0.0573 - binary_accuracy: 0.9812 - val_loss: 0.2070 - val_binary_accuracy: 0.9611\n",
      "Epoch 12/30\n",
      "2714/2714 [==============================] - 7s 2ms/step - loss: 0.0524 - binary_accuracy: 0.9835 - val_loss: 0.1968 - val_binary_accuracy: 0.9604\n",
      "Epoch 13/30\n",
      "2714/2714 [==============================] - 7s 2ms/step - loss: 0.0457 - binary_accuracy: 0.9853 - val_loss: 0.2054 - val_binary_accuracy: 0.9598\n",
      "Epoch 14/30\n",
      "2714/2714 [==============================] - 7s 2ms/step - loss: 0.0443 - binary_accuracy: 0.9858 - val_loss: 0.2101 - val_binary_accuracy: 0.9606\n",
      "Epoch 15/30\n",
      "2714/2714 [==============================] - 7s 2ms/step - loss: 0.0439 - binary_accuracy: 0.9860 - val_loss: 0.2214 - val_binary_accuracy: 0.9593\n",
      "Epoch 16/30\n",
      "2714/2714 [==============================] - 7s 2ms/step - loss: 0.0396 - binary_accuracy: 0.9874 - val_loss: 0.2224 - val_binary_accuracy: 0.9598\n",
      "Epoch 17/30\n",
      "2714/2714 [==============================] - 7s 2ms/step - loss: 0.0396 - binary_accuracy: 0.9878 - val_loss: 0.2349 - val_binary_accuracy: 0.9602\n",
      "Epoch 18/30\n",
      "2714/2714 [==============================] - 7s 2ms/step - loss: 0.0397 - binary_accuracy: 0.9878 - val_loss: 0.2347 - val_binary_accuracy: 0.9622\n",
      "Epoch 19/30\n",
      "2714/2714 [==============================] - 7s 2ms/step - loss: 0.0382 - binary_accuracy: 0.9876 - val_loss: 0.2332 - val_binary_accuracy: 0.9602\n",
      "Epoch 20/30\n",
      "2714/2714 [==============================] - 7s 2ms/step - loss: 0.0357 - binary_accuracy: 0.9888 - val_loss: 0.2680 - val_binary_accuracy: 0.9581\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2714/2714 [==============================] - 6s 2ms/step - loss: 0.0378 - binary_accuracy: 0.9886 - val_loss: 0.2205 - val_binary_accuracy: 0.9617\n",
      "Epoch 22/30\n",
      "2714/2714 [==============================] - 6s 2ms/step - loss: 0.0352 - binary_accuracy: 0.9889 - val_loss: 0.2323 - val_binary_accuracy: 0.9620\n",
      "Epoch 23/30\n",
      "2714/2714 [==============================] - 6s 2ms/step - loss: 0.0282 - binary_accuracy: 0.9908 - val_loss: 0.2392 - val_binary_accuracy: 0.9620\n",
      "Epoch 24/30\n",
      "2714/2714 [==============================] - 6s 2ms/step - loss: 0.0289 - binary_accuracy: 0.9909 - val_loss: 0.2393 - val_binary_accuracy: 0.9615\n",
      "Epoch 25/30\n",
      "2714/2714 [==============================] - 6s 2ms/step - loss: 0.0275 - binary_accuracy: 0.9916 - val_loss: 0.2681 - val_binary_accuracy: 0.9613\n",
      "Epoch 26/30\n",
      "2714/2714 [==============================] - 6s 2ms/step - loss: 0.0251 - binary_accuracy: 0.9918 - val_loss: 0.2700 - val_binary_accuracy: 0.9607\n",
      "Epoch 27/30\n",
      "2714/2714 [==============================] - 6s 2ms/step - loss: 0.0249 - binary_accuracy: 0.9919 - val_loss: 0.2861 - val_binary_accuracy: 0.9602\n",
      "Epoch 28/30\n",
      "2714/2714 [==============================] - 6s 2ms/step - loss: 0.0290 - binary_accuracy: 0.9909 - val_loss: 0.3070 - val_binary_accuracy: 0.9622\n",
      "Epoch 29/30\n",
      "2714/2714 [==============================] - 6s 2ms/step - loss: 0.0225 - binary_accuracy: 0.9922 - val_loss: 0.3230 - val_binary_accuracy: 0.9593\n",
      "Epoch 30/30\n",
      "2714/2714 [==============================] - 6s 2ms/step - loss: 0.0233 - binary_accuracy: 0.9924 - val_loss: 0.3130 - val_binary_accuracy: 0.9609\n",
      "300/300 [==============================] - 0s 355us/step\n",
      "Fold 8 :\n",
      "\n",
      "Train on 2717 samples, validate on 297 samples\n",
      "Epoch 1/30\n",
      "2717/2717 [==============================] - 17s 6ms/step - loss: 0.1671 - binary_accuracy: 0.9466 - val_loss: 0.1438 - val_binary_accuracy: 0.9512\n",
      "Epoch 2/30\n",
      "2717/2717 [==============================] - 8s 3ms/step - loss: 0.1374 - binary_accuracy: 0.9539 - val_loss: 0.1284 - val_binary_accuracy: 0.9549\n",
      "Epoch 3/30\n",
      "2717/2717 [==============================] - 7s 3ms/step - loss: 0.1139 - binary_accuracy: 0.9624 - val_loss: 0.1407 - val_binary_accuracy: 0.9549\n",
      "Epoch 4/30\n",
      "2717/2717 [==============================] - 6s 2ms/step - loss: 0.1056 - binary_accuracy: 0.9664 - val_loss: 0.1320 - val_binary_accuracy: 0.9594\n",
      "Epoch 5/30\n",
      "2717/2717 [==============================] - 6s 2ms/step - loss: 0.0952 - binary_accuracy: 0.9691 - val_loss: 0.1415 - val_binary_accuracy: 0.9583\n",
      "Epoch 6/30\n",
      "2717/2717 [==============================] - 6s 2ms/step - loss: 0.0865 - binary_accuracy: 0.9729 - val_loss: 0.1457 - val_binary_accuracy: 0.9613\n",
      "Epoch 7/30\n",
      "2717/2717 [==============================] - 6s 2ms/step - loss: 0.0832 - binary_accuracy: 0.9733 - val_loss: 0.1554 - val_binary_accuracy: 0.9594\n",
      "Epoch 8/30\n",
      "2717/2717 [==============================] - 6s 2ms/step - loss: 0.0718 - binary_accuracy: 0.9764 - val_loss: 0.1669 - val_binary_accuracy: 0.9615\n",
      "Epoch 9/30\n",
      "2717/2717 [==============================] - 6s 2ms/step - loss: 0.0671 - binary_accuracy: 0.9781 - val_loss: 0.1606 - val_binary_accuracy: 0.9609\n",
      "Epoch 10/30\n",
      "2717/2717 [==============================] - 6s 2ms/step - loss: 0.0607 - binary_accuracy: 0.9798 - val_loss: 0.1729 - val_binary_accuracy: 0.9615\n",
      "Epoch 11/30\n",
      "2717/2717 [==============================] - 6s 2ms/step - loss: 0.0557 - binary_accuracy: 0.9823 - val_loss: 0.1642 - val_binary_accuracy: 0.9628\n",
      "Epoch 12/30\n",
      "2717/2717 [==============================] - 6s 2ms/step - loss: 0.0522 - binary_accuracy: 0.9832 - val_loss: 0.1998 - val_binary_accuracy: 0.9622\n",
      "Epoch 13/30\n",
      "2717/2717 [==============================] - 7s 2ms/step - loss: 0.0500 - binary_accuracy: 0.9846 - val_loss: 0.1937 - val_binary_accuracy: 0.9602\n",
      "Epoch 14/30\n",
      "2717/2717 [==============================] - 6s 2ms/step - loss: 0.0463 - binary_accuracy: 0.9859 - val_loss: 0.1783 - val_binary_accuracy: 0.9611\n",
      "Epoch 15/30\n",
      "2717/2717 [==============================] - 6s 2ms/step - loss: 0.0426 - binary_accuracy: 0.9864 - val_loss: 0.2020 - val_binary_accuracy: 0.9603\n",
      "Epoch 16/30\n",
      "2717/2717 [==============================] - 7s 3ms/step - loss: 0.0408 - binary_accuracy: 0.9875 - val_loss: 0.2174 - val_binary_accuracy: 0.9622\n",
      "Epoch 17/30\n",
      "2717/2717 [==============================] - 7s 2ms/step - loss: 0.0359 - binary_accuracy: 0.9890 - val_loss: 0.2199 - val_binary_accuracy: 0.9628\n",
      "Epoch 18/30\n",
      "2717/2717 [==============================] - 7s 3ms/step - loss: 0.0367 - binary_accuracy: 0.9885 - val_loss: 0.1921 - val_binary_accuracy: 0.9585\n",
      "Epoch 19/30\n",
      "2717/2717 [==============================] - 7s 2ms/step - loss: 0.0343 - binary_accuracy: 0.9893 - val_loss: 0.2326 - val_binary_accuracy: 0.9609\n",
      "Epoch 20/30\n",
      "2717/2717 [==============================] - 7s 2ms/step - loss: 0.0366 - binary_accuracy: 0.9888 - val_loss: 0.2138 - val_binary_accuracy: 0.9620\n",
      "Epoch 21/30\n",
      "2717/2717 [==============================] - 7s 3ms/step - loss: 0.0324 - binary_accuracy: 0.9902 - val_loss: 0.2325 - val_binary_accuracy: 0.9605\n",
      "Epoch 22/30\n",
      "2717/2717 [==============================] - 7s 2ms/step - loss: 0.0339 - binary_accuracy: 0.9899 - val_loss: 0.2476 - val_binary_accuracy: 0.9618\n",
      "Epoch 23/30\n",
      "2717/2717 [==============================] - 7s 2ms/step - loss: 0.0326 - binary_accuracy: 0.9903 - val_loss: 0.2617 - val_binary_accuracy: 0.9596\n",
      "Epoch 24/30\n",
      "2717/2717 [==============================] - 7s 2ms/step - loss: 0.0327 - binary_accuracy: 0.9907 - val_loss: 0.2495 - val_binary_accuracy: 0.9592\n",
      "Epoch 25/30\n",
      "2717/2717 [==============================] - 7s 3ms/step - loss: 0.0316 - binary_accuracy: 0.9907 - val_loss: 0.2483 - val_binary_accuracy: 0.9624\n",
      "Epoch 26/30\n",
      "2717/2717 [==============================] - 7s 3ms/step - loss: 0.0277 - binary_accuracy: 0.9918 - val_loss: 0.2632 - val_binary_accuracy: 0.9603\n",
      "Epoch 27/30\n",
      "2717/2717 [==============================] - 7s 3ms/step - loss: 0.0273 - binary_accuracy: 0.9918 - val_loss: 0.2526 - val_binary_accuracy: 0.9590\n",
      "Epoch 28/30\n",
      "2717/2717 [==============================] - 7s 3ms/step - loss: 0.0280 - binary_accuracy: 0.9918 - val_loss: 0.2716 - val_binary_accuracy: 0.9611\n",
      "Epoch 29/30\n",
      "2717/2717 [==============================] - 7s 3ms/step - loss: 0.0313 - binary_accuracy: 0.9909 - val_loss: 0.2466 - val_binary_accuracy: 0.9639\n",
      "Epoch 30/30\n",
      "2717/2717 [==============================] - 7s 3ms/step - loss: 0.0244 - binary_accuracy: 0.9923 - val_loss: 0.2896 - val_binary_accuracy: 0.9603\n",
      "297/297 [==============================] - 0s 934us/step\n",
      "Fold 9 :\n",
      "\n",
      "Train on 2717 samples, validate on 297 samples\n",
      "Epoch 1/30\n",
      "2717/2717 [==============================] - 17s 6ms/step - loss: 0.1684 - binary_accuracy: 0.9466 - val_loss: 0.1460 - val_binary_accuracy: 0.9506\n",
      "Epoch 2/30\n",
      "2717/2717 [==============================] - 7s 3ms/step - loss: 0.1371 - binary_accuracy: 0.9546 - val_loss: 0.1225 - val_binary_accuracy: 0.9603\n",
      "Epoch 3/30\n",
      "2717/2717 [==============================] - 7s 3ms/step - loss: 0.1187 - binary_accuracy: 0.9616 - val_loss: 0.1132 - val_binary_accuracy: 0.9643\n",
      "Epoch 4/30\n",
      "2717/2717 [==============================] - 7s 3ms/step - loss: 0.1049 - binary_accuracy: 0.9664 - val_loss: 0.1224 - val_binary_accuracy: 0.9594\n",
      "Epoch 5/30\n",
      "2717/2717 [==============================] - 7s 3ms/step - loss: 0.0950 - binary_accuracy: 0.9693 - val_loss: 0.1201 - val_binary_accuracy: 0.9603\n",
      "Epoch 6/30\n",
      "2717/2717 [==============================] - 7s 3ms/step - loss: 0.0858 - binary_accuracy: 0.9728 - val_loss: 0.1267 - val_binary_accuracy: 0.9609\n",
      "Epoch 7/30\n",
      "2717/2717 [==============================] - 7s 3ms/step - loss: 0.0799 - binary_accuracy: 0.9738 - val_loss: 0.1299 - val_binary_accuracy: 0.9633\n",
      "Epoch 8/30\n",
      "2717/2717 [==============================] - 7s 3ms/step - loss: 0.0759 - binary_accuracy: 0.9753 - val_loss: 0.1405 - val_binary_accuracy: 0.9633\n",
      "Epoch 9/30\n",
      "2717/2717 [==============================] - 7s 3ms/step - loss: 0.0675 - binary_accuracy: 0.9785 - val_loss: 0.1484 - val_binary_accuracy: 0.9617\n",
      "Epoch 10/30\n",
      "2717/2717 [==============================] - 7s 3ms/step - loss: 0.0611 - binary_accuracy: 0.9797 - val_loss: 0.1355 - val_binary_accuracy: 0.9661\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2717/2717 [==============================] - 7s 2ms/step - loss: 0.0562 - binary_accuracy: 0.9813 - val_loss: 0.1443 - val_binary_accuracy: 0.9654\n",
      "Epoch 12/30\n",
      "2717/2717 [==============================] - 7s 2ms/step - loss: 0.0535 - binary_accuracy: 0.9824 - val_loss: 0.1562 - val_binary_accuracy: 0.9652\n",
      "Epoch 13/30\n",
      "2717/2717 [==============================] - 7s 2ms/step - loss: 0.0495 - binary_accuracy: 0.9837 - val_loss: 0.1587 - val_binary_accuracy: 0.9673\n",
      "Epoch 14/30\n",
      "2717/2717 [==============================] - 7s 2ms/step - loss: 0.0473 - binary_accuracy: 0.9847 - val_loss: 0.1590 - val_binary_accuracy: 0.9654\n",
      "Epoch 15/30\n",
      "2717/2717 [==============================] - 7s 2ms/step - loss: 0.0431 - binary_accuracy: 0.9861 - val_loss: 0.1800 - val_binary_accuracy: 0.9641\n",
      "Epoch 16/30\n",
      "2717/2717 [==============================] - 7s 3ms/step - loss: 0.0410 - binary_accuracy: 0.9875 - val_loss: 0.1768 - val_binary_accuracy: 0.9669\n",
      "Epoch 17/30\n",
      "2717/2717 [==============================] - 7s 3ms/step - loss: 0.0359 - binary_accuracy: 0.9888 - val_loss: 0.1749 - val_binary_accuracy: 0.9646\n",
      "Epoch 18/30\n",
      "2717/2717 [==============================] - 7s 3ms/step - loss: 0.0377 - binary_accuracy: 0.9885 - val_loss: 0.1755 - val_binary_accuracy: 0.9633\n",
      "Epoch 19/30\n",
      "2717/2717 [==============================] - 7s 3ms/step - loss: 0.0364 - binary_accuracy: 0.9888 - val_loss: 0.1901 - val_binary_accuracy: 0.9658\n",
      "Epoch 20/30\n",
      "2717/2717 [==============================] - 7s 3ms/step - loss: 0.0346 - binary_accuracy: 0.9900 - val_loss: 0.1725 - val_binary_accuracy: 0.9654\n",
      "Epoch 21/30\n",
      "2717/2717 [==============================] - 7s 3ms/step - loss: 0.0339 - binary_accuracy: 0.9897 - val_loss: 0.2103 - val_binary_accuracy: 0.9630\n",
      "Epoch 22/30\n",
      "2717/2717 [==============================] - 7s 3ms/step - loss: 0.0338 - binary_accuracy: 0.9897 - val_loss: 0.1897 - val_binary_accuracy: 0.9667\n",
      "Epoch 23/30\n",
      "2717/2717 [==============================] - 7s 3ms/step - loss: 0.0332 - binary_accuracy: 0.9905 - val_loss: 0.1996 - val_binary_accuracy: 0.9650\n",
      "Epoch 24/30\n",
      "2717/2717 [==============================] - 6s 2ms/step - loss: 0.0309 - binary_accuracy: 0.9909 - val_loss: 0.1928 - val_binary_accuracy: 0.9643\n",
      "Epoch 25/30\n",
      "2717/2717 [==============================] - 7s 2ms/step - loss: 0.0280 - binary_accuracy: 0.9916 - val_loss: 0.2112 - val_binary_accuracy: 0.9656\n",
      "Epoch 26/30\n",
      "2717/2717 [==============================] - 7s 3ms/step - loss: 0.0277 - binary_accuracy: 0.9919 - val_loss: 0.2280 - val_binary_accuracy: 0.9639\n",
      "Epoch 27/30\n",
      "2717/2717 [==============================] - 7s 3ms/step - loss: 0.0268 - binary_accuracy: 0.9920 - val_loss: 0.2188 - val_binary_accuracy: 0.9620\n",
      "Epoch 28/30\n",
      "2717/2717 [==============================] - 7s 3ms/step - loss: 0.0254 - binary_accuracy: 0.9925 - val_loss: 0.2188 - val_binary_accuracy: 0.9631\n",
      "Epoch 29/30\n",
      "2717/2717 [==============================] - 8s 3ms/step - loss: 0.0238 - binary_accuracy: 0.9924 - val_loss: 0.2248 - val_binary_accuracy: 0.9645\n",
      "Epoch 30/30\n",
      "2717/2717 [==============================] - 9s 3ms/step - loss: 0.0258 - binary_accuracy: 0.9926 - val_loss: 0.2104 - val_binary_accuracy: 0.9656\n",
      "297/297 [==============================] - 0s 379us/step\n",
      "Fold 10 :\n",
      "\n",
      "Train on 2718 samples, validate on 296 samples\n",
      "Epoch 1/30\n",
      "2718/2718 [==============================] - 18s 7ms/step - loss: 0.1682 - binary_accuracy: 0.9461 - val_loss: 0.1500 - val_binary_accuracy: 0.9505\n",
      "Epoch 2/30\n",
      "2718/2718 [==============================] - 7s 3ms/step - loss: 0.1354 - binary_accuracy: 0.9551 - val_loss: 0.1279 - val_binary_accuracy: 0.9611\n",
      "Epoch 3/30\n",
      "2718/2718 [==============================] - 7s 3ms/step - loss: 0.1170 - binary_accuracy: 0.9624 - val_loss: 0.1172 - val_binary_accuracy: 0.9642\n",
      "Epoch 4/30\n",
      "2718/2718 [==============================] - 7s 3ms/step - loss: 0.1050 - binary_accuracy: 0.9668 - val_loss: 0.1268 - val_binary_accuracy: 0.9602\n",
      "Epoch 5/30\n",
      "2718/2718 [==============================] - 7s 3ms/step - loss: 0.0954 - binary_accuracy: 0.9698 - val_loss: 0.1261 - val_binary_accuracy: 0.9632\n",
      "Epoch 6/30\n",
      "2718/2718 [==============================] - 7s 3ms/step - loss: 0.0851 - binary_accuracy: 0.9728 - val_loss: 0.1352 - val_binary_accuracy: 0.9634\n",
      "Epoch 7/30\n",
      "2718/2718 [==============================] - 7s 3ms/step - loss: 0.0768 - binary_accuracy: 0.9746 - val_loss: 0.1295 - val_binary_accuracy: 0.9638\n",
      "Epoch 8/30\n",
      "2718/2718 [==============================] - 7s 3ms/step - loss: 0.0687 - binary_accuracy: 0.9778 - val_loss: 0.1414 - val_binary_accuracy: 0.9630\n",
      "Epoch 9/30\n",
      "2718/2718 [==============================] - 7s 3ms/step - loss: 0.0643 - binary_accuracy: 0.9793 - val_loss: 0.1456 - val_binary_accuracy: 0.9634\n",
      "Epoch 10/30\n",
      "2718/2718 [==============================] - 7s 3ms/step - loss: 0.0614 - binary_accuracy: 0.9806 - val_loss: 0.1534 - val_binary_accuracy: 0.9610\n",
      "Epoch 11/30\n",
      "2718/2718 [==============================] - 7s 3ms/step - loss: 0.0542 - binary_accuracy: 0.9821 - val_loss: 0.1606 - val_binary_accuracy: 0.9608\n",
      "Epoch 12/30\n",
      "2718/2718 [==============================] - 7s 3ms/step - loss: 0.0501 - binary_accuracy: 0.9838 - val_loss: 0.1512 - val_binary_accuracy: 0.9651\n",
      "Epoch 13/30\n",
      "2718/2718 [==============================] - 7s 3ms/step - loss: 0.0504 - binary_accuracy: 0.9837 - val_loss: 0.1584 - val_binary_accuracy: 0.9647\n",
      "Epoch 14/30\n",
      "2718/2718 [==============================] - 7s 3ms/step - loss: 0.0484 - binary_accuracy: 0.9845 - val_loss: 0.1871 - val_binary_accuracy: 0.9647\n",
      "Epoch 15/30\n",
      "2718/2718 [==============================] - 7s 3ms/step - loss: 0.0424 - binary_accuracy: 0.9864 - val_loss: 0.1583 - val_binary_accuracy: 0.9642\n",
      "Epoch 16/30\n",
      "2718/2718 [==============================] - 7s 3ms/step - loss: 0.0429 - binary_accuracy: 0.9869 - val_loss: 0.1781 - val_binary_accuracy: 0.9651\n",
      "Epoch 17/30\n",
      "2718/2718 [==============================] - 7s 3ms/step - loss: 0.0388 - binary_accuracy: 0.9880 - val_loss: 0.1887 - val_binary_accuracy: 0.9643\n",
      "Epoch 18/30\n",
      "2718/2718 [==============================] - 7s 3ms/step - loss: 0.0391 - binary_accuracy: 0.9880 - val_loss: 0.1966 - val_binary_accuracy: 0.9645\n",
      "Epoch 19/30\n",
      "2718/2718 [==============================] - 7s 3ms/step - loss: 0.0365 - binary_accuracy: 0.9886 - val_loss: 0.2232 - val_binary_accuracy: 0.9625\n",
      "Epoch 20/30\n",
      "2718/2718 [==============================] - 7s 3ms/step - loss: 0.0323 - binary_accuracy: 0.9905 - val_loss: 0.2308 - val_binary_accuracy: 0.9621\n",
      "Epoch 21/30\n",
      "2718/2718 [==============================] - 7s 3ms/step - loss: 0.0322 - binary_accuracy: 0.9902 - val_loss: 0.1941 - val_binary_accuracy: 0.9649\n",
      "Epoch 22/30\n",
      "2718/2718 [==============================] - 7s 3ms/step - loss: 0.0366 - binary_accuracy: 0.9888 - val_loss: 0.1970 - val_binary_accuracy: 0.9642\n",
      "Epoch 23/30\n",
      "2718/2718 [==============================] - 8s 3ms/step - loss: 0.0348 - binary_accuracy: 0.9896 - val_loss: 0.1955 - val_binary_accuracy: 0.9643\n",
      "Epoch 24/30\n",
      "2718/2718 [==============================] - 8s 3ms/step - loss: 0.0301 - binary_accuracy: 0.9902 - val_loss: 0.2095 - val_binary_accuracy: 0.9653\n",
      "Epoch 25/30\n",
      "2718/2718 [==============================] - 8s 3ms/step - loss: 0.0275 - binary_accuracy: 0.9914 - val_loss: 0.2381 - val_binary_accuracy: 0.9636\n",
      "Epoch 26/30\n",
      "2718/2718 [==============================] - 8s 3ms/step - loss: 0.0329 - binary_accuracy: 0.9894 - val_loss: 0.2008 - val_binary_accuracy: 0.9640\n",
      "Epoch 27/30\n",
      "2718/2718 [==============================] - 7s 3ms/step - loss: 0.0269 - binary_accuracy: 0.9916 - val_loss: 0.2374 - val_binary_accuracy: 0.9615\n",
      "Epoch 28/30\n",
      "2718/2718 [==============================] - 7s 3ms/step - loss: 0.0273 - binary_accuracy: 0.9918 - val_loss: 0.2244 - val_binary_accuracy: 0.9655\n",
      "Epoch 29/30\n",
      "2718/2718 [==============================] - 7s 3ms/step - loss: 0.0286 - binary_accuracy: 0.9915 - val_loss: 0.2498 - val_binary_accuracy: 0.9658\n",
      "Epoch 30/30\n",
      "2718/2718 [==============================] - 7s 3ms/step - loss: 0.0258 - binary_accuracy: 0.9915 - val_loss: 0.2192 - val_binary_accuracy: 0.9640\n",
      "296/296 [==============================] - 0s 435us/step\n"
     ]
    }
   ],
   "source": [
    "#k=10, fungsi aktivasi=ReLU, nilai dropout=0.4\n",
    "kf = StratifiedKFold(n_splits=10, random_state=None, shuffle=False)\n",
    "val_loss_cv = []\n",
    "val_acc_cv = []\n",
    "j = 0\n",
    "for train_index, test_index in kf.split(X,z):\n",
    "    j+=1\n",
    "    print(f\"Fold {j} :\")\n",
    "    print(\"\")\n",
    "    X_train,X_test = X.iloc[train_index,:],X.iloc[test_index,:]\n",
    "    y_train,y_test = y.iloc[train_index,:],y.iloc[test_index,:]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim=X_train.shape[1], units=463,\n",
    "                     kernel_initializer='normal', bias_initializer='zeros'))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    for i in range(0, 6):\n",
    "        model.add(Dense(units=463, kernel_initializer='normal',\n",
    "                         bias_initializer='zeros'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(.4))\n",
    "\n",
    "    model.add(Dense(units=18))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
    "    model.fit(X_train, y_train,batch_size=24,epochs=30,verbose=1,validation_data=(X_test, y_test))\n",
    "    score = model.evaluate(X_test, y_test, verbose=1)\n",
    "    val_loss_cv.append(score[0])\n",
    "    val_acc_cv.append(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss_cv : [0.2821950779807183, 0.36202454876590084, 0.30261991136144883, 0.2853636161433502, 0.19838030185810354, 0.2645033148436055, 0.3129577409227689, 0.28962614635626477, 0.2104085300506566, 0.21920316928141825]\n",
      "mean_val_loss_cv : 0.2727282357564236\n",
      "val_acc_cv : [0.9525089636925728, 0.9473304253119927, 0.9572790412619563, 0.9568106260806619, 0.9695459515153372, 0.9577334705381298, 0.9609259327252706, 0.9603441696777086, 0.9655817468158324, 0.9639639596681338]\n",
      "mean_val_acc_cv : 0.9592024287287595\n"
     ]
    }
   ],
   "source": [
    "print(f\"val_loss_cv : {val_loss_cv}\")\n",
    "print(f\"mean_val_loss_cv : {np.mean(val_loss_cv)}\")\n",
    "print(f\"val_acc_cv : {val_acc_cv}\")\n",
    "print(f\"mean_val_acc_cv : {np.mean(val_acc_cv)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
