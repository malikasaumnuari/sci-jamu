{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#masukin data1\n",
    "data1=pandas.read_csv('D:\\\\SKRIPSI\\\\data\\\\data_praproses\\\\jamu_herbs.csv', sep=',')\n",
    "#masukin data2\n",
    "data2=pandas.read_csv('D:\\\\SKRIPSI\\\\data\\\\data_praproses\\\\jamu_class.csv', sep=',')\n",
    "data_1 = data1.drop('IDJamu',axis=1)\n",
    "data_2 = data2.drop('Jamu ID',axis=1)\n",
    "data_1['Kelas']=data_2['Class of Diseases']\n",
    "X = data_1.drop('Kelas', axis=1).values\n",
    "y = data_1['Kelas'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=4.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 :\n",
      "\n",
      "Train on 2253 samples, validate on 762 samples\n",
      "Epoch 1/30\n",
      "2253/2253 [==============================] - 1s 537us/step - loss: 2.3094 - acc: 0.2055 - val_loss: 2.1144 - val_acc: 0.2139\n",
      "Epoch 2/30\n",
      "2253/2253 [==============================] - 0s 210us/step - loss: 2.0247 - acc: 0.2406 - val_loss: 2.1001 - val_acc: 0.2021\n",
      "Epoch 3/30\n",
      "2253/2253 [==============================] - 0s 214us/step - loss: 1.8690 - acc: 0.3200 - val_loss: 1.8912 - val_acc: 0.3570\n",
      "Epoch 4/30\n",
      "2253/2253 [==============================] - 0s 206us/step - loss: 1.6259 - acc: 0.4190 - val_loss: 1.8954 - val_acc: 0.4331\n",
      "Epoch 5/30\n",
      "2253/2253 [==============================] - 0s 215us/step - loss: 1.3559 - acc: 0.5810 - val_loss: 1.8771 - val_acc: 0.4501\n",
      "Epoch 6/30\n",
      "2253/2253 [==============================] - 0s 198us/step - loss: 1.1368 - acc: 0.6507 - val_loss: 1.8444 - val_acc: 0.4908\n",
      "Epoch 7/30\n",
      "2253/2253 [==============================] - 0s 221us/step - loss: 0.9728 - acc: 0.6968 - val_loss: 1.9350 - val_acc: 0.4961\n",
      "Epoch 8/30\n",
      "2253/2253 [==============================] - 0s 213us/step - loss: 0.8505 - acc: 0.7483 - val_loss: 2.0356 - val_acc: 0.4685\n",
      "Epoch 9/30\n",
      "2253/2253 [==============================] - 0s 205us/step - loss: 0.7008 - acc: 0.7958 - val_loss: 2.3209 - val_acc: 0.4633\n",
      "Epoch 10/30\n",
      "2253/2253 [==============================] - 1s 236us/step - loss: 0.6097 - acc: 0.8247 - val_loss: 2.4931 - val_acc: 0.4606\n",
      "Epoch 11/30\n",
      "2253/2253 [==============================] - 1s 244us/step - loss: 0.5643 - acc: 0.8340 - val_loss: 2.4704 - val_acc: 0.4672\n",
      "Epoch 12/30\n",
      "2253/2253 [==============================] - 0s 211us/step - loss: 0.5119 - acc: 0.8580 - val_loss: 2.6831 - val_acc: 0.5052\n",
      "Epoch 13/30\n",
      "2253/2253 [==============================] - 0s 203us/step - loss: 0.4724 - acc: 0.8557 - val_loss: 2.9080 - val_acc: 0.4633\n",
      "Epoch 14/30\n",
      "2253/2253 [==============================] - 0s 206us/step - loss: 0.4272 - acc: 0.8810 - val_loss: 2.8905 - val_acc: 0.4764\n",
      "Epoch 15/30\n",
      "2253/2253 [==============================] - 0s 206us/step - loss: 0.4026 - acc: 0.8855 - val_loss: 2.9863 - val_acc: 0.4593\n",
      "Epoch 16/30\n",
      "2253/2253 [==============================] - 0s 201us/step - loss: 0.3709 - acc: 0.8970 - val_loss: 3.0410 - val_acc: 0.4921\n",
      "Epoch 17/30\n",
      "2253/2253 [==============================] - 0s 215us/step - loss: 0.3298 - acc: 0.9050 - val_loss: 3.2130 - val_acc: 0.4790\n",
      "Epoch 18/30\n",
      "2253/2253 [==============================] - 0s 216us/step - loss: 0.3158 - acc: 0.9050 - val_loss: 3.5515 - val_acc: 0.4869\n",
      "Epoch 19/30\n",
      "2253/2253 [==============================] - 0s 211us/step - loss: 0.2747 - acc: 0.9219 - val_loss: 3.7428 - val_acc: 0.4580\n",
      "Epoch 20/30\n",
      "2253/2253 [==============================] - 0s 216us/step - loss: 0.2929 - acc: 0.9157 - val_loss: 3.5782 - val_acc: 0.4764\n",
      "Epoch 21/30\n",
      "2253/2253 [==============================] - 1s 254us/step - loss: 0.2620 - acc: 0.9254 - val_loss: 3.4804 - val_acc: 0.4882\n",
      "Epoch 22/30\n",
      "2253/2253 [==============================] - 1s 266us/step - loss: 0.2505 - acc: 0.9285 - val_loss: 3.0730 - val_acc: 0.4751\n",
      "Epoch 23/30\n",
      "2253/2253 [==============================] - 1s 279us/step - loss: 0.2611 - acc: 0.9272 - val_loss: 3.6311 - val_acc: 0.4790\n",
      "Epoch 24/30\n",
      "2253/2253 [==============================] - 1s 280us/step - loss: 0.2380 - acc: 0.9343 - val_loss: 3.5550 - val_acc: 0.4816\n",
      "Epoch 25/30\n",
      "2253/2253 [==============================] - 1s 268us/step - loss: 0.2402 - acc: 0.9339 - val_loss: 3.2133 - val_acc: 0.4764\n",
      "Epoch 26/30\n",
      "2253/2253 [==============================] - 1s 273us/step - loss: 0.2245 - acc: 0.9370 - val_loss: 3.6684 - val_acc: 0.4711\n",
      "Epoch 27/30\n",
      "2253/2253 [==============================] - 1s 254us/step - loss: 0.2201 - acc: 0.9379 - val_loss: 3.4387 - val_acc: 0.4685\n",
      "Epoch 28/30\n",
      "2253/2253 [==============================] - 1s 244us/step - loss: 0.1921 - acc: 0.9436 - val_loss: 3.9351 - val_acc: 0.4593\n",
      "Epoch 29/30\n",
      "2253/2253 [==============================] - 1s 246us/step - loss: 0.1908 - acc: 0.9481 - val_loss: 3.9522 - val_acc: 0.4803\n",
      "Epoch 30/30\n",
      "2253/2253 [==============================] - 1s 271us/step - loss: 0.1791 - acc: 0.9512 - val_loss: 3.8452 - val_acc: 0.4803\n",
      "762/762 [==============================] - 0s 59us/step\n",
      "Fold 2 :\n",
      "\n",
      "Train on 2261 samples, validate on 754 samples\n",
      "Epoch 1/30\n",
      "2261/2261 [==============================] - 1s 559us/step - loss: 2.3337 - acc: 0.1995 - val_loss: 2.0875 - val_acc: 0.2149\n",
      "Epoch 2/30\n",
      "2261/2261 [==============================] - 1s 295us/step - loss: 2.0752 - acc: 0.2141 - val_loss: 2.0838 - val_acc: 0.2095\n",
      "Epoch 3/30\n",
      "2261/2261 [==============================] - ETA: 0s - loss: 1.9645 - acc: 0.249 - 1s 243us/step - loss: 1.9700 - acc: 0.2441 - val_loss: 2.0413 - val_acc: 0.2931\n",
      "Epoch 4/30\n",
      "2261/2261 [==============================] - 1s 258us/step - loss: 1.7850 - acc: 0.3326 - val_loss: 1.8662 - val_acc: 0.4125\n",
      "Epoch 5/30\n",
      "2261/2261 [==============================] - 1s 253us/step - loss: 1.5244 - acc: 0.4573 - val_loss: 1.6783 - val_acc: 0.4854\n",
      "Epoch 6/30\n",
      "2261/2261 [==============================] - 1s 247us/step - loss: 1.3343 - acc: 0.5471 - val_loss: 1.6850 - val_acc: 0.5027\n",
      "Epoch 7/30\n",
      "2261/2261 [==============================] - 1s 251us/step - loss: 1.1460 - acc: 0.6152 - val_loss: 1.7777 - val_acc: 0.5239\n",
      "Epoch 8/30\n",
      "2261/2261 [==============================] - 1s 243us/step - loss: 1.0218 - acc: 0.6807 - val_loss: 1.7501 - val_acc: 0.5411\n",
      "Epoch 9/30\n",
      "2261/2261 [==============================] - 1s 242us/step - loss: 0.8998 - acc: 0.7112 - val_loss: 1.7943 - val_acc: 0.5517\n",
      "Epoch 10/30\n",
      "2261/2261 [==============================] - 1s 255us/step - loss: 0.8353 - acc: 0.7382 - val_loss: 1.7976 - val_acc: 0.5676\n",
      "Epoch 11/30\n",
      "2261/2261 [==============================] - 1s 283us/step - loss: 0.7721 - acc: 0.7572 - val_loss: 1.9798 - val_acc: 0.5531\n",
      "Epoch 12/30\n",
      "2261/2261 [==============================] - 1s 272us/step - loss: 0.6809 - acc: 0.7766 - val_loss: 2.1879 - val_acc: 0.5637\n",
      "Epoch 13/30\n",
      "2261/2261 [==============================] - 1s 237us/step - loss: 0.6545 - acc: 0.7895 - val_loss: 1.9923 - val_acc: 0.5637\n",
      "Epoch 14/30\n",
      "2261/2261 [==============================] - 1s 244us/step - loss: 0.6173 - acc: 0.8036 - val_loss: 2.1324 - val_acc: 0.5676\n",
      "Epoch 15/30\n",
      "2261/2261 [==============================] - 1s 248us/step - loss: 0.5524 - acc: 0.8328 - val_loss: 2.0767 - val_acc: 0.5597\n",
      "Epoch 16/30\n",
      "2261/2261 [==============================] - 1s 238us/step - loss: 0.5423 - acc: 0.8280 - val_loss: 2.4128 - val_acc: 0.5424\n",
      "Epoch 17/30\n",
      "2261/2261 [==============================] - 1s 244us/step - loss: 0.5453 - acc: 0.8430 - val_loss: 2.2399 - val_acc: 0.5424\n",
      "Epoch 18/30\n",
      "2261/2261 [==============================] - 1s 246us/step - loss: 0.4636 - acc: 0.8505 - val_loss: 2.3833 - val_acc: 0.5716\n",
      "Epoch 19/30\n",
      "2261/2261 [==============================] - 1s 245us/step - loss: 0.4398 - acc: 0.8691 - val_loss: 2.4494 - val_acc: 0.5610\n",
      "Epoch 20/30\n",
      "2261/2261 [==============================] - 1s 300us/step - loss: 0.4691 - acc: 0.8633 - val_loss: 2.2631 - val_acc: 0.5690\n",
      "Epoch 21/30\n",
      "2261/2261 [==============================] - 1s 257us/step - loss: 0.4191 - acc: 0.8722 - val_loss: 2.4014 - val_acc: 0.5849\n",
      "Epoch 22/30\n",
      "2261/2261 [==============================] - 1s 254us/step - loss: 0.3865 - acc: 0.8854 - val_loss: 2.6779 - val_acc: 0.5703\n",
      "Epoch 23/30\n",
      "2261/2261 [==============================] - 1s 246us/step - loss: 0.3565 - acc: 0.8943 - val_loss: 2.5473 - val_acc: 0.5729\n",
      "Epoch 24/30\n",
      "2261/2261 [==============================] - 1s 254us/step - loss: 0.3488 - acc: 0.8965 - val_loss: 2.7900 - val_acc: 0.5849\n",
      "Epoch 25/30\n",
      "2261/2261 [==============================] - 1s 245us/step - loss: 0.3122 - acc: 0.9071 - val_loss: 2.7302 - val_acc: 0.5729\n",
      "Epoch 26/30\n",
      "2261/2261 [==============================] - 1s 258us/step - loss: 0.3273 - acc: 0.9031 - val_loss: 2.7083 - val_acc: 0.5663\n",
      "Epoch 27/30\n",
      "2261/2261 [==============================] - 1s 247us/step - loss: 0.3138 - acc: 0.9058 - val_loss: 2.7765 - val_acc: 0.5743\n",
      "Epoch 28/30\n",
      "2261/2261 [==============================] - 1s 260us/step - loss: 0.3197 - acc: 0.9027 - val_loss: 2.6223 - val_acc: 0.5915\n",
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2261/2261 [==============================] - 1s 228us/step - loss: 0.2942 - acc: 0.9146 - val_loss: 2.6474 - val_acc: 0.5716\n",
      "Epoch 30/30\n",
      "2261/2261 [==============================] - 1s 233us/step - loss: 0.3103 - acc: 0.9089 - val_loss: 2.8696 - val_acc: 0.5836\n",
      "754/754 [==============================] - 0s 49us/step\n",
      "Fold 3 :\n",
      "\n",
      "Train on 2265 samples, validate on 750 samples\n",
      "Epoch 1/30\n",
      "2265/2265 [==============================] - 1s 630us/step - loss: 2.3227 - acc: 0.2053 - val_loss: 2.1202 - val_acc: 0.2280\n",
      "Epoch 2/30\n",
      "2265/2265 [==============================] - 1s 299us/step - loss: 2.0639 - acc: 0.2256 - val_loss: 2.0472 - val_acc: 0.2573\n",
      "Epoch 3/30\n",
      "2265/2265 [==============================] - 1s 270us/step - loss: 1.9349 - acc: 0.2733 - val_loss: 1.9360 - val_acc: 0.2947\n",
      "Epoch 4/30\n",
      "2265/2265 [==============================] - 1s 237us/step - loss: 1.6717 - acc: 0.4132 - val_loss: 1.8480 - val_acc: 0.4013\n",
      "Epoch 5/30\n",
      "2265/2265 [==============================] - 1s 238us/step - loss: 1.3991 - acc: 0.5210 - val_loss: 1.8479 - val_acc: 0.4413\n",
      "Epoch 6/30\n",
      "2265/2265 [==============================] - 1s 271us/step - loss: 1.2222 - acc: 0.5934 - val_loss: 1.8386 - val_acc: 0.5053\n",
      "Epoch 7/30\n",
      "2265/2265 [==============================] - 1s 246us/step - loss: 1.0780 - acc: 0.6623 - val_loss: 1.9533 - val_acc: 0.4760\n",
      "Epoch 8/30\n",
      "2265/2265 [==============================] - 1s 241us/step - loss: 0.9813 - acc: 0.6870 - val_loss: 2.0719 - val_acc: 0.5040\n",
      "Epoch 9/30\n",
      "2265/2265 [==============================] - 1s 234us/step - loss: 0.8782 - acc: 0.7241 - val_loss: 2.2410 - val_acc: 0.5093\n",
      "Epoch 10/30\n",
      "2265/2265 [==============================] - 1s 235us/step - loss: 0.7909 - acc: 0.7506 - val_loss: 2.2280 - val_acc: 0.5320\n",
      "Epoch 11/30\n",
      "2265/2265 [==============================] - 1s 234us/step - loss: 0.7524 - acc: 0.7585 - val_loss: 2.2895 - val_acc: 0.5107\n",
      "Epoch 12/30\n",
      "2265/2265 [==============================] - 1s 235us/step - loss: 0.6807 - acc: 0.7784 - val_loss: 2.3105 - val_acc: 0.4907\n",
      "Epoch 13/30\n",
      "2265/2265 [==============================] - 1s 243us/step - loss: 0.6474 - acc: 0.7996 - val_loss: 2.4851 - val_acc: 0.5280\n",
      "Epoch 14/30\n",
      "2265/2265 [==============================] - 1s 239us/step - loss: 0.6200 - acc: 0.8075 - val_loss: 2.3815 - val_acc: 0.5213\n",
      "Epoch 15/30\n",
      "2265/2265 [==============================] - 1s 241us/step - loss: 0.6019 - acc: 0.8137 - val_loss: 2.4121 - val_acc: 0.5347\n",
      "Epoch 16/30\n",
      "2265/2265 [==============================] - 1s 236us/step - loss: 0.5531 - acc: 0.8296 - val_loss: 2.6201 - val_acc: 0.5333\n",
      "Epoch 17/30\n",
      "2265/2265 [==============================] - 1s 289us/step - loss: 0.4919 - acc: 0.8490 - val_loss: 2.8974 - val_acc: 0.5333\n",
      "Epoch 18/30\n",
      "2265/2265 [==============================] - 1s 279us/step - loss: 0.4757 - acc: 0.8494 - val_loss: 2.8363 - val_acc: 0.5253\n",
      "Epoch 19/30\n",
      "2265/2265 [==============================] - 1s 275us/step - loss: 0.4673 - acc: 0.8530 - val_loss: 2.5442 - val_acc: 0.5307\n",
      "Epoch 20/30\n",
      "2265/2265 [==============================] - 1s 273us/step - loss: 0.4539 - acc: 0.8618 - val_loss: 2.9537 - val_acc: 0.5440\n",
      "Epoch 21/30\n",
      "2265/2265 [==============================] - 1s 276us/step - loss: 0.4229 - acc: 0.8720 - val_loss: 2.9646 - val_acc: 0.5320\n",
      "Epoch 22/30\n",
      "2265/2265 [==============================] - 1s 272us/step - loss: 0.3790 - acc: 0.8870 - val_loss: 2.9059 - val_acc: 0.5427\n",
      "Epoch 23/30\n",
      "2265/2265 [==============================] - 1s 276us/step - loss: 0.3665 - acc: 0.8879 - val_loss: 3.1070 - val_acc: 0.5373\n",
      "Epoch 24/30\n",
      "2265/2265 [==============================] - 1s 272us/step - loss: 0.3563 - acc: 0.8985 - val_loss: 3.0732 - val_acc: 0.5533\n",
      "Epoch 25/30\n",
      "2265/2265 [==============================] - 1s 285us/step - loss: 0.3640 - acc: 0.8905 - val_loss: 3.0753 - val_acc: 0.5493\n",
      "Epoch 26/30\n",
      "2265/2265 [==============================] - 1s 287us/step - loss: 0.3490 - acc: 0.9015 - val_loss: 3.1850 - val_acc: 0.5507\n",
      "Epoch 27/30\n",
      "2265/2265 [==============================] - 1s 302us/step - loss: 0.3268 - acc: 0.9064 - val_loss: 3.0754 - val_acc: 0.5360\n",
      "Epoch 28/30\n",
      "2265/2265 [==============================] - 1s 293us/step - loss: 0.3599 - acc: 0.8985 - val_loss: 3.0090 - val_acc: 0.5467\n",
      "Epoch 29/30\n",
      "2265/2265 [==============================] - 1s 280us/step - loss: 0.2905 - acc: 0.9135 - val_loss: 3.1324 - val_acc: 0.5387\n",
      "Epoch 30/30\n",
      "2265/2265 [==============================] - 1s 231us/step - loss: 0.3158 - acc: 0.9135 - val_loss: 3.0450 - val_acc: 0.5520\n",
      "750/750 [==============================] - 0s 43us/step\n",
      "Fold 4 :\n",
      "\n",
      "Train on 2266 samples, validate on 749 samples\n",
      "Epoch 1/30\n",
      "2266/2266 [==============================] - 1s 598us/step - loss: 2.3460 - acc: 0.1990 - val_loss: 2.0968 - val_acc: 0.2163\n",
      "Epoch 2/30\n",
      "2266/2266 [==============================] - 1s 228us/step - loss: 2.0734 - acc: 0.2074 - val_loss: 2.0700 - val_acc: 0.2657\n",
      "Epoch 3/30\n",
      "2266/2266 [==============================] - 1s 272us/step - loss: 1.9804 - acc: 0.2224 - val_loss: 1.9720 - val_acc: 0.2483\n",
      "Epoch 4/30\n",
      "2266/2266 [==============================] - 1s 262us/step - loss: 1.8299 - acc: 0.3297 - val_loss: 1.8712 - val_acc: 0.4112\n",
      "Epoch 5/30\n",
      "2266/2266 [==============================] - 1s 308us/step - loss: 1.5125 - acc: 0.4801 - val_loss: 1.7209 - val_acc: 0.5047\n",
      "Epoch 6/30\n",
      "2266/2266 [==============================] - 1s 274us/step - loss: 1.2706 - acc: 0.5891 - val_loss: 1.6718 - val_acc: 0.5407\n",
      "Epoch 7/30\n",
      "2266/2266 [==============================] - 1s 288us/step - loss: 1.0743 - acc: 0.6598 - val_loss: 1.6991 - val_acc: 0.5781\n",
      "Epoch 8/30\n",
      "2266/2266 [==============================] - 1s 321us/step - loss: 0.9593 - acc: 0.6920 - val_loss: 1.7544 - val_acc: 0.5514\n",
      "Epoch 9/30\n",
      "2266/2266 [==============================] - 1s 318us/step - loss: 0.8518 - acc: 0.7304 - val_loss: 1.8775 - val_acc: 0.5461\n",
      "Epoch 10/30\n",
      "2266/2266 [==============================] - 1s 312us/step - loss: 0.7686 - acc: 0.7595 - val_loss: 1.8883 - val_acc: 0.5567\n",
      "Epoch 11/30\n",
      "2266/2266 [==============================] - 1s 287us/step - loss: 0.6772 - acc: 0.7855 - val_loss: 2.0505 - val_acc: 0.5527\n",
      "Epoch 12/30\n",
      "2266/2266 [==============================] - 1s 280us/step - loss: 0.6443 - acc: 0.7970 - val_loss: 2.0437 - val_acc: 0.5621\n",
      "Epoch 13/30\n",
      "2266/2266 [==============================] - 1s 279us/step - loss: 0.6055 - acc: 0.8049 - val_loss: 2.1682 - val_acc: 0.5434\n",
      "Epoch 14/30\n",
      "2266/2266 [==============================] - 1s 292us/step - loss: 0.5551 - acc: 0.8261 - val_loss: 2.4142 - val_acc: 0.5421\n",
      "Epoch 15/30\n",
      "2266/2266 [==============================] - 1s 300us/step - loss: 0.5527 - acc: 0.8301 - val_loss: 2.3286 - val_acc: 0.5968\n",
      "Epoch 16/30\n",
      "2266/2266 [==============================] - 1s 300us/step - loss: 0.4902 - acc: 0.8482 - val_loss: 2.2595 - val_acc: 0.5407\n",
      "Epoch 17/30\n",
      "2266/2266 [==============================] - 1s 344us/step - loss: 0.4669 - acc: 0.8592 - val_loss: 2.6970 - val_acc: 0.5554\n",
      "Epoch 18/30\n",
      "2266/2266 [==============================] - 1s 305us/step - loss: 0.4660 - acc: 0.8610 - val_loss: 2.5164 - val_acc: 0.5541\n",
      "Epoch 19/30\n",
      "2266/2266 [==============================] - 1s 269us/step - loss: 0.3841 - acc: 0.8853 - val_loss: 2.5354 - val_acc: 0.5661\n",
      "Epoch 20/30\n",
      "2266/2266 [==============================] - 1s 254us/step - loss: 0.3695 - acc: 0.8888 - val_loss: 2.7490 - val_acc: 0.5821\n",
      "Epoch 21/30\n",
      "2266/2266 [==============================] - 1s 232us/step - loss: 0.3672 - acc: 0.8883 - val_loss: 2.6921 - val_acc: 0.5594\n",
      "Epoch 22/30\n",
      "2266/2266 [==============================] - 1s 230us/step - loss: 0.3271 - acc: 0.8989 - val_loss: 2.9878 - val_acc: 0.5567\n",
      "Epoch 23/30\n",
      "2266/2266 [==============================] - 1s 235us/step - loss: 0.3243 - acc: 0.9020 - val_loss: 2.9103 - val_acc: 0.5567\n",
      "Epoch 24/30\n",
      "2266/2266 [==============================] - 1s 228us/step - loss: 0.2936 - acc: 0.9122 - val_loss: 3.3416 - val_acc: 0.5541\n",
      "Epoch 25/30\n",
      "2266/2266 [==============================] - 1s 228us/step - loss: 0.3107 - acc: 0.9051 - val_loss: 3.0011 - val_acc: 0.5567\n",
      "Epoch 26/30\n",
      "2266/2266 [==============================] - 1s 237us/step - loss: 0.2854 - acc: 0.9188 - val_loss: 2.9941 - val_acc: 0.5674\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2266/2266 [==============================] - 1s 227us/step - loss: 0.2619 - acc: 0.9170 - val_loss: 3.3881 - val_acc: 0.5594\n",
      "Epoch 28/30\n",
      "2266/2266 [==============================] - 1s 235us/step - loss: 0.2780 - acc: 0.9259 - val_loss: 3.0295 - val_acc: 0.5394\n",
      "Epoch 29/30\n",
      "2266/2266 [==============================] - 1s 228us/step - loss: 0.3162 - acc: 0.9073 - val_loss: 3.0460 - val_acc: 0.5367\n",
      "Epoch 30/30\n",
      "2266/2266 [==============================] - 1s 238us/step - loss: 0.2845 - acc: 0.9179 - val_loss: 2.8990 - val_acc: 0.5741\n",
      "749/749 [==============================] - 0s 42us/step\n"
     ]
    }
   ],
   "source": [
    "#k=4\n",
    "kf = StratifiedKFold(n_splits=4, random_state=None, shuffle=False)\n",
    "val_loss_cv = []\n",
    "val_acc_cv = []\n",
    "j = 0\n",
    "for train_index, test_index in kf.split(X,y):\n",
    "    j+=1\n",
    "    print(f\"Fold {j} :\")\n",
    "    print(\"\")\n",
    "    X_train,X_test = X[train_index],X[test_index]\n",
    "    y_train,y_test = y[train_index],y[test_index]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim=X_train.shape[1], units=128,\n",
    "                     kernel_initializer='normal', bias_initializer='zeros'))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    for i in range(0, 6):\n",
    "        model.add(Dense(units=128, kernel_initializer='normal',\n",
    "                         bias_initializer='zeros'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(.15))\n",
    "\n",
    "    model.add(Dense(units=19))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train,batch_size=24,epochs=30,verbose=1,validation_data=(X_test, y_test))\n",
    "    score = model.evaluate(X_test, y_test, verbose=1)\n",
    "    val_loss_cv.append(score[0])\n",
    "    val_acc_cv.append(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss_cv : [3.8451745416235736, 2.8696349154100496, 3.045045368830363, 2.899002401787385]\n",
      "mean_val_loss_cv : 3.1647143069128427\n",
      "val_acc_cv : [0.4803149606690319, 0.5835543768159275, 0.5519999998410543, 0.5740987985968112]\n",
      "mean_val_acc_cv : 0.5474920339807062\n"
     ]
    }
   ],
   "source": [
    "print(f\"val_loss_cv : {val_loss_cv}\")\n",
    "print(f\"mean_val_loss_cv : {np.mean(val_loss_cv)}\")\n",
    "print(f\"val_acc_cv : {val_acc_cv}\")\n",
    "print(f\"mean_val_acc_cv : {np.mean(val_acc_cv)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
