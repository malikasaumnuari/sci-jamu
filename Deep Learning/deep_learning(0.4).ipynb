{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#masukin data1\n",
    "data1=pandas.read_csv('D:\\\\SKRIPSI\\\\data\\\\data_praproses\\\\jamu_herbs.csv', sep=',')\n",
    "#masukin data2\n",
    "data2=pandas.read_csv('D:\\\\SKRIPSI\\\\data\\\\data_praproses\\\\jamu_class.csv', sep=',')\n",
    "data_1 = data1.drop('IDJamu',axis=1)\n",
    "data_2 = data2.drop('Jamu ID',axis=1)\n",
    "data_1['Kelas']=data_2['Class of Diseases']\n",
    "X = data_1.drop('Kelas', axis=1).values\n",
    "y = data_1['Kelas'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=4.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 :\n",
      "\n",
      "Train on 2253 samples, validate on 762 samples\n",
      "Epoch 1/30\n",
      "2253/2253 [==============================] - 2s 717us/step - loss: 2.3687 - acc: 0.1855 - val_loss: 2.1182 - val_acc: 0.2139\n",
      "Epoch 2/30\n",
      "2253/2253 [==============================] - 1s 403us/step - loss: 2.0923 - acc: 0.2246 - val_loss: 2.0754 - val_acc: 0.1916\n",
      "Epoch 3/30\n",
      "2253/2253 [==============================] - 1s 254us/step - loss: 1.9765 - acc: 0.2663 - val_loss: 1.9890 - val_acc: 0.3504\n",
      "Epoch 4/30\n",
      "2253/2253 [==============================] - 1s 263us/step - loss: 1.8285 - acc: 0.3555 - val_loss: 1.8566 - val_acc: 0.4226\n",
      "Epoch 5/30\n",
      "2253/2253 [==============================] - 1s 263us/step - loss: 1.6386 - acc: 0.4421 - val_loss: 1.9115 - val_acc: 0.3976\n",
      "Epoch 6/30\n",
      "2253/2253 [==============================] - 1s 252us/step - loss: 1.4929 - acc: 0.5131 - val_loss: 1.9128 - val_acc: 0.4790\n",
      "Epoch 7/30\n",
      "2253/2253 [==============================] - 1s 282us/step - loss: 1.3288 - acc: 0.5814 - val_loss: 1.9063 - val_acc: 0.4659\n",
      "Epoch 8/30\n",
      "2253/2253 [==============================] - 1s 270us/step - loss: 1.2580 - acc: 0.6201 - val_loss: 2.1157 - val_acc: 0.4816\n",
      "Epoch 9/30\n",
      "2253/2253 [==============================] - 1s 267us/step - loss: 1.1499 - acc: 0.6529 - val_loss: 2.0891 - val_acc: 0.4449\n",
      "Epoch 10/30\n",
      "2253/2253 [==============================] - 1s 231us/step - loss: 1.0951 - acc: 0.6720 - val_loss: 2.2815 - val_acc: 0.4790\n",
      "Epoch 11/30\n",
      "2253/2253 [==============================] - 1s 244us/step - loss: 0.9814 - acc: 0.6991 - val_loss: 2.4930 - val_acc: 0.4567\n",
      "Epoch 12/30\n",
      "2253/2253 [==============================] - 1s 266us/step - loss: 0.9274 - acc: 0.7235 - val_loss: 2.3485 - val_acc: 0.4738\n",
      "Epoch 13/30\n",
      "2253/2253 [==============================] - 1s 229us/step - loss: 0.8845 - acc: 0.7381 - val_loss: 2.3491 - val_acc: 0.4633\n",
      "Epoch 14/30\n",
      "2253/2253 [==============================] - 1s 253us/step - loss: 0.8208 - acc: 0.7479 - val_loss: 2.7191 - val_acc: 0.4646\n",
      "Epoch 15/30\n",
      "2253/2253 [==============================] - 1s 252us/step - loss: 0.7634 - acc: 0.7625 - val_loss: 2.6278 - val_acc: 0.4724\n",
      "Epoch 16/30\n",
      "2253/2253 [==============================] - 1s 236us/step - loss: 0.7353 - acc: 0.7883 - val_loss: 2.7924 - val_acc: 0.4633\n",
      "Epoch 17/30\n",
      "2253/2253 [==============================] - 1s 254us/step - loss: 0.7094 - acc: 0.7781 - val_loss: 2.8319 - val_acc: 0.4304\n",
      "Epoch 18/30\n",
      "2253/2253 [==============================] - 1s 261us/step - loss: 0.6495 - acc: 0.8074 - val_loss: 3.3503 - val_acc: 0.4357\n",
      "Epoch 19/30\n",
      "2253/2253 [==============================] - 1s 243us/step - loss: 0.6292 - acc: 0.8091 - val_loss: 3.2749 - val_acc: 0.4475\n",
      "Epoch 20/30\n",
      "2253/2253 [==============================] - 1s 242us/step - loss: 0.5986 - acc: 0.8185 - val_loss: 3.2507 - val_acc: 0.4514\n",
      "Epoch 21/30\n",
      "2253/2253 [==============================] - 1s 234us/step - loss: 0.5645 - acc: 0.8322 - val_loss: 3.3974 - val_acc: 0.4488\n",
      "Epoch 22/30\n",
      "2253/2253 [==============================] - 1s 238us/step - loss: 0.5441 - acc: 0.8336 - val_loss: 3.4302 - val_acc: 0.4764\n",
      "Epoch 23/30\n",
      "2253/2253 [==============================] - 1s 234us/step - loss: 0.5578 - acc: 0.8371 - val_loss: 3.0476 - val_acc: 0.4475\n",
      "Epoch 24/30\n",
      "2253/2253 [==============================] - 1s 235us/step - loss: 0.5421 - acc: 0.8367 - val_loss: 3.2921 - val_acc: 0.4633\n",
      "Epoch 25/30\n",
      "2253/2253 [==============================] - 1s 259us/step - loss: 0.5152 - acc: 0.8442 - val_loss: 3.3089 - val_acc: 0.4528\n",
      "Epoch 26/30\n",
      "2253/2253 [==============================] - 1s 238us/step - loss: 0.4969 - acc: 0.8509 - val_loss: 3.3837 - val_acc: 0.4541\n",
      "Epoch 27/30\n",
      "2253/2253 [==============================] - 1s 237us/step - loss: 0.4845 - acc: 0.8526 - val_loss: 3.1852 - val_acc: 0.4711\n",
      "Epoch 28/30\n",
      "2253/2253 [==============================] - 1s 232us/step - loss: 0.4629 - acc: 0.8660 - val_loss: 3.4522 - val_acc: 0.4685\n",
      "Epoch 29/30\n",
      "2253/2253 [==============================] - 1s 247us/step - loss: 0.4683 - acc: 0.8628 - val_loss: 4.0011 - val_acc: 0.4554\n",
      "Epoch 30/30\n",
      "2253/2253 [==============================] - 1s 242us/step - loss: 0.4407 - acc: 0.8731 - val_loss: 3.5966 - val_acc: 0.4501\n",
      "762/762 [==============================] - 0s 62us/step\n",
      "Fold 2 :\n",
      "\n",
      "Train on 2261 samples, validate on 754 samples\n",
      "Epoch 1/30\n",
      "2261/2261 [==============================] - 2s 790us/step - loss: 2.4236 - acc: 0.2030 - val_loss: 2.1023 - val_acc: 0.2149\n",
      "Epoch 2/30\n",
      "2261/2261 [==============================] - 1s 249us/step - loss: 2.1195 - acc: 0.2260 - val_loss: 2.0609 - val_acc: 0.2268\n",
      "Epoch 3/30\n",
      "2261/2261 [==============================] - 1s 238us/step - loss: 2.0231 - acc: 0.2556 - val_loss: 2.0486 - val_acc: 0.2692\n",
      "Epoch 4/30\n",
      "2261/2261 [==============================] - 1s 249us/step - loss: 1.9372 - acc: 0.3198 - val_loss: 1.9992 - val_acc: 0.3780\n",
      "Epoch 5/30\n",
      "2261/2261 [==============================] - 1s 245us/step - loss: 1.7951 - acc: 0.3954 - val_loss: 1.8442 - val_acc: 0.4164\n",
      "Epoch 6/30\n",
      "2261/2261 [==============================] - 1s 256us/step - loss: 1.6428 - acc: 0.4573 - val_loss: 1.8022 - val_acc: 0.4363\n",
      "Epoch 7/30\n",
      "2261/2261 [==============================] - 1s 237us/step - loss: 1.5790 - acc: 0.4843 - val_loss: 1.7605 - val_acc: 0.4456\n",
      "Epoch 8/30\n",
      "2261/2261 [==============================] - 1s 242us/step - loss: 1.4707 - acc: 0.5113 - val_loss: 1.7608 - val_acc: 0.4735\n",
      "Epoch 9/30\n",
      "2261/2261 [==============================] - 1s 238us/step - loss: 1.3799 - acc: 0.5356 - val_loss: 1.9150 - val_acc: 0.4284\n",
      "Epoch 10/30\n",
      "2261/2261 [==============================] - 1s 235us/step - loss: 1.3376 - acc: 0.5515 - val_loss: 1.8002 - val_acc: 0.4894\n",
      "Epoch 11/30\n",
      "2261/2261 [==============================] - 1s 245us/step - loss: 1.2424 - acc: 0.5728 - val_loss: 1.9340 - val_acc: 0.4788\n",
      "Epoch 12/30\n",
      "2261/2261 [==============================] - 1s 242us/step - loss: 1.1974 - acc: 0.5865 - val_loss: 1.8445 - val_acc: 0.4867\n",
      "Epoch 13/30\n",
      "2261/2261 [==============================] - 1s 235us/step - loss: 1.1635 - acc: 0.6267 - val_loss: 1.9813 - val_acc: 0.4987\n",
      "Epoch 14/30\n",
      "2261/2261 [==============================] - 1s 238us/step - loss: 1.0905 - acc: 0.6648 - val_loss: 1.9111 - val_acc: 0.4960\n",
      "Epoch 15/30\n",
      "2261/2261 [==============================] - 1s 242us/step - loss: 1.0099 - acc: 0.6798 - val_loss: 2.0218 - val_acc: 0.5252\n",
      "Epoch 16/30\n",
      "2261/2261 [==============================] - 1s 238us/step - loss: 1.0027 - acc: 0.6877 - val_loss: 2.0537 - val_acc: 0.5093\n",
      "Epoch 17/30\n",
      "2261/2261 [==============================] - 1s 242us/step - loss: 0.9472 - acc: 0.7006 - val_loss: 2.0132 - val_acc: 0.5133\n",
      "Epoch 18/30\n",
      "2261/2261 [==============================] - 1s 245us/step - loss: 0.8715 - acc: 0.7196 - val_loss: 2.2584 - val_acc: 0.5159\n",
      "Epoch 19/30\n",
      "2261/2261 [==============================] - 1s 272us/step - loss: 0.8970 - acc: 0.7169 - val_loss: 2.2656 - val_acc: 0.5172\n",
      "Epoch 20/30\n",
      "2261/2261 [==============================] - 1s 228us/step - loss: 0.8655 - acc: 0.7267 - val_loss: 2.3237 - val_acc: 0.5106\n",
      "Epoch 21/30\n",
      "2261/2261 [==============================] - 1s 237us/step - loss: 0.8261 - acc: 0.7510 - val_loss: 2.2975 - val_acc: 0.4960\n",
      "Epoch 22/30\n",
      "2261/2261 [==============================] - 1s 229us/step - loss: 0.7669 - acc: 0.7488 - val_loss: 2.1682 - val_acc: 0.5239\n",
      "Epoch 23/30\n",
      "2261/2261 [==============================] - 1s 249us/step - loss: 0.7601 - acc: 0.7660 - val_loss: 2.2263 - val_acc: 0.5000\n",
      "Epoch 24/30\n",
      "2261/2261 [==============================] - 1s 252us/step - loss: 0.6850 - acc: 0.7806 - val_loss: 2.5182 - val_acc: 0.5093\n",
      "Epoch 25/30\n",
      "2261/2261 [==============================] - 1s 242us/step - loss: 0.7126 - acc: 0.7797 - val_loss: 2.4767 - val_acc: 0.5252\n",
      "Epoch 26/30\n",
      "2261/2261 [==============================] - 1s 275us/step - loss: 0.6474 - acc: 0.8010 - val_loss: 2.5287 - val_acc: 0.5225\n",
      "Epoch 27/30\n",
      "2261/2261 [==============================] - 1s 249us/step - loss: 0.6041 - acc: 0.8147 - val_loss: 2.6457 - val_acc: 0.5265\n",
      "Epoch 28/30\n",
      "2261/2261 [==============================] - 1s 245us/step - loss: 0.5964 - acc: 0.8098 - val_loss: 2.6143 - val_acc: 0.5358\n",
      "Epoch 29/30\n",
      "2261/2261 [==============================] - 1s 249us/step - loss: 0.6120 - acc: 0.8169 - val_loss: 2.6536 - val_acc: 0.5332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30\n",
      "2261/2261 [==============================] - 1s 245us/step - loss: 0.5578 - acc: 0.8302 - val_loss: 2.7408 - val_acc: 0.5225\n",
      "754/754 [==============================] - 0s 41us/step\n",
      "Fold 3 :\n",
      "\n",
      "Train on 2265 samples, validate on 750 samples\n",
      "Epoch 1/30\n",
      "2265/2265 [==============================] - 2s 730us/step - loss: 2.3897 - acc: 0.1960 - val_loss: 2.1427 - val_acc: 0.2160\n",
      "Epoch 2/30\n",
      "2265/2265 [==============================] - 1s 235us/step - loss: 2.1250 - acc: 0.2185 - val_loss: 2.0677 - val_acc: 0.2600\n",
      "Epoch 3/30\n",
      "2265/2265 [==============================] - 1s 245us/step - loss: 2.0292 - acc: 0.2340 - val_loss: 2.0119 - val_acc: 0.2067\n",
      "Epoch 4/30\n",
      "2265/2265 [==============================] - 1s 248us/step - loss: 1.9344 - acc: 0.2821 - val_loss: 2.0093 - val_acc: 0.3173\n",
      "Epoch 5/30\n",
      "2265/2265 [==============================] - 1s 252us/step - loss: 1.7575 - acc: 0.3770 - val_loss: 1.9407 - val_acc: 0.3880\n",
      "Epoch 6/30\n",
      "2265/2265 [==============================] - 1s 251us/step - loss: 1.5931 - acc: 0.4596 - val_loss: 1.8216 - val_acc: 0.4280\n",
      "Epoch 7/30\n",
      "2265/2265 [==============================] - 1s 248us/step - loss: 1.4409 - acc: 0.5073 - val_loss: 1.8459 - val_acc: 0.4520\n",
      "Epoch 8/30\n",
      "2265/2265 [==============================] - 1s 258us/step - loss: 1.3247 - acc: 0.5598 - val_loss: 1.8988 - val_acc: 0.4787\n",
      "Epoch 9/30\n",
      "2265/2265 [==============================] - 1s 245us/step - loss: 1.2315 - acc: 0.6071 - val_loss: 1.8903 - val_acc: 0.4853\n",
      "Epoch 10/30\n",
      "2265/2265 [==============================] - 1s 251us/step - loss: 1.0862 - acc: 0.6627 - val_loss: 1.9971 - val_acc: 0.5053\n",
      "Epoch 11/30\n",
      "2265/2265 [==============================] - 1s 242us/step - loss: 1.0583 - acc: 0.6689 - val_loss: 2.0651 - val_acc: 0.5307\n",
      "Epoch 12/30\n",
      "2265/2265 [==============================] - 1s 254us/step - loss: 1.0069 - acc: 0.6927 - val_loss: 1.9939 - val_acc: 0.5093\n",
      "Epoch 13/30\n",
      "2265/2265 [==============================] - 1s 252us/step - loss: 0.9167 - acc: 0.7267 - val_loss: 2.1603 - val_acc: 0.5093\n",
      "Epoch 14/30\n",
      "2265/2265 [==============================] - 1s 247us/step - loss: 0.8691 - acc: 0.7400 - val_loss: 2.2734 - val_acc: 0.5000\n",
      "Epoch 15/30\n",
      "2265/2265 [==============================] - 1s 253us/step - loss: 0.8187 - acc: 0.7625 - val_loss: 2.3635 - val_acc: 0.5240\n",
      "Epoch 16/30\n",
      "2265/2265 [==============================] - 1s 242us/step - loss: 0.7893 - acc: 0.7740 - val_loss: 2.4654 - val_acc: 0.5173\n",
      "Epoch 17/30\n",
      "2265/2265 [==============================] - 1s 253us/step - loss: 0.7558 - acc: 0.7810 - val_loss: 2.3245 - val_acc: 0.5173\n",
      "Epoch 18/30\n",
      "2265/2265 [==============================] - 1s 253us/step - loss: 0.7201 - acc: 0.7969 - val_loss: 2.3802 - val_acc: 0.5133\n",
      "Epoch 19/30\n",
      "2265/2265 [==============================] - 1s 270us/step - loss: 0.6706 - acc: 0.8084 - val_loss: 2.4925 - val_acc: 0.5360\n",
      "Epoch 20/30\n",
      "2265/2265 [==============================] - 1s 245us/step - loss: 0.6460 - acc: 0.8190 - val_loss: 2.6703 - val_acc: 0.5293\n",
      "Epoch 21/30\n",
      "2265/2265 [==============================] - 1s 244us/step - loss: 0.6461 - acc: 0.8194 - val_loss: 2.6818 - val_acc: 0.5347\n",
      "Epoch 22/30\n",
      "2265/2265 [==============================] - 1s 242us/step - loss: 0.5987 - acc: 0.8305 - val_loss: 2.8017 - val_acc: 0.5347\n",
      "Epoch 23/30\n",
      "2265/2265 [==============================] - 1s 242us/step - loss: 0.6185 - acc: 0.8216 - val_loss: 2.6471 - val_acc: 0.5360\n",
      "Epoch 24/30\n",
      "2265/2265 [==============================] - 1s 237us/step - loss: 0.5873 - acc: 0.8353 - val_loss: 2.7089 - val_acc: 0.5293\n",
      "Epoch 25/30\n",
      "2265/2265 [==============================] - 1s 242us/step - loss: 0.5621 - acc: 0.8419 - val_loss: 2.9758 - val_acc: 0.5187\n",
      "Epoch 26/30\n",
      "2265/2265 [==============================] - 1s 244us/step - loss: 0.5726 - acc: 0.8393 - val_loss: 2.5944 - val_acc: 0.5200\n",
      "Epoch 27/30\n",
      "2265/2265 [==============================] - 1s 251us/step - loss: 0.5380 - acc: 0.8552 - val_loss: 2.7142 - val_acc: 0.5280\n",
      "Epoch 28/30\n",
      "2265/2265 [==============================] - 1s 266us/step - loss: 0.5139 - acc: 0.8552 - val_loss: 2.7824 - val_acc: 0.5387\n",
      "Epoch 29/30\n",
      "2265/2265 [==============================] - 1s 242us/step - loss: 0.4972 - acc: 0.8614 - val_loss: 2.8844 - val_acc: 0.5333\n",
      "Epoch 30/30\n",
      "2265/2265 [==============================] - 1s 245us/step - loss: 0.4849 - acc: 0.8587 - val_loss: 2.8081 - val_acc: 0.5333\n",
      "750/750 [==============================] - 0s 63us/step\n",
      "Fold 4 :\n",
      "\n",
      "Train on 2266 samples, validate on 749 samples\n",
      "Epoch 1/30\n",
      "2266/2266 [==============================] - 2s 773us/step - loss: 2.3738 - acc: 0.1915 - val_loss: 2.1244 - val_acc: 0.2844\n",
      "Epoch 2/30\n",
      "2266/2266 [==============================] - 1s 257us/step - loss: 2.1332 - acc: 0.1986 - val_loss: 2.0641 - val_acc: 0.2644\n",
      "Epoch 3/30\n",
      "2266/2266 [==============================] - 1s 251us/step - loss: 1.9961 - acc: 0.2577 - val_loss: 1.8470 - val_acc: 0.3738\n",
      "Epoch 4/30\n",
      "2266/2266 [==============================] - ETA: 0s - loss: 1.7472 - acc: 0.391 - 1s 251us/step - loss: 1.7521 - acc: 0.3910 - val_loss: 1.7726 - val_acc: 0.4339\n",
      "Epoch 5/30\n",
      "2266/2266 [==============================] - 1s 251us/step - loss: 1.5927 - acc: 0.4673 - val_loss: 1.7688 - val_acc: 0.4446\n",
      "Epoch 6/30\n",
      "2266/2266 [==============================] - 1s 249us/step - loss: 1.4838 - acc: 0.5026 - val_loss: 1.7213 - val_acc: 0.4553\n",
      "Epoch 7/30\n",
      "2266/2266 [==============================] - 1s 258us/step - loss: 1.3641 - acc: 0.5468 - val_loss: 1.7525 - val_acc: 0.4766\n",
      "Epoch 8/30\n",
      "2266/2266 [==============================] - 1s 258us/step - loss: 1.2567 - acc: 0.5834 - val_loss: 1.8580 - val_acc: 0.4846\n",
      "Epoch 9/30\n",
      "2266/2266 [==============================] - 1s 251us/step - loss: 1.1631 - acc: 0.6134 - val_loss: 1.9679 - val_acc: 0.5073\n",
      "Epoch 10/30\n",
      "2266/2266 [==============================] - 1s 256us/step - loss: 1.1053 - acc: 0.6536 - val_loss: 1.8524 - val_acc: 0.5501\n",
      "Epoch 11/30\n",
      "2266/2266 [==============================] - 1s 251us/step - loss: 1.0286 - acc: 0.6690 - val_loss: 2.0732 - val_acc: 0.5140\n",
      "Epoch 12/30\n",
      "2266/2266 [==============================] - 1s 288us/step - loss: 0.9785 - acc: 0.6880 - val_loss: 2.1369 - val_acc: 0.5287\n",
      "Epoch 13/30\n",
      "2266/2266 [==============================] - 1s 248us/step - loss: 0.9045 - acc: 0.7149 - val_loss: 2.2011 - val_acc: 0.5527\n",
      "Epoch 14/30\n",
      "2266/2266 [==============================] - 1s 258us/step - loss: 0.8775 - acc: 0.7158 - val_loss: 2.2786 - val_acc: 0.5354\n",
      "Epoch 15/30\n",
      "2266/2266 [==============================] - 1s 258us/step - loss: 0.8728 - acc: 0.7264 - val_loss: 2.1438 - val_acc: 0.5300\n",
      "Epoch 16/30\n",
      "2266/2266 [==============================] - 1s 251us/step - loss: 0.7912 - acc: 0.7507 - val_loss: 2.3154 - val_acc: 0.5314\n",
      "Epoch 17/30\n",
      "2266/2266 [==============================] - 1s 265us/step - loss: 0.7435 - acc: 0.7635 - val_loss: 2.5372 - val_acc: 0.5327\n",
      "Epoch 18/30\n",
      "2266/2266 [==============================] - 1s 260us/step - loss: 0.7482 - acc: 0.7754 - val_loss: 2.4342 - val_acc: 0.5100\n",
      "Epoch 19/30\n",
      "2266/2266 [==============================] - 1s 253us/step - loss: 0.7378 - acc: 0.7780 - val_loss: 2.5660 - val_acc: 0.5421\n",
      "Epoch 20/30\n",
      "2266/2266 [==============================] - 1s 244us/step - loss: 0.7057 - acc: 0.7758 - val_loss: 2.4880 - val_acc: 0.5434\n",
      "Epoch 21/30\n",
      "2266/2266 [==============================] - 1s 248us/step - loss: 0.6799 - acc: 0.7891 - val_loss: 2.4934 - val_acc: 0.5487\n",
      "Epoch 22/30\n",
      "2266/2266 [==============================] - 1s 258us/step - loss: 0.6873 - acc: 0.7935 - val_loss: 2.3982 - val_acc: 0.5340\n",
      "Epoch 23/30\n",
      "2266/2266 [==============================] - 1s 258us/step - loss: 0.6138 - acc: 0.8133 - val_loss: 2.7097 - val_acc: 0.5447\n",
      "Epoch 24/30\n",
      "2266/2266 [==============================] - 1s 265us/step - loss: 0.5929 - acc: 0.8244 - val_loss: 2.6319 - val_acc: 0.5340\n",
      "Epoch 25/30\n",
      "2266/2266 [==============================] - 1s 258us/step - loss: 0.5807 - acc: 0.8213 - val_loss: 2.6074 - val_acc: 0.5327\n",
      "Epoch 26/30\n",
      "2266/2266 [==============================] - 1s 265us/step - loss: 0.5685 - acc: 0.8261 - val_loss: 2.7270 - val_acc: 0.5367\n",
      "Epoch 27/30\n",
      "2266/2266 [==============================] - 1s 340us/step - loss: 0.5744 - acc: 0.8235 - val_loss: 2.5543 - val_acc: 0.5354\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2266/2266 [==============================] - 1s 265us/step - loss: 0.6083 - acc: 0.8138 - val_loss: 2.6175 - val_acc: 0.5220\n",
      "Epoch 29/30\n",
      "2266/2266 [==============================] - 1s 255us/step - loss: 0.5406 - acc: 0.8310 - val_loss: 2.8167 - val_acc: 0.5314\n",
      "Epoch 30/30\n",
      "2266/2266 [==============================] - 1s 251us/step - loss: 0.5271 - acc: 0.8402 - val_loss: 2.8165 - val_acc: 0.5514\n",
      "749/749 [==============================] - 0s 71us/step\n"
     ]
    }
   ],
   "source": [
    "#k=4\n",
    "kf = StratifiedKFold(n_splits=4, random_state=None, shuffle=False)\n",
    "val_loss_cv = []\n",
    "val_acc_cv = []\n",
    "j = 0\n",
    "for train_index, test_index in kf.split(X,y):\n",
    "    j+=1\n",
    "    print(f\"Fold {j} :\")\n",
    "    print(\"\")\n",
    "    X_train,X_test = X[train_index],X[test_index]\n",
    "    y_train,y_test = y[train_index],y[test_index]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim=X_train.shape[1], units=128,\n",
    "                     kernel_initializer='normal', bias_initializer='zeros'))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    for i in range(0, 6):\n",
    "        model.add(Dense(units=128, kernel_initializer='normal',\n",
    "                         bias_initializer='zeros'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(.40))\n",
    "\n",
    "    model.add(Dense(units=19))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train,batch_size=24,epochs=30,verbose=1,validation_data=(X_test, y_test))\n",
    "    score = model.evaluate(X_test, y_test, verbose=1)\n",
    "    val_loss_cv.append(score[0])\n",
    "    val_acc_cv.append(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss_cv : [3.596566188992478, 2.740837336218958, 2.8080869782765707, 2.816477676895814]\n",
      "mean_val_loss_cv : 2.990492045095955\n",
      "val_acc_cv : [0.45013123406512845, 0.5225464194143482, 0.5333333336512248, 0.551401869278247]\n",
      "mean_val_acc_cv : 0.5143532141022371\n"
     ]
    }
   ],
   "source": [
    "print(f\"val_loss_cv : {val_loss_cv}\")\n",
    "print(f\"mean_val_loss_cv : {np.mean(val_loss_cv)}\")\n",
    "print(f\"val_acc_cv : {val_acc_cv}\")\n",
    "print(f\"mean_val_acc_cv : {np.mean(val_acc_cv)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
