{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#masukin data1\n",
    "data1=pandas.read_csv('D:\\\\SKRIPSI\\\\data\\\\data_praproses\\\\jamu_herbs.csv', sep=',')\n",
    "#masukin data2\n",
    "data2=pandas.read_csv('D:\\\\SKRIPSI\\\\data\\\\data_praproses\\\\jamu_class.csv', sep=',')\n",
    "data_1 = data1.drop('IDJamu',axis=1)\n",
    "data_2 = data2.drop('Jamu ID',axis=1)\n",
    "data_1['Kelas']=data_2['Class of Diseases']\n",
    "X = data_1.drop('Kelas', axis=1).values\n",
    "y = data_1['Kelas'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=4.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 :\n",
      "\n",
      "Train on 2253 samples, validate on 762 samples\n",
      "Epoch 1/50\n",
      "2253/2253 [==============================] - 1s 590us/step - loss: 2.3272 - acc: 0.2015 - val_loss: 2.1048 - val_acc: 0.2113\n",
      "Epoch 2/50\n",
      "2253/2253 [==============================] - 1s 238us/step - loss: 2.0418 - acc: 0.2304 - val_loss: 2.0782 - val_acc: 0.2047\n",
      "Epoch 3/50\n",
      "2253/2253 [==============================] - 1s 245us/step - loss: 1.9111 - acc: 0.2854 - val_loss: 1.9576 - val_acc: 0.3583\n",
      "Epoch 4/50\n",
      "2253/2253 [==============================] - 1s 224us/step - loss: 1.6296 - acc: 0.4292 - val_loss: 1.8036 - val_acc: 0.4475\n",
      "Epoch 5/50\n",
      "2253/2253 [==============================] - 0s 220us/step - loss: 1.3544 - acc: 0.5619 - val_loss: 2.1523 - val_acc: 0.4094\n",
      "Epoch 6/50\n",
      "2253/2253 [==============================] - 1s 236us/step - loss: 1.1705 - acc: 0.6343 - val_loss: 1.9265 - val_acc: 0.4593\n",
      "Epoch 7/50\n",
      "2253/2253 [==============================] - 0s 219us/step - loss: 1.0138 - acc: 0.6835 - val_loss: 2.3415 - val_acc: 0.4501\n",
      "Epoch 8/50\n",
      "2253/2253 [==============================] - 1s 230us/step - loss: 0.9195 - acc: 0.7133 - val_loss: 2.5047 - val_acc: 0.4068\n",
      "Epoch 9/50\n",
      "2253/2253 [==============================] - 0s 216us/step - loss: 0.8098 - acc: 0.7532 - val_loss: 2.4038 - val_acc: 0.4121\n",
      "Epoch 10/50\n",
      "2253/2253 [==============================] - 1s 228us/step - loss: 0.6902 - acc: 0.7816 - val_loss: 2.6690 - val_acc: 0.4659\n",
      "Epoch 11/50\n",
      "2253/2253 [==============================] - 1s 238us/step - loss: 0.6411 - acc: 0.8034 - val_loss: 2.5781 - val_acc: 0.4777\n",
      "Epoch 12/50\n",
      "2253/2253 [==============================] - 0s 218us/step - loss: 0.6112 - acc: 0.8123 - val_loss: 2.5627 - val_acc: 0.4541\n",
      "Epoch 13/50\n",
      "2253/2253 [==============================] - 1s 226us/step - loss: 0.5556 - acc: 0.8327 - val_loss: 2.7025 - val_acc: 0.4711\n",
      "Epoch 14/50\n",
      "2253/2253 [==============================] - 0s 215us/step - loss: 0.5270 - acc: 0.8393 - val_loss: 2.9541 - val_acc: 0.4488\n",
      "Epoch 15/50\n",
      "2253/2253 [==============================] - 1s 222us/step - loss: 0.4616 - acc: 0.8571 - val_loss: 3.2263 - val_acc: 0.4633\n",
      "Epoch 16/50\n",
      "2253/2253 [==============================] - 0s 222us/step - loss: 0.4880 - acc: 0.8451 - val_loss: 2.7668 - val_acc: 0.4409\n",
      "Epoch 17/50\n",
      "2253/2253 [==============================] - 0s 220us/step - loss: 0.4469 - acc: 0.8651 - val_loss: 3.0063 - val_acc: 0.4738\n",
      "Epoch 18/50\n",
      "2253/2253 [==============================] - 1s 227us/step - loss: 0.3967 - acc: 0.8815 - val_loss: 3.2962 - val_acc: 0.4567\n",
      "Epoch 19/50\n",
      "2253/2253 [==============================] - 1s 243us/step - loss: 0.4145 - acc: 0.8788 - val_loss: 3.2317 - val_acc: 0.4974\n",
      "Epoch 20/50\n",
      "2253/2253 [==============================] - 1s 242us/step - loss: 0.3662 - acc: 0.8895 - val_loss: 3.3503 - val_acc: 0.4908\n",
      "Epoch 21/50\n",
      "2253/2253 [==============================] - 1s 236us/step - loss: 0.3465 - acc: 0.9037 - val_loss: 3.4527 - val_acc: 0.4803\n",
      "Epoch 22/50\n",
      "2253/2253 [==============================] - 1s 231us/step - loss: 0.3434 - acc: 0.8975 - val_loss: 3.5267 - val_acc: 0.4829\n",
      "Epoch 23/50\n",
      "2253/2253 [==============================] - 1s 233us/step - loss: 0.3435 - acc: 0.8948 - val_loss: 3.5031 - val_acc: 0.4790\n",
      "Epoch 24/50\n",
      "2253/2253 [==============================] - 0s 220us/step - loss: 0.2868 - acc: 0.9130 - val_loss: 3.5353 - val_acc: 0.4974\n",
      "Epoch 25/50\n",
      "2253/2253 [==============================] - 0s 217us/step - loss: 0.3112 - acc: 0.9183 - val_loss: 3.7853 - val_acc: 0.4829\n",
      "Epoch 26/50\n",
      "2253/2253 [==============================] - 1s 228us/step - loss: 0.2809 - acc: 0.9201 - val_loss: 3.5997 - val_acc: 0.4934\n",
      "Epoch 27/50\n",
      "2253/2253 [==============================] - 1s 224us/step - loss: 0.2536 - acc: 0.9312 - val_loss: 3.8985 - val_acc: 0.4790\n",
      "Epoch 28/50\n",
      "2253/2253 [==============================] - 0s 221us/step - loss: 0.2736 - acc: 0.9237 - val_loss: 3.7724 - val_acc: 0.5000\n",
      "Epoch 29/50\n",
      "2253/2253 [==============================] - 1s 222us/step - loss: 0.2681 - acc: 0.9214 - val_loss: 3.6969 - val_acc: 0.4764\n",
      "Epoch 30/50\n",
      "2253/2253 [==============================] - 1s 229us/step - loss: 0.2303 - acc: 0.9348 - val_loss: 4.0312 - val_acc: 0.4816\n",
      "Epoch 31/50\n",
      "2253/2253 [==============================] - 0s 217us/step - loss: 0.2416 - acc: 0.9339 - val_loss: 3.9484 - val_acc: 0.4790\n",
      "Epoch 32/50\n",
      "2253/2253 [==============================] - 1s 224us/step - loss: 0.2570 - acc: 0.9316 - val_loss: 3.8281 - val_acc: 0.4908\n",
      "Epoch 33/50\n",
      "2253/2253 [==============================] - 1s 232us/step - loss: 0.2173 - acc: 0.9414 - val_loss: 4.3237 - val_acc: 0.4554\n",
      "Epoch 34/50\n",
      "2253/2253 [==============================] - 0s 219us/step - loss: 0.2173 - acc: 0.9445 - val_loss: 4.0305 - val_acc: 0.4724\n",
      "Epoch 35/50\n",
      "2253/2253 [==============================] - 1s 224us/step - loss: 0.1838 - acc: 0.9525 - val_loss: 4.6622 - val_acc: 0.4409\n",
      "Epoch 36/50\n",
      "2253/2253 [==============================] - 1s 229us/step - loss: 0.2057 - acc: 0.9450 - val_loss: 4.3773 - val_acc: 0.4698\n",
      "Epoch 37/50\n",
      "2253/2253 [==============================] - 0s 221us/step - loss: 0.2303 - acc: 0.9405 - val_loss: 4.0656 - val_acc: 0.4974\n",
      "Epoch 38/50\n",
      "2253/2253 [==============================] - 1s 223us/step - loss: 0.2138 - acc: 0.9436 - val_loss: 3.8778 - val_acc: 0.4869\n",
      "Epoch 39/50\n",
      "2253/2253 [==============================] - 1s 230us/step - loss: 0.2468 - acc: 0.9365 - val_loss: 3.5511 - val_acc: 0.4961\n",
      "Epoch 40/50\n",
      "2253/2253 [==============================] - 0s 222us/step - loss: 0.2110 - acc: 0.9445 - val_loss: 3.5602 - val_acc: 0.4843\n",
      "Epoch 41/50\n",
      "2253/2253 [==============================] - 1s 222us/step - loss: 0.1888 - acc: 0.9516 - val_loss: 3.8391 - val_acc: 0.4908\n",
      "Epoch 42/50\n",
      "2253/2253 [==============================] - 1s 240us/step - loss: 0.1660 - acc: 0.9556 - val_loss: 4.0426 - val_acc: 0.4790\n",
      "Epoch 43/50\n",
      "2253/2253 [==============================] - 1s 231us/step - loss: 0.1906 - acc: 0.9534 - val_loss: 3.8532 - val_acc: 0.4790\n",
      "Epoch 44/50\n",
      "2253/2253 [==============================] - 1s 231us/step - loss: 0.1836 - acc: 0.9569 - val_loss: 3.7537 - val_acc: 0.4895\n",
      "Epoch 45/50\n",
      "2253/2253 [==============================] - 0s 220us/step - loss: 0.1737 - acc: 0.9543 - val_loss: 4.1914 - val_acc: 0.4764\n",
      "Epoch 46/50\n",
      "2253/2253 [==============================] - 1s 236us/step - loss: 0.1589 - acc: 0.9592 - val_loss: 3.9897 - val_acc: 0.4882\n",
      "Epoch 47/50\n",
      "2253/2253 [==============================] - 0s 220us/step - loss: 0.1588 - acc: 0.9609 - val_loss: 4.1955 - val_acc: 0.4856\n",
      "Epoch 48/50\n",
      "2253/2253 [==============================] - 1s 226us/step - loss: 0.1582 - acc: 0.9605 - val_loss: 3.8957 - val_acc: 0.4908\n",
      "Epoch 49/50\n",
      "2253/2253 [==============================] - 0s 218us/step - loss: 0.1445 - acc: 0.9601 - val_loss: 4.4079 - val_acc: 0.4829\n",
      "Epoch 50/50\n",
      "2253/2253 [==============================] - 1s 231us/step - loss: 0.1687 - acc: 0.9530 - val_loss: 4.2626 - val_acc: 0.4816\n",
      "762/762 [==============================] - 0s 62us/step\n",
      "Fold 2 :\n",
      "\n",
      "Train on 2261 samples, validate on 754 samples\n",
      "Epoch 1/50\n",
      "2261/2261 [==============================] - 1s 539us/step - loss: 2.3204 - acc: 0.2096 - val_loss: 2.0716 - val_acc: 0.2149\n",
      "Epoch 2/50\n",
      "2261/2261 [==============================] - 1s 242us/step - loss: 2.0604 - acc: 0.2136 - val_loss: 2.0909 - val_acc: 0.1844\n",
      "Epoch 3/50\n",
      "2261/2261 [==============================] - 1s 236us/step - loss: 1.9496 - acc: 0.2636 - val_loss: 2.0317 - val_acc: 0.3117\n",
      "Epoch 4/50\n",
      "2261/2261 [==============================] - 1s 230us/step - loss: 1.7533 - acc: 0.3534 - val_loss: 1.8383 - val_acc: 0.3833\n",
      "Epoch 5/50\n",
      "2261/2261 [==============================] - 1s 234us/step - loss: 1.5234 - acc: 0.4494 - val_loss: 1.7973 - val_acc: 0.4218\n",
      "Epoch 6/50\n",
      "2261/2261 [==============================] - 1s 232us/step - loss: 1.3349 - acc: 0.5082 - val_loss: 1.8344 - val_acc: 0.4721\n",
      "Epoch 7/50\n",
      "2261/2261 [==============================] - 1s 234us/step - loss: 1.1993 - acc: 0.5878 - val_loss: 1.7835 - val_acc: 0.4973\n",
      "Epoch 8/50\n",
      "2261/2261 [==============================] - 1s 234us/step - loss: 1.0800 - acc: 0.6395 - val_loss: 1.9108 - val_acc: 0.5212\n",
      "Epoch 9/50\n",
      "2261/2261 [==============================] - 1s 236us/step - loss: 0.9556 - acc: 0.6997 - val_loss: 1.8946 - val_acc: 0.5358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "2261/2261 [==============================] - 0s 218us/step - loss: 0.8855 - acc: 0.7267 - val_loss: 1.9114 - val_acc: 0.5464\n",
      "Epoch 11/50\n",
      "2261/2261 [==============================] - 0s 221us/step - loss: 0.8096 - acc: 0.7510 - val_loss: 1.8949 - val_acc: 0.5544\n",
      "Epoch 12/50\n",
      "2261/2261 [==============================] - 0s 215us/step - loss: 0.7320 - acc: 0.7718 - val_loss: 1.9931 - val_acc: 0.5464\n",
      "Epoch 13/50\n",
      "2261/2261 [==============================] - 1s 223us/step - loss: 0.6864 - acc: 0.7912 - val_loss: 1.9614 - val_acc: 0.5650\n",
      "Epoch 14/50\n",
      "2261/2261 [==============================] - 0s 212us/step - loss: 0.6290 - acc: 0.8094 - val_loss: 2.0016 - val_acc: 0.5623\n",
      "Epoch 15/50\n",
      "2261/2261 [==============================] - 1s 222us/step - loss: 0.6022 - acc: 0.8120 - val_loss: 1.9862 - val_acc: 0.5358\n",
      "Epoch 16/50\n",
      "2261/2261 [==============================] - 1s 229us/step - loss: 0.5586 - acc: 0.8306 - val_loss: 2.1816 - val_acc: 0.5411\n",
      "Epoch 17/50\n",
      "2261/2261 [==============================] - 0s 214us/step - loss: 0.5538 - acc: 0.8240 - val_loss: 2.2553 - val_acc: 0.5371\n",
      "Epoch 18/50\n",
      "2261/2261 [==============================] - 1s 229us/step - loss: 0.5323 - acc: 0.8368 - val_loss: 2.4576 - val_acc: 0.5332\n",
      "Epoch 19/50\n",
      "2261/2261 [==============================] - 0s 218us/step - loss: 0.4926 - acc: 0.8532 - val_loss: 2.3552 - val_acc: 0.5292\n",
      "Epoch 20/50\n",
      "2261/2261 [==============================] - 0s 218us/step - loss: 0.4859 - acc: 0.8408 - val_loss: 2.4570 - val_acc: 0.5345\n",
      "Epoch 21/50\n",
      "2261/2261 [==============================] - 1s 221us/step - loss: 0.4800 - acc: 0.8549 - val_loss: 2.4779 - val_acc: 0.5584\n",
      "Epoch 22/50\n",
      "2261/2261 [==============================] - 0s 216us/step - loss: 0.4042 - acc: 0.8762 - val_loss: 2.6734 - val_acc: 0.5663\n",
      "Epoch 23/50\n",
      "2261/2261 [==============================] - 0s 220us/step - loss: 0.4517 - acc: 0.8607 - val_loss: 2.3827 - val_acc: 0.5451\n",
      "Epoch 24/50\n",
      "2261/2261 [==============================] - 0s 213us/step - loss: 0.4133 - acc: 0.8731 - val_loss: 2.5872 - val_acc: 0.5796\n",
      "Epoch 25/50\n",
      "2261/2261 [==============================] - 1s 223us/step - loss: 0.3692 - acc: 0.8828 - val_loss: 2.8804 - val_acc: 0.5570\n",
      "Epoch 26/50\n",
      "2261/2261 [==============================] - 0s 217us/step - loss: 0.3495 - acc: 0.8934 - val_loss: 2.7200 - val_acc: 0.5398\n",
      "Epoch 27/50\n",
      "2261/2261 [==============================] - 0s 220us/step - loss: 0.3759 - acc: 0.8890 - val_loss: 2.5938 - val_acc: 0.5782\n",
      "Epoch 28/50\n",
      "2261/2261 [==============================] - 0s 221us/step - loss: 0.3538 - acc: 0.8978 - val_loss: 2.8523 - val_acc: 0.5676\n",
      "Epoch 29/50\n",
      "2261/2261 [==============================] - 0s 218us/step - loss: 0.3305 - acc: 0.9054 - val_loss: 2.7761 - val_acc: 0.5676\n",
      "Epoch 30/50\n",
      "2261/2261 [==============================] - 0s 218us/step - loss: 0.3340 - acc: 0.8965 - val_loss: 2.7336 - val_acc: 0.5464\n",
      "Epoch 31/50\n",
      "2261/2261 [==============================] - 1s 222us/step - loss: 0.3364 - acc: 0.8956 - val_loss: 2.7307 - val_acc: 0.5650\n",
      "Epoch 32/50\n",
      "2261/2261 [==============================] - 1s 223us/step - loss: 0.3005 - acc: 0.9124 - val_loss: 3.0353 - val_acc: 0.5769\n",
      "Epoch 33/50\n",
      "2261/2261 [==============================] - 0s 215us/step - loss: 0.3327 - acc: 0.9093 - val_loss: 2.6103 - val_acc: 0.5703\n",
      "Epoch 34/50\n",
      "2261/2261 [==============================] - 0s 221us/step - loss: 0.3036 - acc: 0.9120 - val_loss: 2.9486 - val_acc: 0.5650\n",
      "Epoch 35/50\n",
      "2261/2261 [==============================] - 1s 225us/step - loss: 0.3028 - acc: 0.9124 - val_loss: 2.9168 - val_acc: 0.5782\n",
      "Epoch 36/50\n",
      "2261/2261 [==============================] - 0s 219us/step - loss: 0.2813 - acc: 0.9177 - val_loss: 2.8142 - val_acc: 0.5650\n",
      "Epoch 37/50\n",
      "2261/2261 [==============================] - 0s 220us/step - loss: 0.2675 - acc: 0.9253 - val_loss: 2.9309 - val_acc: 0.5610\n",
      "Epoch 38/50\n",
      "2261/2261 [==============================] - 0s 220us/step - loss: 0.2333 - acc: 0.9310 - val_loss: 3.1399 - val_acc: 0.5610\n",
      "Epoch 39/50\n",
      "2261/2261 [==============================] - 0s 217us/step - loss: 0.2855 - acc: 0.9164 - val_loss: 2.9764 - val_acc: 0.5676\n",
      "Epoch 40/50\n",
      "2261/2261 [==============================] - 0s 216us/step - loss: 0.2411 - acc: 0.9301 - val_loss: 3.0456 - val_acc: 0.5782\n",
      "Epoch 41/50\n",
      "2261/2261 [==============================] - 1s 228us/step - loss: 0.2556 - acc: 0.9266 - val_loss: 3.0814 - val_acc: 0.5796\n",
      "Epoch 42/50\n",
      "2261/2261 [==============================] - 0s 221us/step - loss: 0.2231 - acc: 0.9385 - val_loss: 2.9606 - val_acc: 0.5743\n",
      "Epoch 43/50\n",
      "2261/2261 [==============================] - 1s 222us/step - loss: 0.2415 - acc: 0.9270 - val_loss: 3.0652 - val_acc: 0.5769\n",
      "Epoch 44/50\n",
      "2261/2261 [==============================] - 1s 221us/step - loss: 0.2497 - acc: 0.9292 - val_loss: 3.1380 - val_acc: 0.5756\n",
      "Epoch 45/50\n",
      "2261/2261 [==============================] - 0s 220us/step - loss: 0.2241 - acc: 0.9372 - val_loss: 2.9740 - val_acc: 0.5716\n",
      "Epoch 46/50\n",
      "2261/2261 [==============================] - 0s 221us/step - loss: 0.2161 - acc: 0.9381 - val_loss: 3.3009 - val_acc: 0.5570\n",
      "Epoch 47/50\n",
      "2261/2261 [==============================] - 0s 221us/step - loss: 0.2478 - acc: 0.9292 - val_loss: 3.1043 - val_acc: 0.5637\n",
      "Epoch 48/50\n",
      "2261/2261 [==============================] - 1s 225us/step - loss: 0.2081 - acc: 0.9416 - val_loss: 3.2517 - val_acc: 0.5623\n",
      "Epoch 49/50\n",
      "2261/2261 [==============================] - 1s 224us/step - loss: 0.2156 - acc: 0.9385 - val_loss: 3.0195 - val_acc: 0.5729\n",
      "Epoch 50/50\n",
      "2261/2261 [==============================] - 0s 221us/step - loss: 0.2105 - acc: 0.9438 - val_loss: 3.0238 - val_acc: 0.5796\n",
      "754/754 [==============================] - 0s 52us/step\n",
      "Fold 3 :\n",
      "\n",
      "Train on 2265 samples, validate on 750 samples\n",
      "Epoch 1/50\n",
      "2265/2265 [==============================] - 1s 569us/step - loss: 2.3274 - acc: 0.1982 - val_loss: 2.1205 - val_acc: 0.1920\n",
      "Epoch 2/50\n",
      "2265/2265 [==============================] - 1s 251us/step - loss: 2.0580 - acc: 0.2216 - val_loss: 2.0562 - val_acc: 0.1800\n",
      "Epoch 3/50\n",
      "2265/2265 [==============================] - 1s 240us/step - loss: 1.9286 - acc: 0.2503 - val_loss: 1.9180 - val_acc: 0.3013\n",
      "Epoch 4/50\n",
      "2265/2265 [==============================] - 1s 246us/step - loss: 1.7385 - acc: 0.3205 - val_loss: 1.9399 - val_acc: 0.2907\n",
      "Epoch 5/50\n",
      "2265/2265 [==============================] - 1s 237us/step - loss: 1.5553 - acc: 0.3925 - val_loss: 1.8734 - val_acc: 0.4027\n",
      "Epoch 6/50\n",
      "2265/2265 [==============================] - 1s 236us/step - loss: 1.3069 - acc: 0.5444 - val_loss: 1.9189 - val_acc: 0.4493\n",
      "Epoch 7/50\n",
      "2265/2265 [==============================] - 1s 232us/step - loss: 1.1430 - acc: 0.6053 - val_loss: 1.9164 - val_acc: 0.4880\n",
      "Epoch 8/50\n",
      "2265/2265 [==============================] - 1s 238us/step - loss: 1.0067 - acc: 0.6640 - val_loss: 2.0619 - val_acc: 0.4840\n",
      "Epoch 9/50\n",
      "2265/2265 [==============================] - 1s 238us/step - loss: 0.9112 - acc: 0.7020 - val_loss: 2.1063 - val_acc: 0.5173\n",
      "Epoch 10/50\n",
      "2265/2265 [==============================] - 1s 239us/step - loss: 0.8232 - acc: 0.7369 - val_loss: 2.1573 - val_acc: 0.5307\n",
      "Epoch 11/50\n",
      "2265/2265 [==============================] - 1s 233us/step - loss: 0.7495 - acc: 0.7532 - val_loss: 2.3050 - val_acc: 0.5480\n",
      "Epoch 12/50\n",
      "2265/2265 [==============================] - 1s 235us/step - loss: 0.6803 - acc: 0.7943 - val_loss: 2.2559 - val_acc: 0.5347\n",
      "Epoch 13/50\n",
      "2265/2265 [==============================] - 1s 230us/step - loss: 0.6459 - acc: 0.8053 - val_loss: 2.4631 - val_acc: 0.5560\n",
      "Epoch 14/50\n",
      "2265/2265 [==============================] - 1s 236us/step - loss: 0.5917 - acc: 0.8216 - val_loss: 2.3518 - val_acc: 0.5493\n",
      "Epoch 15/50\n",
      "2265/2265 [==============================] - 1s 238us/step - loss: 0.5268 - acc: 0.8371 - val_loss: 2.4842 - val_acc: 0.5347\n",
      "Epoch 16/50\n",
      "2265/2265 [==============================] - 1s 232us/step - loss: 0.4603 - acc: 0.8693 - val_loss: 2.6693 - val_acc: 0.5573\n",
      "Epoch 17/50\n",
      "2265/2265 [==============================] - 1s 233us/step - loss: 0.4338 - acc: 0.8702 - val_loss: 2.7845 - val_acc: 0.5493\n",
      "Epoch 18/50\n",
      "2265/2265 [==============================] - 1s 246us/step - loss: 0.4021 - acc: 0.8843 - val_loss: 2.6945 - val_acc: 0.5320\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2265/2265 [==============================] - 1s 233us/step - loss: 0.3869 - acc: 0.8861 - val_loss: 2.8330 - val_acc: 0.5293\n",
      "Epoch 20/50\n",
      "2265/2265 [==============================] - 1s 221us/step - loss: 0.3332 - acc: 0.9020 - val_loss: 3.0044 - val_acc: 0.5520\n",
      "Epoch 21/50\n",
      "2265/2265 [==============================] - 1s 240us/step - loss: 0.3484 - acc: 0.9011 - val_loss: 2.7124 - val_acc: 0.5600\n",
      "Epoch 22/50\n",
      "2265/2265 [==============================] - 1s 230us/step - loss: 0.3364 - acc: 0.8989 - val_loss: 2.9450 - val_acc: 0.5493\n",
      "Epoch 23/50\n",
      "2265/2265 [==============================] - 1s 251us/step - loss: 0.3333 - acc: 0.9068 - val_loss: 3.0511 - val_acc: 0.5653\n",
      "Epoch 24/50\n",
      "2265/2265 [==============================] - 1s 253us/step - loss: 0.3324 - acc: 0.9020 - val_loss: 2.7916 - val_acc: 0.5653\n",
      "Epoch 25/50\n",
      "2265/2265 [==============================] - 1s 265us/step - loss: 0.2979 - acc: 0.9148 - val_loss: 2.8917 - val_acc: 0.5747\n",
      "Epoch 26/50\n",
      "2265/2265 [==============================] - 1s 254us/step - loss: 0.2942 - acc: 0.9148 - val_loss: 3.0358 - val_acc: 0.5653\n",
      "Epoch 27/50\n",
      "2265/2265 [==============================] - 1s 260us/step - loss: 0.2809 - acc: 0.9210 - val_loss: 2.9371 - val_acc: 0.5547\n",
      "Epoch 28/50\n",
      "2265/2265 [==============================] - 1s 254us/step - loss: 0.2939 - acc: 0.9179 - val_loss: 3.0169 - val_acc: 0.5693\n",
      "Epoch 29/50\n",
      "2265/2265 [==============================] - 1s 232us/step - loss: 0.2578 - acc: 0.9285 - val_loss: 3.0335 - val_acc: 0.5773\n",
      "Epoch 30/50\n",
      "2265/2265 [==============================] - 1s 233us/step - loss: 0.2299 - acc: 0.9351 - val_loss: 3.3022 - val_acc: 0.5440\n",
      "Epoch 31/50\n",
      "2265/2265 [==============================] - 1s 231us/step - loss: 0.2245 - acc: 0.9408 - val_loss: 3.0924 - val_acc: 0.5653\n",
      "Epoch 32/50\n",
      "2265/2265 [==============================] - 1s 223us/step - loss: 0.2438 - acc: 0.9302 - val_loss: 3.3868 - val_acc: 0.5480\n",
      "Epoch 33/50\n",
      "2265/2265 [==============================] - 1s 237us/step - loss: 0.2405 - acc: 0.9325 - val_loss: 3.4444 - val_acc: 0.5613\n",
      "Epoch 34/50\n",
      "2265/2265 [==============================] - 1s 232us/step - loss: 0.2439 - acc: 0.9325 - val_loss: 3.3198 - val_acc: 0.5720\n",
      "Epoch 35/50\n",
      "2265/2265 [==============================] - 1s 237us/step - loss: 0.2073 - acc: 0.9382 - val_loss: 3.4231 - val_acc: 0.5800\n",
      "Epoch 36/50\n",
      "2265/2265 [==============================] - 1s 237us/step - loss: 0.2125 - acc: 0.9377 - val_loss: 3.3612 - val_acc: 0.5600\n",
      "Epoch 37/50\n",
      "2265/2265 [==============================] - 1s 231us/step - loss: 0.2547 - acc: 0.9316 - val_loss: 3.1746 - val_acc: 0.5693\n",
      "Epoch 38/50\n",
      "2265/2265 [==============================] - 1s 247us/step - loss: 0.2567 - acc: 0.9333 - val_loss: 3.2736 - val_acc: 0.5720\n",
      "Epoch 39/50\n",
      "2265/2265 [==============================] - 1s 239us/step - loss: 0.2419 - acc: 0.9338 - val_loss: 3.1377 - val_acc: 0.5760\n",
      "Epoch 40/50\n",
      "2265/2265 [==============================] - 1s 267us/step - loss: 0.2082 - acc: 0.9426 - val_loss: 3.2233 - val_acc: 0.5693\n",
      "Epoch 41/50\n",
      "2265/2265 [==============================] - 1s 228us/step - loss: 0.1983 - acc: 0.9448 - val_loss: 3.3407 - val_acc: 0.5613\n",
      "Epoch 42/50\n",
      "2265/2265 [==============================] - 1s 237us/step - loss: 0.1947 - acc: 0.9479 - val_loss: 3.4650 - val_acc: 0.5547\n",
      "Epoch 43/50\n",
      "2265/2265 [==============================] - 1s 224us/step - loss: 0.1875 - acc: 0.9461 - val_loss: 3.5811 - val_acc: 0.5600\n",
      "Epoch 44/50\n",
      "2265/2265 [==============================] - 1s 237us/step - loss: 0.2013 - acc: 0.9475 - val_loss: 3.4225 - val_acc: 0.5547\n",
      "Epoch 45/50\n",
      "2265/2265 [==============================] - 1s 233us/step - loss: 0.1799 - acc: 0.9430 - val_loss: 3.5226 - val_acc: 0.5480\n",
      "Epoch 46/50\n",
      "2265/2265 [==============================] - 1s 231us/step - loss: 0.2155 - acc: 0.9422 - val_loss: 3.2847 - val_acc: 0.5667\n",
      "Epoch 47/50\n",
      "2265/2265 [==============================] - 1s 233us/step - loss: 0.1713 - acc: 0.9497 - val_loss: 3.5528 - val_acc: 0.5827\n",
      "Epoch 48/50\n",
      "2265/2265 [==============================] - 1s 230us/step - loss: 0.1540 - acc: 0.9589 - val_loss: 3.6770 - val_acc: 0.5720\n",
      "Epoch 49/50\n",
      "2265/2265 [==============================] - 1s 234us/step - loss: 0.1464 - acc: 0.9576 - val_loss: 3.6340 - val_acc: 0.5680\n",
      "Epoch 50/50\n",
      "2265/2265 [==============================] - 1s 228us/step - loss: 0.1486 - acc: 0.9625 - val_loss: 3.6579 - val_acc: 0.5747\n",
      "750/750 [==============================] - 0s 55us/step\n",
      "Fold 4 :\n",
      "\n",
      "Train on 2266 samples, validate on 749 samples\n",
      "Epoch 1/50\n",
      "2266/2266 [==============================] - 1s 607us/step - loss: 2.3145 - acc: 0.1968 - val_loss: 2.0935 - val_acc: 0.2163\n",
      "Epoch 2/50\n",
      "2266/2266 [==============================] - 1s 239us/step - loss: 2.0634 - acc: 0.2242 - val_loss: 2.0154 - val_acc: 0.2243\n",
      "Epoch 3/50\n",
      "2266/2266 [==============================] - 1s 231us/step - loss: 1.8806 - acc: 0.2979 - val_loss: 1.8524 - val_acc: 0.3591\n",
      "Epoch 4/50\n",
      "2266/2266 [==============================] - 1s 242us/step - loss: 1.6461 - acc: 0.3928 - val_loss: 1.7907 - val_acc: 0.3952\n",
      "Epoch 5/50\n",
      "2266/2266 [==============================] - 1s 235us/step - loss: 1.4731 - acc: 0.4850 - val_loss: 1.8245 - val_acc: 0.4646\n",
      "Epoch 6/50\n",
      "2266/2266 [==============================] - 1s 237us/step - loss: 1.2933 - acc: 0.5728 - val_loss: 1.7787 - val_acc: 0.5154\n",
      "Epoch 7/50\n",
      "2266/2266 [==============================] - 1s 240us/step - loss: 1.1673 - acc: 0.6302 - val_loss: 1.8463 - val_acc: 0.4927\n",
      "Epoch 8/50\n",
      "2266/2266 [==============================] - 1s 226us/step - loss: 1.0404 - acc: 0.6761 - val_loss: 1.7065 - val_acc: 0.5527\n",
      "Epoch 9/50\n",
      "2266/2266 [==============================] - 1s 241us/step - loss: 0.9134 - acc: 0.7109 - val_loss: 1.7185 - val_acc: 0.5714\n",
      "Epoch 10/50\n",
      "2266/2266 [==============================] - 1s 231us/step - loss: 0.8033 - acc: 0.7449 - val_loss: 1.8979 - val_acc: 0.5594\n",
      "Epoch 11/50\n",
      "2266/2266 [==============================] - 1s 234us/step - loss: 0.7308 - acc: 0.7696 - val_loss: 1.9498 - val_acc: 0.5474\n",
      "Epoch 12/50\n",
      "2266/2266 [==============================] - 1s 238us/step - loss: 0.7118 - acc: 0.7674 - val_loss: 2.0977 - val_acc: 0.5541\n",
      "Epoch 13/50\n",
      "2266/2266 [==============================] - 1s 233us/step - loss: 0.6390 - acc: 0.7895 - val_loss: 2.0175 - val_acc: 0.5714\n",
      "Epoch 14/50\n",
      "2266/2266 [==============================] - 1s 237us/step - loss: 0.5903 - acc: 0.8032 - val_loss: 2.3171 - val_acc: 0.5447\n",
      "Epoch 15/50\n",
      "2266/2266 [==============================] - 1s 249us/step - loss: 0.5462 - acc: 0.8266 - val_loss: 2.4175 - val_acc: 0.5554\n",
      "Epoch 16/50\n",
      "2266/2266 [==============================] - 1s 241us/step - loss: 0.5406 - acc: 0.8310 - val_loss: 2.4299 - val_acc: 0.5514\n",
      "Epoch 17/50\n",
      "2266/2266 [==============================] - 1s 235us/step - loss: 0.4894 - acc: 0.8486 - val_loss: 2.4678 - val_acc: 0.5340\n",
      "Epoch 18/50\n",
      "2266/2266 [==============================] - 1s 244us/step - loss: 0.4479 - acc: 0.8566 - val_loss: 2.4375 - val_acc: 0.5541\n",
      "Epoch 19/50\n",
      "2266/2266 [==============================] - 1s 241us/step - loss: 0.4784 - acc: 0.8508 - val_loss: 2.3812 - val_acc: 0.5541\n",
      "Epoch 20/50\n",
      "2266/2266 [==============================] - 1s 231us/step - loss: 0.4080 - acc: 0.8747 - val_loss: 2.6949 - val_acc: 0.5407\n",
      "Epoch 21/50\n",
      "2266/2266 [==============================] - 1s 240us/step - loss: 0.3747 - acc: 0.8800 - val_loss: 2.6938 - val_acc: 0.5794\n",
      "Epoch 22/50\n",
      "2266/2266 [==============================] - 1s 237us/step - loss: 0.3789 - acc: 0.8875 - val_loss: 2.6016 - val_acc: 0.5714\n",
      "Epoch 23/50\n",
      "2266/2266 [==============================] - 1s 231us/step - loss: 0.3541 - acc: 0.8972 - val_loss: 2.9088 - val_acc: 0.5087\n",
      "Epoch 24/50\n",
      "2266/2266 [==============================] - 1s 239us/step - loss: 0.3438 - acc: 0.8998 - val_loss: 3.1048 - val_acc: 0.5421\n",
      "Epoch 25/50\n",
      "2266/2266 [==============================] - 1s 241us/step - loss: 0.3236 - acc: 0.9056 - val_loss: 3.0005 - val_acc: 0.5487\n",
      "Epoch 26/50\n",
      "2266/2266 [==============================] - 1s 234us/step - loss: 0.3210 - acc: 0.9016 - val_loss: 2.9673 - val_acc: 0.5381\n",
      "Epoch 27/50\n",
      "2266/2266 [==============================] - 1s 237us/step - loss: 0.3093 - acc: 0.9131 - val_loss: 3.0166 - val_acc: 0.5621\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2266/2266 [==============================] - 1s 233us/step - loss: 0.2725 - acc: 0.9170 - val_loss: 3.1128 - val_acc: 0.5808\n",
      "Epoch 29/50\n",
      "2266/2266 [==============================] - 1s 228us/step - loss: 0.2761 - acc: 0.9192 - val_loss: 2.9680 - val_acc: 0.5260\n",
      "Epoch 30/50\n",
      "2266/2266 [==============================] - 1s 238us/step - loss: 0.2920 - acc: 0.9153 - val_loss: 3.2903 - val_acc: 0.5501\n",
      "Epoch 31/50\n",
      "2266/2266 [==============================] - 1s 235us/step - loss: 0.2623 - acc: 0.9237 - val_loss: 3.2129 - val_acc: 0.5501\n",
      "Epoch 32/50\n",
      "2266/2266 [==============================] - 1s 235us/step - loss: 0.2401 - acc: 0.9281 - val_loss: 3.2880 - val_acc: 0.5461\n",
      "Epoch 33/50\n",
      "2266/2266 [==============================] - 1s 235us/step - loss: 0.2368 - acc: 0.9325 - val_loss: 3.3645 - val_acc: 0.5501\n",
      "Epoch 34/50\n",
      "2266/2266 [==============================] - 1s 231us/step - loss: 0.2421 - acc: 0.9316 - val_loss: 3.2908 - val_acc: 0.5394\n",
      "Epoch 35/50\n",
      "2266/2266 [==============================] - 1s 239us/step - loss: 0.2097 - acc: 0.9448 - val_loss: 3.3306 - val_acc: 0.5434\n",
      "Epoch 36/50\n",
      "2266/2266 [==============================] - 1s 237us/step - loss: 0.2069 - acc: 0.9413 - val_loss: 3.3317 - val_acc: 0.5434\n",
      "Epoch 37/50\n",
      "2266/2266 [==============================] - 1s 238us/step - loss: 0.2040 - acc: 0.9413 - val_loss: 3.3957 - val_acc: 0.5527\n",
      "Epoch 38/50\n",
      "2266/2266 [==============================] - 1s 232us/step - loss: 0.1990 - acc: 0.9409 - val_loss: 3.7418 - val_acc: 0.5447\n",
      "Epoch 39/50\n",
      "2266/2266 [==============================] - 1s 239us/step - loss: 0.2002 - acc: 0.9404 - val_loss: 3.5368 - val_acc: 0.5501\n",
      "Epoch 40/50\n",
      "2266/2266 [==============================] - 1s 238us/step - loss: 0.1971 - acc: 0.9448 - val_loss: 3.3310 - val_acc: 0.5634\n",
      "Epoch 41/50\n",
      "2266/2266 [==============================] - 1s 236us/step - loss: 0.1955 - acc: 0.9488 - val_loss: 3.3305 - val_acc: 0.5567\n",
      "Epoch 42/50\n",
      "2266/2266 [==============================] - 1s 237us/step - loss: 0.2198 - acc: 0.9409 - val_loss: 3.3316 - val_acc: 0.5581\n",
      "Epoch 43/50\n",
      "2266/2266 [==============================] - 1s 236us/step - loss: 0.1727 - acc: 0.9506 - val_loss: 3.6295 - val_acc: 0.5474\n",
      "Epoch 44/50\n",
      "2266/2266 [==============================] - 1s 237us/step - loss: 0.1589 - acc: 0.9590 - val_loss: 3.4682 - val_acc: 0.5474\n",
      "Epoch 45/50\n",
      "2266/2266 [==============================] - 1s 239us/step - loss: 0.1729 - acc: 0.9497 - val_loss: 3.7127 - val_acc: 0.5167\n",
      "Epoch 46/50\n",
      "2266/2266 [==============================] - 1s 236us/step - loss: 0.1919 - acc: 0.9426 - val_loss: 3.5637 - val_acc: 0.5367\n",
      "Epoch 47/50\n",
      "2266/2266 [==============================] - 1s 233us/step - loss: 0.1838 - acc: 0.9519 - val_loss: 3.6936 - val_acc: 0.5421\n",
      "Epoch 48/50\n",
      "2266/2266 [==============================] - 1s 246us/step - loss: 0.1611 - acc: 0.9537 - val_loss: 3.4480 - val_acc: 0.5354\n",
      "Epoch 49/50\n",
      "2266/2266 [==============================] - 1s 236us/step - loss: 0.1688 - acc: 0.9559 - val_loss: 3.5305 - val_acc: 0.5634\n",
      "Epoch 50/50\n",
      "2266/2266 [==============================] - 1s 231us/step - loss: 0.1624 - acc: 0.9554 - val_loss: 3.5380 - val_acc: 0.5394\n",
      "749/749 [==============================] - 0s 66us/step\n"
     ]
    }
   ],
   "source": [
    "#k=4\n",
    "kf = StratifiedKFold(n_splits=4, random_state=None, shuffle=False)\n",
    "val_loss_cv = []\n",
    "val_acc_cv = []\n",
    "j = 0\n",
    "for train_index, test_index in kf.split(X,y):\n",
    "    j+=1\n",
    "    print(f\"Fold {j} :\")\n",
    "    print(\"\")\n",
    "    X_train,X_test = X[train_index],X[test_index]\n",
    "    y_train,y_test = y[train_index],y[test_index]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim=X_train.shape[1], units=128,\n",
    "                     kernel_initializer='normal', bias_initializer='zeros'))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    for i in range(0, 6):\n",
    "        model.add(Dense(units=128, kernel_initializer='normal',\n",
    "                         bias_initializer='zeros'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(.15))\n",
    "\n",
    "    model.add(Dense(units=19))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train,batch_size=24,epochs=50,verbose=1,validation_data=(X_test, y_test))\n",
    "    score = model.evaluate(X_test, y_test, verbose=1)\n",
    "    val_loss_cv.append(score[0])\n",
    "    val_acc_cv.append(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss_cv : [4.2626364249882736, 3.02383305476262, 3.657882578531901, 3.5380325737559746]\n",
      "mean_val_loss_cv : 3.6205961580096924\n",
      "val_acc_cv : [0.48162729705725443, 0.5795755971331812, 0.5746666666666667, 0.5393858479960102]\n",
      "mean_val_acc_cv : 0.5438138522132782\n"
     ]
    }
   ],
   "source": [
    "print(f\"val_loss_cv : {val_loss_cv}\")\n",
    "print(f\"mean_val_loss_cv : {np.mean(val_loss_cv)}\")\n",
    "print(f\"val_acc_cv : {val_acc_cv}\")\n",
    "print(f\"mean_val_acc_cv : {np.mean(val_acc_cv)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
