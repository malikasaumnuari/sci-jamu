{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['J00021', 0, 0, ..., 0, 0, 0],\n",
       "       ['J00050', 0, 0, ..., 0, 0, 0],\n",
       "       ['J00113', 1, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       ['J03006', 0, 0, ..., 0, 0, 0],\n",
       "       ['J03017', 0, 0, ..., 0, 0, 0],\n",
       "       ['J03023', 0, 0, ..., 0, 0, 0]], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#masukin data1\n",
    "data1=pandas.read_csv('D:\\\\SKRIPSI\\\\data\\\\data_praproses\\\\jamu_herbs.csv', sep=',')\n",
    "data1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['J00021', 17],\n",
       "       ['J00050', 17],\n",
       "       ['J00113', 17],\n",
       "       ...,\n",
       "       ['J03006', 16],\n",
       "       ['J03017', 16],\n",
       "       ['J03023', 16]], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#masukin data2\n",
    "data2=pandas.read_csv('D:\\\\SKRIPSI\\\\data\\\\data_praproses\\\\jamu_class.csv', sep=',')\n",
    "data2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = data1.drop('IDJamu',axis=1)\n",
    "data_2 = data2.drop('Jamu ID',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1['Kelas']=data_2['Class of Diseases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_temp  = data_1[data_1['Kelas'] != 5]\n",
    "X = data_temp.drop('Kelas', axis=1).values\n",
    "y = data_temp['Kelas'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 :\n",
      "\n",
      "Train on 2704 samples, validate on 311 samples\n",
      "Epoch 1/30\n",
      "2704/2704 [==============================] - 4s 1ms/step - loss: 2.2961 - acc: 0.2001 - val_loss: 2.1434 - val_acc: 0.2090\n",
      "Epoch 2/30\n",
      "2704/2704 [==============================] - 1s 261us/step - loss: 2.0303 - acc: 0.2559 - val_loss: 2.0837 - val_acc: 0.3248\n",
      "Epoch 3/30\n",
      "2704/2704 [==============================] - 1s 214us/step - loss: 1.7878 - acc: 0.3561 - val_loss: 1.7224 - val_acc: 0.3859\n",
      "Epoch 4/30\n",
      "2704/2704 [==============================] - 1s 215us/step - loss: 1.4765 - acc: 0.4959 - val_loss: 1.6784 - val_acc: 0.4630\n",
      "Epoch 5/30\n",
      "2704/2704 [==============================] - 1s 247us/step - loss: 1.2569 - acc: 0.6084 - val_loss: 1.7251 - val_acc: 0.5048\n",
      "Epoch 6/30\n",
      "2704/2704 [==============================] - 1s 225us/step - loss: 1.1029 - acc: 0.6690 - val_loss: 1.6704 - val_acc: 0.5241\n",
      "Epoch 7/30\n",
      "2704/2704 [==============================] - 1s 222us/step - loss: 0.9745 - acc: 0.7027 - val_loss: 1.7959 - val_acc: 0.5177\n",
      "Epoch 8/30\n",
      "2704/2704 [==============================] - 1s 222us/step - loss: 0.8799 - acc: 0.7304 - val_loss: 1.7885 - val_acc: 0.5145\n",
      "Epoch 9/30\n",
      "2704/2704 [==============================] - 1s 230us/step - loss: 0.8071 - acc: 0.7530 - val_loss: 2.0375 - val_acc: 0.5177\n",
      "Epoch 10/30\n",
      "2704/2704 [==============================] - 1s 231us/step - loss: 0.7607 - acc: 0.7604 - val_loss: 1.8584 - val_acc: 0.5338\n",
      "Epoch 11/30\n",
      "2704/2704 [==============================] - 1s 234us/step - loss: 0.6954 - acc: 0.7914 - val_loss: 2.1984 - val_acc: 0.5048\n",
      "Epoch 12/30\n",
      "2704/2704 [==============================] - 1s 249us/step - loss: 0.6583 - acc: 0.8047 - val_loss: 2.1321 - val_acc: 0.5241\n",
      "Epoch 13/30\n",
      "2704/2704 [==============================] - 1s 219us/step - loss: 0.6117 - acc: 0.8110 - val_loss: 2.5714 - val_acc: 0.5466\n",
      "Epoch 14/30\n",
      "2704/2704 [==============================] - 1s 268us/step - loss: 0.5674 - acc: 0.8306 - val_loss: 2.8428 - val_acc: 0.5241\n",
      "Epoch 15/30\n",
      "2704/2704 [==============================] - 1s 237us/step - loss: 0.5430 - acc: 0.8310 - val_loss: 2.8864 - val_acc: 0.5016\n",
      "Epoch 16/30\n",
      "2704/2704 [==============================] - 1s 216us/step - loss: 0.5070 - acc: 0.8465 - val_loss: 2.6066 - val_acc: 0.5209\n",
      "Epoch 17/30\n",
      "2704/2704 [==============================] - 1s 228us/step - loss: 0.4891 - acc: 0.8513 - val_loss: 2.6106 - val_acc: 0.5338\n",
      "Epoch 18/30\n",
      "2704/2704 [==============================] - 1s 247us/step - loss: 0.4632 - acc: 0.8587 - val_loss: 2.7316 - val_acc: 0.4887\n",
      "Epoch 19/30\n",
      "2704/2704 [==============================] - 1s 229us/step - loss: 0.4453 - acc: 0.8609 - val_loss: 2.7388 - val_acc: 0.5016\n",
      "Epoch 20/30\n",
      "2704/2704 [==============================] - 1s 231us/step - loss: 0.4329 - acc: 0.8702 - val_loss: 3.0245 - val_acc: 0.4695\n",
      "Epoch 21/30\n",
      "2704/2704 [==============================] - 1s 237us/step - loss: 0.3870 - acc: 0.8798 - val_loss: 3.0697 - val_acc: 0.4855\n",
      "Epoch 22/30\n",
      "2704/2704 [==============================] - 1s 246us/step - loss: 0.3634 - acc: 0.8861 - val_loss: 3.4283 - val_acc: 0.4759\n",
      "Epoch 23/30\n",
      "2704/2704 [==============================] - 1s 213us/step - loss: 0.3439 - acc: 0.8961 - val_loss: 3.2845 - val_acc: 0.4823\n",
      "Epoch 24/30\n",
      "2704/2704 [==============================] - 1s 234us/step - loss: 0.3416 - acc: 0.8916 - val_loss: 3.2197 - val_acc: 0.5113\n",
      "Epoch 25/30\n",
      "2704/2704 [==============================] - 1s 222us/step - loss: 0.3328 - acc: 0.8990 - val_loss: 2.8796 - val_acc: 0.4823\n",
      "Epoch 26/30\n",
      "2704/2704 [==============================] - 1s 224us/step - loss: 0.3133 - acc: 0.9050 - val_loss: 3.4049 - val_acc: 0.4759\n",
      "Epoch 27/30\n",
      "2704/2704 [==============================] - 1s 219us/step - loss: 0.2874 - acc: 0.9116 - val_loss: 3.3836 - val_acc: 0.5113\n",
      "Epoch 28/30\n",
      "2704/2704 [==============================] - 1s 232us/step - loss: 0.3055 - acc: 0.9116 - val_loss: 3.3412 - val_acc: 0.5177\n",
      "Epoch 29/30\n",
      "2704/2704 [==============================] - 1s 225us/step - loss: 0.3327 - acc: 0.9027 - val_loss: 3.6126 - val_acc: 0.4823\n",
      "Epoch 30/30\n",
      "2704/2704 [==============================] - 1s 219us/step - loss: 0.2865 - acc: 0.9186 - val_loss: 3.7036 - val_acc: 0.4759\n",
      "311/311 [==============================] - 0s 79us/step\n",
      "Fold 2 :\n",
      "\n",
      "Train on 2707 samples, validate on 308 samples\n",
      "Epoch 1/30\n",
      "2707/2707 [==============================] - 1s 523us/step - loss: 2.2961 - acc: 0.1995 - val_loss: 2.1284 - val_acc: 0.2110\n",
      "Epoch 2/30\n",
      "2707/2707 [==============================] - 1s 232us/step - loss: 2.0233 - acc: 0.2512 - val_loss: 1.9667 - val_acc: 0.3279\n",
      "Epoch 3/30\n",
      "2707/2707 [==============================] - 1s 230us/step - loss: 1.7757 - acc: 0.3624 - val_loss: 1.9194 - val_acc: 0.3669\n",
      "Epoch 4/30\n",
      "2707/2707 [==============================] - ETA: 0s - loss: 1.5497 - acc: 0.476 - 1s 218us/step - loss: 1.5366 - acc: 0.4791 - val_loss: 2.0585 - val_acc: 0.4058\n",
      "Epoch 5/30\n",
      "2707/2707 [==============================] - 1s 222us/step - loss: 1.3063 - acc: 0.5541 - val_loss: 1.8791 - val_acc: 0.4481\n",
      "Epoch 6/30\n",
      "2707/2707 [==============================] - 1s 224us/step - loss: 1.1508 - acc: 0.6354 - val_loss: 1.9942 - val_acc: 0.4545\n",
      "Epoch 7/30\n",
      "2707/2707 [==============================] - 1s 225us/step - loss: 1.0146 - acc: 0.6786 - val_loss: 1.9742 - val_acc: 0.4416\n",
      "Epoch 8/30\n",
      "2707/2707 [==============================] - 1s 221us/step - loss: 0.9243 - acc: 0.7100 - val_loss: 2.2478 - val_acc: 0.4448\n",
      "Epoch 9/30\n",
      "2707/2707 [==============================] - 1s 221us/step - loss: 0.8208 - acc: 0.7429 - val_loss: 2.4800 - val_acc: 0.4253\n",
      "Epoch 10/30\n",
      "2707/2707 [==============================] - 1s 222us/step - loss: 0.7509 - acc: 0.7654 - val_loss: 2.6470 - val_acc: 0.4351\n",
      "Epoch 11/30\n",
      "2707/2707 [==============================] - 1s 224us/step - loss: 0.6845 - acc: 0.7898 - val_loss: 2.5936 - val_acc: 0.4156\n",
      "Epoch 12/30\n",
      "2707/2707 [==============================] - 1s 224us/step - loss: 0.6538 - acc: 0.8001 - val_loss: 2.8179 - val_acc: 0.4481\n",
      "Epoch 13/30\n",
      "2707/2707 [==============================] - 1s 220us/step - loss: 0.5690 - acc: 0.8182 - val_loss: 2.7562 - val_acc: 0.4156\n",
      "Epoch 14/30\n",
      "2707/2707 [==============================] - 1s 223us/step - loss: 0.5856 - acc: 0.8216 - val_loss: 3.0181 - val_acc: 0.4156\n",
      "Epoch 15/30\n",
      "2707/2707 [==============================] - 1s 221us/step - loss: 0.4945 - acc: 0.8478 - val_loss: 2.8794 - val_acc: 0.4221\n",
      "Epoch 16/30\n",
      "2707/2707 [==============================] - 1s 225us/step - loss: 0.4566 - acc: 0.8537 - val_loss: 3.2580 - val_acc: 0.4188\n",
      "Epoch 17/30\n",
      "2707/2707 [==============================] - 1s 226us/step - loss: 0.4450 - acc: 0.8578 - val_loss: 2.9640 - val_acc: 0.4481\n",
      "Epoch 18/30\n",
      "2707/2707 [==============================] - 1s 223us/step - loss: 0.4061 - acc: 0.8748 - val_loss: 3.7215 - val_acc: 0.4026\n",
      "Epoch 19/30\n",
      "2707/2707 [==============================] - 1s 220us/step - loss: 0.4020 - acc: 0.8770 - val_loss: 3.4076 - val_acc: 0.4188\n",
      "Epoch 20/30\n",
      "2707/2707 [==============================] - 1s 223us/step - loss: 0.3816 - acc: 0.8862 - val_loss: 3.4391 - val_acc: 0.4286\n",
      "Epoch 21/30\n",
      "2707/2707 [==============================] - 1s 222us/step - loss: 0.3831 - acc: 0.8855 - val_loss: 3.7204 - val_acc: 0.4123\n",
      "Epoch 22/30\n",
      "2707/2707 [==============================] - 1s 222us/step - loss: 0.3830 - acc: 0.8855 - val_loss: 3.4974 - val_acc: 0.4513\n",
      "Epoch 23/30\n",
      "2707/2707 [==============================] - 1s 223us/step - loss: 0.3443 - acc: 0.8984 - val_loss: 3.8935 - val_acc: 0.4221\n",
      "Epoch 24/30\n",
      "2707/2707 [==============================] - 1s 220us/step - loss: 0.3280 - acc: 0.9051 - val_loss: 3.8122 - val_acc: 0.4188\n",
      "Epoch 25/30\n",
      "2707/2707 [==============================] - 1s 220us/step - loss: 0.3173 - acc: 0.9058 - val_loss: 4.2100 - val_acc: 0.4156\n",
      "Epoch 26/30\n",
      "2707/2707 [==============================] - 1s 236us/step - loss: 0.3007 - acc: 0.9110 - val_loss: 3.9327 - val_acc: 0.4091\n",
      "Epoch 27/30\n",
      "2707/2707 [==============================] - 1s 219us/step - loss: 0.2788 - acc: 0.9147 - val_loss: 3.9341 - val_acc: 0.4253\n",
      "Epoch 28/30\n",
      "2707/2707 [==============================] - 1s 222us/step - loss: 0.2739 - acc: 0.9221 - val_loss: 4.1409 - val_acc: 0.4318\n",
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2707/2707 [==============================] - 1s 245us/step - loss: 0.3107 - acc: 0.9106 - val_loss: 3.7416 - val_acc: 0.4188\n",
      "Epoch 30/30\n",
      "2707/2707 [==============================] - 1s 246us/step - loss: 0.2984 - acc: 0.9180 - val_loss: 3.9519 - val_acc: 0.4156\n",
      "308/308 [==============================] - 0s 83us/step\n",
      "Fold 3 :\n",
      "\n",
      "Train on 2712 samples, validate on 303 samples\n",
      "Epoch 1/30\n",
      "2712/2712 [==============================] - 2s 591us/step - loss: 2.3000 - acc: 0.1903 - val_loss: 2.0742 - val_acc: 0.2145\n",
      "Epoch 2/30\n",
      "2712/2712 [==============================] - 1s 246us/step - loss: 2.0403 - acc: 0.2268 - val_loss: 2.0398 - val_acc: 0.1914\n",
      "Epoch 3/30\n",
      "2712/2712 [==============================] - 1s 260us/step - loss: 1.8104 - acc: 0.3525 - val_loss: 1.6873 - val_acc: 0.4785\n",
      "Epoch 4/30\n",
      "2712/2712 [==============================] - 1s 229us/step - loss: 1.5130 - acc: 0.4860 - val_loss: 1.6458 - val_acc: 0.4587\n",
      "Epoch 5/30\n",
      "2712/2712 [==============================] - 1s 235us/step - loss: 1.2888 - acc: 0.5914 - val_loss: 1.5156 - val_acc: 0.5545\n",
      "Epoch 6/30\n",
      "2712/2712 [==============================] - 1s 257us/step - loss: 1.1240 - acc: 0.6523 - val_loss: 1.5347 - val_acc: 0.5611\n",
      "Epoch 7/30\n",
      "2712/2712 [==============================] - 1s 258us/step - loss: 0.9606 - acc: 0.7216 - val_loss: 1.6087 - val_acc: 0.5479\n",
      "Epoch 8/30\n",
      "2712/2712 [==============================] - 1s 236us/step - loss: 0.8654 - acc: 0.7474 - val_loss: 1.6066 - val_acc: 0.5611\n",
      "Epoch 9/30\n",
      "2712/2712 [==============================] - 1s 232us/step - loss: 0.7474 - acc: 0.7784 - val_loss: 1.7482 - val_acc: 0.5809\n",
      "Epoch 10/30\n",
      "2712/2712 [==============================] - 1s 232us/step - loss: 0.7073 - acc: 0.7965 - val_loss: 1.8734 - val_acc: 0.5545\n",
      "Epoch 11/30\n",
      "2712/2712 [==============================] - 1s 228us/step - loss: 0.6577 - acc: 0.8027 - val_loss: 1.8509 - val_acc: 0.5611\n",
      "Epoch 12/30\n",
      "2712/2712 [==============================] - 1s 230us/step - loss: 0.5846 - acc: 0.8237 - val_loss: 1.9588 - val_acc: 0.5578\n",
      "Epoch 13/30\n",
      "2712/2712 [==============================] - 1s 230us/step - loss: 0.5691 - acc: 0.8260 - val_loss: 1.8536 - val_acc: 0.5809\n",
      "Epoch 14/30\n",
      "2712/2712 [==============================] - 1s 293us/step - loss: 0.5153 - acc: 0.8488 - val_loss: 2.0244 - val_acc: 0.5578\n",
      "Epoch 15/30\n",
      "2712/2712 [==============================] - 1s 245us/step - loss: 0.5131 - acc: 0.8451 - val_loss: 1.9769 - val_acc: 0.5446\n",
      "Epoch 16/30\n",
      "2712/2712 [==============================] - 1s 233us/step - loss: 0.4547 - acc: 0.8647 - val_loss: 2.1429 - val_acc: 0.5644\n",
      "Epoch 17/30\n",
      "2712/2712 [==============================] - 1s 228us/step - loss: 0.4708 - acc: 0.8588 - val_loss: 2.0966 - val_acc: 0.5743\n",
      "Epoch 18/30\n",
      "2712/2712 [==============================] - 1s 237us/step - loss: 0.4490 - acc: 0.8695 - val_loss: 2.3032 - val_acc: 0.5677\n",
      "Epoch 19/30\n",
      "2712/2712 [==============================] - 1s 258us/step - loss: 0.3898 - acc: 0.8765 - val_loss: 2.4676 - val_acc: 0.5743\n",
      "Epoch 20/30\n",
      "2712/2712 [==============================] - 1s 275us/step - loss: 0.3837 - acc: 0.8842 - val_loss: 2.7638 - val_acc: 0.5611\n",
      "Epoch 21/30\n",
      "2712/2712 [==============================] - 1s 221us/step - loss: 0.3362 - acc: 0.8993 - val_loss: 3.0716 - val_acc: 0.5677\n",
      "Epoch 22/30\n",
      "2712/2712 [==============================] - 1s 274us/step - loss: 0.3394 - acc: 0.8979 - val_loss: 2.8453 - val_acc: 0.5677\n",
      "Epoch 23/30\n",
      "2712/2712 [==============================] - 1s 231us/step - loss: 0.3574 - acc: 0.8968 - val_loss: 2.6595 - val_acc: 0.5710\n",
      "Epoch 24/30\n",
      "2712/2712 [==============================] - 1s 216us/step - loss: 0.2969 - acc: 0.9130 - val_loss: 2.9970 - val_acc: 0.5479\n",
      "Epoch 25/30\n",
      "2712/2712 [==============================] - 1s 210us/step - loss: 0.3073 - acc: 0.9115 - val_loss: 3.0196 - val_acc: 0.5545\n",
      "Epoch 26/30\n",
      "2712/2712 [==============================] - 1s 196us/step - loss: 0.2951 - acc: 0.9159 - val_loss: 3.3016 - val_acc: 0.5611\n",
      "Epoch 27/30\n",
      "2712/2712 [==============================] - 1s 210us/step - loss: 0.2664 - acc: 0.9222 - val_loss: 3.2675 - val_acc: 0.6040\n",
      "Epoch 28/30\n",
      "2712/2712 [==============================] - 1s 202us/step - loss: 0.2952 - acc: 0.9178 - val_loss: 2.8689 - val_acc: 0.5743\n",
      "Epoch 29/30\n",
      "2712/2712 [==============================] - 1s 196us/step - loss: 0.2674 - acc: 0.9248 - val_loss: 3.0765 - val_acc: 0.5677\n",
      "Epoch 30/30\n",
      "2712/2712 [==============================] - 1s 204us/step - loss: 0.2526 - acc: 0.9248 - val_loss: 3.1222 - val_acc: 0.5347\n",
      "303/303 [==============================] - 0s 52us/step\n",
      "Fold 4 :\n",
      "\n",
      "Train on 2714 samples, validate on 301 samples\n",
      "Epoch 1/30\n",
      "2714/2714 [==============================] - 2s 583us/step - loss: 2.2826 - acc: 0.2078 - val_loss: 2.0450 - val_acc: 0.2093\n",
      "Epoch 2/30\n",
      "2714/2714 [==============================] - 1s 248us/step - loss: 2.0264 - acc: 0.2332 - val_loss: 1.9991 - val_acc: 0.2326\n",
      "Epoch 3/30\n",
      "2714/2714 [==============================] - 1s 274us/step - loss: 1.7837 - acc: 0.3729 - val_loss: 1.8366 - val_acc: 0.4086\n",
      "Epoch 4/30\n",
      "2714/2714 [==============================] - 1s 215us/step - loss: 1.5349 - acc: 0.4801 - val_loss: 1.7275 - val_acc: 0.4385\n",
      "Epoch 5/30\n",
      "2714/2714 [==============================] - 1s 216us/step - loss: 1.3381 - acc: 0.5534 - val_loss: 1.7170 - val_acc: 0.4651\n",
      "Epoch 6/30\n",
      "2714/2714 [==============================] - 1s 253us/step - loss: 1.1856 - acc: 0.6102 - val_loss: 1.6955 - val_acc: 0.5116\n",
      "Epoch 7/30\n",
      "2714/2714 [==============================] - 1s 285us/step - loss: 1.0536 - acc: 0.6603 - val_loss: 1.6922 - val_acc: 0.5150\n",
      "Epoch 8/30\n",
      "2714/2714 [==============================] - 1s 250us/step - loss: 0.9487 - acc: 0.6912 - val_loss: 1.7276 - val_acc: 0.5216\n",
      "Epoch 9/30\n",
      "2714/2714 [==============================] - 1s 259us/step - loss: 0.8680 - acc: 0.7203 - val_loss: 1.6478 - val_acc: 0.5349\n",
      "Epoch 10/30\n",
      "2714/2714 [==============================] - 1s 249us/step - loss: 0.8089 - acc: 0.7428 - val_loss: 1.8544 - val_acc: 0.5116\n",
      "Epoch 11/30\n",
      "2714/2714 [==============================] - 1s 210us/step - loss: 0.7618 - acc: 0.7671 - val_loss: 1.8188 - val_acc: 0.5216\n",
      "Epoch 12/30\n",
      "2714/2714 [==============================] - 1s 208us/step - loss: 0.7164 - acc: 0.7811 - val_loss: 1.8687 - val_acc: 0.5382\n",
      "Epoch 13/30\n",
      "2714/2714 [==============================] - 1s 209us/step - loss: 0.6354 - acc: 0.8128 - val_loss: 1.9412 - val_acc: 0.5282\n",
      "Epoch 14/30\n",
      "2714/2714 [==============================] - 1s 210us/step - loss: 0.6091 - acc: 0.8102 - val_loss: 2.1029 - val_acc: 0.5349\n",
      "Epoch 15/30\n",
      "2714/2714 [==============================] - 1s 246us/step - loss: 0.5961 - acc: 0.8099 - val_loss: 2.0431 - val_acc: 0.5282\n",
      "Epoch 16/30\n",
      "2714/2714 [==============================] - 1s 217us/step - loss: 0.5767 - acc: 0.8239 - val_loss: 2.1916 - val_acc: 0.5382\n",
      "Epoch 17/30\n",
      "2714/2714 [==============================] - 1s 224us/step - loss: 0.5330 - acc: 0.8349 - val_loss: 2.0632 - val_acc: 0.5581\n",
      "Epoch 18/30\n",
      "2714/2714 [==============================] - 1s 239us/step - loss: 0.5071 - acc: 0.8445 - val_loss: 2.0643 - val_acc: 0.5482\n",
      "Epoch 19/30\n",
      "2714/2714 [==============================] - 1s 215us/step - loss: 0.4794 - acc: 0.8452 - val_loss: 2.3145 - val_acc: 0.5515\n",
      "Epoch 20/30\n",
      "2714/2714 [==============================] - 1s 232us/step - loss: 0.4827 - acc: 0.8541 - val_loss: 2.3342 - val_acc: 0.5648\n",
      "Epoch 21/30\n",
      "2714/2714 [==============================] - 1s 211us/step - loss: 0.4467 - acc: 0.8696 - val_loss: 2.2660 - val_acc: 0.5714\n",
      "Epoch 22/30\n",
      "2714/2714 [==============================] - 1s 281us/step - loss: 0.4305 - acc: 0.8677 - val_loss: 2.4199 - val_acc: 0.5615\n",
      "Epoch 23/30\n",
      "2714/2714 [==============================] - 1s 245us/step - loss: 0.4039 - acc: 0.8762 - val_loss: 2.2636 - val_acc: 0.5847\n",
      "Epoch 24/30\n",
      "2714/2714 [==============================] - 1s 314us/step - loss: 0.3967 - acc: 0.8784 - val_loss: 2.6624 - val_acc: 0.5681\n",
      "Epoch 25/30\n",
      "2714/2714 [==============================] - 1s 231us/step - loss: 0.4001 - acc: 0.8817 - val_loss: 2.2399 - val_acc: 0.5615\n",
      "Epoch 26/30\n",
      "2714/2714 [==============================] - 1s 259us/step - loss: 0.3667 - acc: 0.8954 - val_loss: 2.4232 - val_acc: 0.5847\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2714/2714 [==============================] - 1s 223us/step - loss: 0.3498 - acc: 0.8957 - val_loss: 2.6158 - val_acc: 0.5781\n",
      "Epoch 28/30\n",
      "2714/2714 [==============================] - 1s 234us/step - loss: 0.3308 - acc: 0.8998 - val_loss: 2.4455 - val_acc: 0.6013\n",
      "Epoch 29/30\n",
      "2714/2714 [==============================] - 1s 251us/step - loss: 0.3284 - acc: 0.9046 - val_loss: 2.5365 - val_acc: 0.5415\n",
      "Epoch 30/30\n",
      "2714/2714 [==============================] - 1s 250us/step - loss: 0.3241 - acc: 0.9064 - val_loss: 2.6998 - val_acc: 0.5548\n",
      "301/301 [==============================] - 0s 114us/step\n",
      "Fold 5 :\n",
      "\n",
      "Train on 2714 samples, validate on 301 samples\n",
      "Epoch 1/30\n",
      "2714/2714 [==============================] - 2s 675us/step - loss: 2.2944 - acc: 0.2012 - val_loss: 2.0610 - val_acc: 0.2159\n",
      "Epoch 2/30\n",
      "2714/2714 [==============================] - 1s 269us/step - loss: 2.0335 - acc: 0.2034 - val_loss: 2.0660 - val_acc: 0.3588\n",
      "Epoch 3/30\n",
      "2714/2714 [==============================] - 1s 343us/step - loss: 1.8117 - acc: 0.3747 - val_loss: 1.6233 - val_acc: 0.4651\n",
      "Epoch 4/30\n",
      "2714/2714 [==============================] - 1s 307us/step - loss: 1.4659 - acc: 0.5317 - val_loss: 1.4374 - val_acc: 0.5880\n",
      "Epoch 5/30\n",
      "2714/2714 [==============================] - 1s 245us/step - loss: 1.2400 - acc: 0.6256 - val_loss: 1.4718 - val_acc: 0.5814\n",
      "Epoch 6/30\n",
      "2714/2714 [==============================] - 1s 302us/step - loss: 1.0940 - acc: 0.6735 - val_loss: 1.5042 - val_acc: 0.6047\n",
      "Epoch 7/30\n",
      "2714/2714 [==============================] - 1s 234us/step - loss: 0.9546 - acc: 0.7093 - val_loss: 1.5507 - val_acc: 0.6047\n",
      "Epoch 8/30\n",
      "2714/2714 [==============================] - 1s 336us/step - loss: 0.8681 - acc: 0.7384 - val_loss: 1.5430 - val_acc: 0.6179\n",
      "Epoch 9/30\n",
      "2714/2714 [==============================] - 1s 271us/step - loss: 0.7802 - acc: 0.7719 - val_loss: 1.4872 - val_acc: 0.6013\n",
      "Epoch 10/30\n",
      "2714/2714 [==============================] - 1s 331us/step - loss: 0.7057 - acc: 0.7874 - val_loss: 1.6282 - val_acc: 0.6279\n",
      "Epoch 11/30\n",
      "2714/2714 [==============================] - 1s 310us/step - loss: 0.6553 - acc: 0.7988 - val_loss: 1.7885 - val_acc: 0.6545\n",
      "Epoch 12/30\n",
      "2714/2714 [==============================] - 1s 308us/step - loss: 0.6169 - acc: 0.8091 - val_loss: 1.8474 - val_acc: 0.6312\n",
      "Epoch 13/30\n",
      "2714/2714 [==============================] - 1s 264us/step - loss: 0.5483 - acc: 0.8375 - val_loss: 1.9234 - val_acc: 0.6146\n",
      "Epoch 14/30\n",
      "2714/2714 [==============================] - 1s 249us/step - loss: 0.5202 - acc: 0.8475 - val_loss: 1.9746 - val_acc: 0.6312\n",
      "Epoch 15/30\n",
      "2714/2714 [==============================] - 1s 245us/step - loss: 0.5009 - acc: 0.8526 - val_loss: 2.1221 - val_acc: 0.6179\n",
      "Epoch 16/30\n",
      "2714/2714 [==============================] - 1s 247us/step - loss: 0.4651 - acc: 0.8574 - val_loss: 1.8857 - val_acc: 0.6179\n",
      "Epoch 17/30\n",
      "2714/2714 [==============================] - 1s 224us/step - loss: 0.4374 - acc: 0.8655 - val_loss: 2.1035 - val_acc: 0.6279\n",
      "Epoch 18/30\n",
      "2714/2714 [==============================] - 1s 313us/step - loss: 0.4288 - acc: 0.8696 - val_loss: 2.1878 - val_acc: 0.5980\n",
      "Epoch 19/30\n",
      "2714/2714 [==============================] - 1s 245us/step - loss: 0.3690 - acc: 0.8928 - val_loss: 2.2589 - val_acc: 0.6080\n",
      "Epoch 20/30\n",
      "2714/2714 [==============================] - 1s 226us/step - loss: 0.3671 - acc: 0.8895 - val_loss: 2.2304 - val_acc: 0.6013\n",
      "Epoch 21/30\n",
      "2714/2714 [==============================] - 1s 223us/step - loss: 0.3572 - acc: 0.8972 - val_loss: 2.5941 - val_acc: 0.6246\n",
      "Epoch 22/30\n",
      "2714/2714 [==============================] - 1s 245us/step - loss: 0.3523 - acc: 0.9005 - val_loss: 2.4735 - val_acc: 0.6478\n",
      "Epoch 23/30\n",
      "2714/2714 [==============================] - 1s 267us/step - loss: 0.3511 - acc: 0.8987 - val_loss: 2.3878 - val_acc: 0.6279\n",
      "Epoch 24/30\n",
      "2714/2714 [==============================] - 1s 229us/step - loss: 0.3757 - acc: 0.8961 - val_loss: 2.1726 - val_acc: 0.6445\n",
      "Epoch 25/30\n",
      "2714/2714 [==============================] - 1s 222us/step - loss: 0.2938 - acc: 0.9127 - val_loss: 2.6246 - val_acc: 0.6279\n",
      "Epoch 26/30\n",
      "2714/2714 [==============================] - 1s 226us/step - loss: 0.2971 - acc: 0.9153 - val_loss: 2.4100 - val_acc: 0.6312\n",
      "Epoch 27/30\n",
      "2714/2714 [==============================] - 1s 222us/step - loss: 0.2973 - acc: 0.9141 - val_loss: 2.3513 - val_acc: 0.6346\n",
      "Epoch 28/30\n",
      "2714/2714 [==============================] - 1s 222us/step - loss: 0.2837 - acc: 0.9112 - val_loss: 2.5285 - val_acc: 0.6412\n",
      "Epoch 29/30\n",
      "2714/2714 [==============================] - 1s 247us/step - loss: 0.2770 - acc: 0.9145 - val_loss: 2.3837 - val_acc: 0.6213\n",
      "Epoch 30/30\n",
      "2714/2714 [==============================] - 1s 271us/step - loss: 0.2797 - acc: 0.9189 - val_loss: 2.5283 - val_acc: 0.6246\n",
      "301/301 [==============================] - 0s 65us/step\n",
      "Fold 6 :\n",
      "\n",
      "Train on 2714 samples, validate on 301 samples\n",
      "Epoch 1/30\n",
      "2714/2714 [==============================] - 2s 604us/step - loss: 2.2543 - acc: 0.2078 - val_loss: 2.0465 - val_acc: 0.2458\n",
      "Epoch 2/30\n",
      "2714/2714 [==============================] - 1s 242us/step - loss: 2.0167 - acc: 0.2410 - val_loss: 2.0000 - val_acc: 0.2292\n",
      "Epoch 3/30\n",
      "2714/2714 [==============================] - 1s 241us/step - loss: 1.8342 - acc: 0.3607 - val_loss: 1.8745 - val_acc: 0.3488\n",
      "Epoch 4/30\n",
      "2714/2714 [==============================] - 1s 239us/step - loss: 1.5223 - acc: 0.4889 - val_loss: 1.7167 - val_acc: 0.4219\n",
      "Epoch 5/30\n",
      "2714/2714 [==============================] - 1s 249us/step - loss: 1.2506 - acc: 0.6146 - val_loss: 1.7169 - val_acc: 0.4718\n",
      "Epoch 6/30\n",
      "2714/2714 [==============================] - 1s 282us/step - loss: 1.0695 - acc: 0.6776 - val_loss: 1.6860 - val_acc: 0.5282\n",
      "Epoch 7/30\n",
      "2714/2714 [==============================] - 1s 304us/step - loss: 0.9310 - acc: 0.7178 - val_loss: 1.7970 - val_acc: 0.5581\n",
      "Epoch 8/30\n",
      "2714/2714 [==============================] - 1s 243us/step - loss: 0.8336 - acc: 0.7513 - val_loss: 1.7158 - val_acc: 0.5216\n",
      "Epoch 9/30\n",
      "2714/2714 [==============================] - 1s 229us/step - loss: 0.7600 - acc: 0.7716 - val_loss: 1.8166 - val_acc: 0.5382\n",
      "Epoch 10/30\n",
      "2714/2714 [==============================] - 1s 233us/step - loss: 0.6380 - acc: 0.8088 - val_loss: 1.9748 - val_acc: 0.5349\n",
      "Epoch 11/30\n",
      "2714/2714 [==============================] - 1s 242us/step - loss: 0.6161 - acc: 0.8102 - val_loss: 2.0048 - val_acc: 0.5316\n",
      "Epoch 12/30\n",
      "2714/2714 [==============================] - 1s 236us/step - loss: 0.5765 - acc: 0.8327 - val_loss: 2.2866 - val_acc: 0.5083\n",
      "Epoch 13/30\n",
      "2714/2714 [==============================] - 1s 229us/step - loss: 0.5127 - acc: 0.8522 - val_loss: 2.2437 - val_acc: 0.5449\n",
      "Epoch 14/30\n",
      "2714/2714 [==============================] - 1s 230us/step - loss: 0.5161 - acc: 0.8456 - val_loss: 2.0083 - val_acc: 0.5681\n",
      "Epoch 15/30\n",
      "2714/2714 [==============================] - 1s 231us/step - loss: 0.4470 - acc: 0.8696 - val_loss: 2.4071 - val_acc: 0.5615\n",
      "Epoch 16/30\n",
      "2714/2714 [==============================] - 1s 247us/step - loss: 0.4854 - acc: 0.8530 - val_loss: 2.4250 - val_acc: 0.5449\n",
      "Epoch 17/30\n",
      "2714/2714 [==============================] - ETA: 0s - loss: 0.4228 - acc: 0.871 - 1s 252us/step - loss: 0.4203 - acc: 0.8714 - val_loss: 2.4923 - val_acc: 0.5548\n",
      "Epoch 18/30\n",
      "2714/2714 [==============================] - 1s 243us/step - loss: 0.3909 - acc: 0.8784 - val_loss: 2.3101 - val_acc: 0.5714\n",
      "Epoch 19/30\n",
      "2714/2714 [==============================] - 1s 313us/step - loss: 0.3647 - acc: 0.8917 - val_loss: 2.6202 - val_acc: 0.5581\n",
      "Epoch 20/30\n",
      "2714/2714 [==============================] - 1s 272us/step - loss: 0.3382 - acc: 0.9009 - val_loss: 2.6044 - val_acc: 0.5714\n",
      "Epoch 21/30\n",
      "2714/2714 [==============================] - 1s 246us/step - loss: 0.3098 - acc: 0.9086 - val_loss: 3.1555 - val_acc: 0.5316\n",
      "Epoch 22/30\n",
      "2714/2714 [==============================] - 1s 250us/step - loss: 0.3007 - acc: 0.9138 - val_loss: 2.7701 - val_acc: 0.5681\n",
      "Epoch 23/30\n",
      "2714/2714 [==============================] - 1s 257us/step - loss: 0.3130 - acc: 0.9119 - val_loss: 2.8795 - val_acc: 0.5648\n",
      "Epoch 24/30\n",
      "2714/2714 [==============================] - 1s 291us/step - loss: 0.2832 - acc: 0.9178 - val_loss: 2.7859 - val_acc: 0.5449\n",
      "Epoch 25/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2714/2714 [==============================] - 1s 254us/step - loss: 0.2700 - acc: 0.9219 - val_loss: 2.7763 - val_acc: 0.5415\n",
      "Epoch 26/30\n",
      "2714/2714 [==============================] - 1s 233us/step - loss: 0.2851 - acc: 0.9204 - val_loss: 2.8916 - val_acc: 0.5216\n",
      "Epoch 27/30\n",
      "2714/2714 [==============================] - 1s 274us/step - loss: 0.2858 - acc: 0.9189 - val_loss: 2.7367 - val_acc: 0.5847\n",
      "Epoch 28/30\n",
      "2714/2714 [==============================] - 1s 260us/step - loss: 0.2647 - acc: 0.9267 - val_loss: 2.9285 - val_acc: 0.5548\n",
      "Epoch 29/30\n",
      "2714/2714 [==============================] - 1s 257us/step - loss: 0.2560 - acc: 0.9274 - val_loss: 2.8521 - val_acc: 0.5415\n",
      "Epoch 30/30\n",
      "2714/2714 [==============================] - 1s 248us/step - loss: 0.2798 - acc: 0.9175 - val_loss: 2.8132 - val_acc: 0.5581\n",
      "301/301 [==============================] - 0s 81us/step\n",
      "Fold 7 :\n",
      "\n",
      "Train on 2715 samples, validate on 300 samples\n",
      "Epoch 1/30\n",
      "2715/2715 [==============================] - 2s 762us/step - loss: 2.2902 - acc: 0.2103 - val_loss: 2.1161 - val_acc: 0.2200\n",
      "Epoch 2/30\n",
      "2715/2715 [==============================] - 1s 243us/step - loss: 2.0464 - acc: 0.2306 - val_loss: 2.0101 - val_acc: 0.2833\n",
      "Epoch 3/30\n",
      "2715/2715 [==============================] - 1s 278us/step - loss: 1.8463 - acc: 0.3378 - val_loss: 1.8688 - val_acc: 0.4167\n",
      "Epoch 4/30\n",
      "2715/2715 [==============================] - ETA: 0s - loss: 1.5592 - acc: 0.471 - 1s 258us/step - loss: 1.5544 - acc: 0.4729 - val_loss: 1.7361 - val_acc: 0.5133\n",
      "Epoch 5/30\n",
      "2715/2715 [==============================] - 1s 238us/step - loss: 1.3171 - acc: 0.5750 - val_loss: 1.6691 - val_acc: 0.5600\n",
      "Epoch 6/30\n",
      "2715/2715 [==============================] - 1s 235us/step - loss: 1.0859 - acc: 0.6700 - val_loss: 1.6123 - val_acc: 0.5733\n",
      "Epoch 7/30\n",
      "2715/2715 [==============================] - 1s 231us/step - loss: 0.9360 - acc: 0.7101 - val_loss: 1.7694 - val_acc: 0.5967\n",
      "Epoch 8/30\n",
      "2715/2715 [==============================] - 1s 240us/step - loss: 0.8336 - acc: 0.7591 - val_loss: 1.7513 - val_acc: 0.5933\n",
      "Epoch 9/30\n",
      "2715/2715 [==============================] - 1s 229us/step - loss: 0.7329 - acc: 0.7820 - val_loss: 1.8307 - val_acc: 0.6033\n",
      "Epoch 10/30\n",
      "2715/2715 [==============================] - 1s 237us/step - loss: 0.6830 - acc: 0.7971 - val_loss: 1.8733 - val_acc: 0.6100\n",
      "Epoch 11/30\n",
      "2715/2715 [==============================] - 1s 242us/step - loss: 0.5957 - acc: 0.8169 - val_loss: 2.1672 - val_acc: 0.5767\n",
      "Epoch 12/30\n",
      "2715/2715 [==============================] - 1s 232us/step - loss: 0.5512 - acc: 0.8339 - val_loss: 2.1377 - val_acc: 0.5800\n",
      "Epoch 13/30\n",
      "2715/2715 [==============================] - 1s 244us/step - loss: 0.5107 - acc: 0.8460 - val_loss: 2.2826 - val_acc: 0.5800\n",
      "Epoch 14/30\n",
      "2715/2715 [==============================] - 1s 236us/step - loss: 0.4722 - acc: 0.8619 - val_loss: 2.1933 - val_acc: 0.5967\n",
      "Epoch 15/30\n",
      "2715/2715 [==============================] - 1s 236us/step - loss: 0.4423 - acc: 0.8722 - val_loss: 2.3254 - val_acc: 0.6033\n",
      "Epoch 16/30\n",
      "2715/2715 [==============================] - 1s 234us/step - loss: 0.4106 - acc: 0.8836 - val_loss: 2.3331 - val_acc: 0.6000\n",
      "Epoch 17/30\n",
      "2715/2715 [==============================] - 1s 233us/step - loss: 0.4021 - acc: 0.8866 - val_loss: 2.6523 - val_acc: 0.5533\n",
      "Epoch 18/30\n",
      "2715/2715 [==============================] - 1s 240us/step - loss: 0.3752 - acc: 0.8906 - val_loss: 2.6717 - val_acc: 0.5633\n",
      "Epoch 19/30\n",
      "2715/2715 [==============================] - 1s 239us/step - loss: 0.3702 - acc: 0.8969 - val_loss: 2.5857 - val_acc: 0.5833\n",
      "Epoch 20/30\n",
      "2715/2715 [==============================] - 1s 240us/step - loss: 0.3576 - acc: 0.8943 - val_loss: 2.7290 - val_acc: 0.5567\n",
      "Epoch 21/30\n",
      "2715/2715 [==============================] - 1s 231us/step - loss: 0.3003 - acc: 0.9153 - val_loss: 3.0108 - val_acc: 0.5700\n",
      "Epoch 22/30\n",
      "2715/2715 [==============================] - 1s 239us/step - loss: 0.3140 - acc: 0.9101 - val_loss: 2.6860 - val_acc: 0.6100\n",
      "Epoch 23/30\n",
      "2715/2715 [==============================] - 1s 234us/step - loss: 0.2805 - acc: 0.9186 - val_loss: 2.7701 - val_acc: 0.5867\n",
      "Epoch 24/30\n",
      "2715/2715 [==============================] - 1s 236us/step - loss: 0.2552 - acc: 0.9278 - val_loss: 2.8426 - val_acc: 0.5733\n",
      "Epoch 25/30\n",
      "2715/2715 [==============================] - 1s 238us/step - loss: 0.2834 - acc: 0.9204 - val_loss: 3.0251 - val_acc: 0.5733\n",
      "Epoch 26/30\n",
      "2715/2715 [==============================] - 1s 233us/step - loss: 0.2833 - acc: 0.9201 - val_loss: 3.1805 - val_acc: 0.5867\n",
      "Epoch 27/30\n",
      "2715/2715 [==============================] - 1s 241us/step - loss: 0.2522 - acc: 0.9319 - val_loss: 2.5270 - val_acc: 0.5867\n",
      "Epoch 28/30\n",
      "2715/2715 [==============================] - 1s 238us/step - loss: 0.2279 - acc: 0.9374 - val_loss: 2.9798 - val_acc: 0.6000\n",
      "Epoch 29/30\n",
      "2715/2715 [==============================] - 1s 240us/step - loss: 0.2467 - acc: 0.9293 - val_loss: 3.0393 - val_acc: 0.5800\n",
      "Epoch 30/30\n",
      "2715/2715 [==============================] - 1s 240us/step - loss: 0.2568 - acc: 0.9274 - val_loss: 3.0270 - val_acc: 0.5967\n",
      "300/300 [==============================] - 0s 80us/step\n",
      "Fold 8 :\n",
      "\n",
      "Train on 2718 samples, validate on 297 samples\n",
      "Epoch 1/30\n",
      "2718/2718 [==============================] - 2s 707us/step - loss: 2.2835 - acc: 0.2009 - val_loss: 2.0625 - val_acc: 0.2458\n",
      "Epoch 2/30\n",
      "2718/2718 [==============================] - 1s 265us/step - loss: 2.0272 - acc: 0.2215 - val_loss: 2.0047 - val_acc: 0.2290\n",
      "Epoch 3/30\n",
      "2718/2718 [==============================] - 1s 265us/step - loss: 1.8481 - acc: 0.3326 - val_loss: 1.7794 - val_acc: 0.4747\n",
      "Epoch 4/30\n",
      "2718/2718 [==============================] - 1s 263us/step - loss: 1.5448 - acc: 0.4776 - val_loss: 1.6368 - val_acc: 0.4848\n",
      "Epoch 5/30\n",
      "2718/2718 [==============================] - 1s 256us/step - loss: 1.3001 - acc: 0.5894 - val_loss: 1.6457 - val_acc: 0.5185\n",
      "Epoch 6/30\n",
      "2718/2718 [==============================] - 1s 264us/step - loss: 1.0981 - acc: 0.6527 - val_loss: 1.7104 - val_acc: 0.5724\n",
      "Epoch 7/30\n",
      "2718/2718 [==============================] - 1s 258us/step - loss: 0.9960 - acc: 0.6921 - val_loss: 1.6363 - val_acc: 0.5522\n",
      "Epoch 8/30\n",
      "2718/2718 [==============================] - 1s 264us/step - loss: 0.8972 - acc: 0.7222 - val_loss: 1.6317 - val_acc: 0.5791\n",
      "Epoch 9/30\n",
      "2718/2718 [==============================] - 1s 262us/step - loss: 0.7691 - acc: 0.7579 - val_loss: 1.7644 - val_acc: 0.5690\n",
      "Epoch 10/30\n",
      "2718/2718 [==============================] - 1s 258us/step - loss: 0.7092 - acc: 0.7888 - val_loss: 1.9197 - val_acc: 0.5421\n",
      "Epoch 11/30\n",
      "2718/2718 [==============================] - 1s 261us/step - loss: 0.6520 - acc: 0.8021 - val_loss: 1.7423 - val_acc: 0.5926\n",
      "Epoch 12/30\n",
      "2718/2718 [==============================] - 1s 256us/step - loss: 0.6191 - acc: 0.8138 - val_loss: 1.9129 - val_acc: 0.5892\n",
      "Epoch 13/30\n",
      "2718/2718 [==============================] - 1s 256us/step - loss: 0.5439 - acc: 0.8370 - val_loss: 2.0070 - val_acc: 0.5892\n",
      "Epoch 14/30\n",
      "2718/2718 [==============================] - 1s 255us/step - loss: 0.4993 - acc: 0.8455 - val_loss: 2.0491 - val_acc: 0.5960\n",
      "Epoch 15/30\n",
      "2718/2718 [==============================] - 1s 249us/step - loss: 0.5028 - acc: 0.8510 - val_loss: 1.9717 - val_acc: 0.5825\n",
      "Epoch 16/30\n",
      "2718/2718 [==============================] - 1s 251us/step - loss: 0.4408 - acc: 0.8687 - val_loss: 2.2290 - val_acc: 0.5791\n",
      "Epoch 17/30\n",
      "2718/2718 [==============================] - 1s 265us/step - loss: 0.4184 - acc: 0.8742 - val_loss: 2.3001 - val_acc: 0.6061\n",
      "Epoch 18/30\n",
      "2718/2718 [==============================] - 1s 278us/step - loss: 0.4331 - acc: 0.8734 - val_loss: 2.3855 - val_acc: 0.5926\n",
      "Epoch 19/30\n",
      "2718/2718 [==============================] - 1s 263us/step - loss: 0.4035 - acc: 0.8764 - val_loss: 2.3464 - val_acc: 0.6094\n",
      "Epoch 20/30\n",
      "2718/2718 [==============================] - 1s 253us/step - loss: 0.3619 - acc: 0.8962 - val_loss: 2.4488 - val_acc: 0.5960\n",
      "Epoch 21/30\n",
      "2718/2718 [==============================] - 1s 256us/step - loss: 0.3300 - acc: 0.9032 - val_loss: 2.3965 - val_acc: 0.5993\n",
      "Epoch 22/30\n",
      "2718/2718 [==============================] - 1s 256us/step - loss: 0.3144 - acc: 0.9036 - val_loss: 2.7767 - val_acc: 0.5892\n",
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2718/2718 [==============================] - 1s 247us/step - loss: 0.3067 - acc: 0.9054 - val_loss: 2.9156 - val_acc: 0.5623\n",
      "Epoch 24/30\n",
      "2718/2718 [==============================] - 1s 240us/step - loss: 0.3018 - acc: 0.9128 - val_loss: 2.5564 - val_acc: 0.5960\n",
      "Epoch 25/30\n",
      "2718/2718 [==============================] - 1s 252us/step - loss: 0.2749 - acc: 0.9220 - val_loss: 2.7224 - val_acc: 0.6027\n",
      "Epoch 26/30\n",
      "2718/2718 [==============================] - 1s 251us/step - loss: 0.2610 - acc: 0.9242 - val_loss: 2.7150 - val_acc: 0.6229\n",
      "Epoch 27/30\n",
      "2718/2718 [==============================] - 1s 251us/step - loss: 0.2591 - acc: 0.9275 - val_loss: 2.5590 - val_acc: 0.6061\n",
      "Epoch 28/30\n",
      "2718/2718 [==============================] - 1s 252us/step - loss: 0.2684 - acc: 0.9202 - val_loss: 2.5695 - val_acc: 0.6061\n",
      "Epoch 29/30\n",
      "2718/2718 [==============================] - 1s 251us/step - loss: 0.2521 - acc: 0.9268 - val_loss: 2.6764 - val_acc: 0.6128\n",
      "Epoch 30/30\n",
      "2718/2718 [==============================] - 1s 257us/step - loss: 0.2489 - acc: 0.9283 - val_loss: 2.8176 - val_acc: 0.5892\n",
      "297/297 [==============================] - 0s 95us/step\n",
      "Fold 9 :\n",
      "\n",
      "Train on 2718 samples, validate on 297 samples\n",
      "Epoch 1/30\n",
      "2718/2718 [==============================] - 2s 722us/step - loss: 2.2963 - acc: 0.2001 - val_loss: 2.0861 - val_acc: 0.2694\n",
      "Epoch 2/30\n",
      "2718/2718 [==============================] - 1s 254us/step - loss: 2.0604 - acc: 0.2222 - val_loss: 1.9669 - val_acc: 0.2290\n",
      "Epoch 3/30\n",
      "2718/2718 [==============================] - 1s 252us/step - loss: 1.8815 - acc: 0.3105 - val_loss: 1.7477 - val_acc: 0.4377\n",
      "Epoch 4/30\n",
      "2718/2718 [==============================] - 1s 250us/step - loss: 1.5964 - acc: 0.4673 - val_loss: 1.6356 - val_acc: 0.4714\n",
      "Epoch 5/30\n",
      "2718/2718 [==============================] - 1s 246us/step - loss: 1.3763 - acc: 0.5545 - val_loss: 1.4568 - val_acc: 0.5623\n",
      "Epoch 6/30\n",
      "2718/2718 [==============================] - 1s 245us/step - loss: 1.2088 - acc: 0.6100 - val_loss: 1.4359 - val_acc: 0.5387\n",
      "Epoch 7/30\n",
      "2718/2718 [==============================] - 1s 244us/step - loss: 1.0744 - acc: 0.6505 - val_loss: 1.3890 - val_acc: 0.5657\n",
      "Epoch 8/30\n",
      "2718/2718 [==============================] - 1s 258us/step - loss: 0.9509 - acc: 0.7042 - val_loss: 1.4084 - val_acc: 0.6061\n",
      "Epoch 9/30\n",
      "2718/2718 [==============================] - 1s 241us/step - loss: 0.8869 - acc: 0.7196 - val_loss: 1.4740 - val_acc: 0.5926\n",
      "Epoch 10/30\n",
      "2718/2718 [==============================] - 1s 248us/step - loss: 0.8079 - acc: 0.7546 - val_loss: 1.4246 - val_acc: 0.6330\n",
      "Epoch 11/30\n",
      "2718/2718 [==============================] - 1s 247us/step - loss: 0.7025 - acc: 0.7789 - val_loss: 1.5647 - val_acc: 0.6195\n",
      "Epoch 12/30\n",
      "2718/2718 [==============================] - 1s 240us/step - loss: 0.6604 - acc: 0.7962 - val_loss: 1.6092 - val_acc: 0.6431\n",
      "Epoch 13/30\n",
      "2718/2718 [==============================] - 1s 237us/step - loss: 0.6095 - acc: 0.8157 - val_loss: 1.6486 - val_acc: 0.6431\n",
      "Epoch 14/30\n",
      "2718/2718 [==============================] - 1s 237us/step - loss: 0.5871 - acc: 0.8230 - val_loss: 1.6561 - val_acc: 0.6364\n",
      "Epoch 15/30\n",
      "2718/2718 [==============================] - 1s 236us/step - loss: 0.5351 - acc: 0.8370 - val_loss: 1.7270 - val_acc: 0.6330\n",
      "Epoch 16/30\n",
      "2718/2718 [==============================] - 1s 251us/step - loss: 0.5099 - acc: 0.8400 - val_loss: 1.7162 - val_acc: 0.6330\n",
      "Epoch 17/30\n",
      "2718/2718 [==============================] - 1s 244us/step - loss: 0.4566 - acc: 0.8543 - val_loss: 2.0938 - val_acc: 0.6162\n",
      "Epoch 18/30\n",
      "2718/2718 [==============================] - 1s 253us/step - loss: 0.4449 - acc: 0.8642 - val_loss: 1.9978 - val_acc: 0.6330\n",
      "Epoch 19/30\n",
      "2718/2718 [==============================] - 1s 269us/step - loss: 0.4194 - acc: 0.8723 - val_loss: 2.0380 - val_acc: 0.6229\n",
      "Epoch 20/30\n",
      "2718/2718 [==============================] - 1s 287us/step - loss: 0.4282 - acc: 0.8764 - val_loss: 2.0539 - val_acc: 0.6195\n",
      "Epoch 21/30\n",
      "2718/2718 [==============================] - 1s 282us/step - loss: 0.3969 - acc: 0.8753 - val_loss: 2.1647 - val_acc: 0.6094\n",
      "Epoch 22/30\n",
      "2718/2718 [==============================] - 1s 269us/step - loss: 0.3561 - acc: 0.8896 - val_loss: 2.3996 - val_acc: 0.6061\n",
      "Epoch 23/30\n",
      "2718/2718 [==============================] - 1s 253us/step - loss: 0.3545 - acc: 0.8900 - val_loss: 2.2283 - val_acc: 0.6061\n",
      "Epoch 24/30\n",
      "2718/2718 [==============================] - 1s 239us/step - loss: 0.3189 - acc: 0.9007 - val_loss: 2.2918 - val_acc: 0.6229\n",
      "Epoch 25/30\n",
      "2718/2718 [==============================] - 1s 242us/step - loss: 0.3124 - acc: 0.9077 - val_loss: 2.3006 - val_acc: 0.6195\n",
      "Epoch 26/30\n",
      "2718/2718 [==============================] - 1s 243us/step - loss: 0.3122 - acc: 0.9077 - val_loss: 2.4146 - val_acc: 0.6229\n",
      "Epoch 27/30\n",
      "2718/2718 [==============================] - 1s 237us/step - loss: 0.3057 - acc: 0.9099 - val_loss: 2.2391 - val_acc: 0.6296\n",
      "Epoch 28/30\n",
      "2718/2718 [==============================] - 1s 241us/step - loss: 0.3198 - acc: 0.9032 - val_loss: 2.4067 - val_acc: 0.5892\n",
      "Epoch 29/30\n",
      "2718/2718 [==============================] - 1s 241us/step - loss: 0.2802 - acc: 0.9183 - val_loss: 2.5360 - val_acc: 0.5960\n",
      "Epoch 30/30\n",
      "2718/2718 [==============================] - 1s 239us/step - loss: 0.2484 - acc: 0.9246 - val_loss: 2.4955 - val_acc: 0.6195\n",
      "297/297 [==============================] - 0s 58us/step\n",
      "Fold 10 :\n",
      "\n",
      "Train on 2719 samples, validate on 296 samples\n",
      "Epoch 1/30\n",
      "2719/2719 [==============================] - 2s 744us/step - loss: 2.2804 - acc: 0.2082 - val_loss: 2.0802 - val_acc: 0.2162\n",
      "Epoch 2/30\n",
      "2719/2719 [==============================] - 1s 263us/step - loss: 2.0482 - acc: 0.2185 - val_loss: 2.0295 - val_acc: 0.2736\n",
      "Epoch 3/30\n",
      "2719/2719 [==============================] - 1s 257us/step - loss: 1.8257 - acc: 0.3545 - val_loss: 1.7784 - val_acc: 0.3818\n",
      "Epoch 4/30\n",
      "2719/2719 [==============================] - 1s 256us/step - loss: 1.5248 - acc: 0.4906 - val_loss: 1.5940 - val_acc: 0.5338\n",
      "Epoch 5/30\n",
      "2719/2719 [==============================] - 1s 255us/step - loss: 1.2861 - acc: 0.5947 - val_loss: 1.6214 - val_acc: 0.4932\n",
      "Epoch 6/30\n",
      "2719/2719 [==============================] - 1s 242us/step - loss: 1.1421 - acc: 0.6524 - val_loss: 1.3992 - val_acc: 0.6047\n",
      "Epoch 7/30\n",
      "2719/2719 [==============================] - 1s 251us/step - loss: 1.0011 - acc: 0.6977 - val_loss: 1.5211 - val_acc: 0.5980\n",
      "Epoch 8/30\n",
      "2719/2719 [==============================] - 1s 250us/step - loss: 0.8955 - acc: 0.7223 - val_loss: 1.5830 - val_acc: 0.6182\n",
      "Epoch 9/30\n",
      "2719/2719 [==============================] - 1s 291us/step - loss: 0.8211 - acc: 0.7444 - val_loss: 1.5572 - val_acc: 0.6081\n",
      "Epoch 10/30\n",
      "2719/2719 [==============================] - 1s 299us/step - loss: 0.7363 - acc: 0.7723 - val_loss: 1.6352 - val_acc: 0.6115\n",
      "Epoch 11/30\n",
      "2719/2719 [==============================] - 1s 262us/step - loss: 0.7027 - acc: 0.7812 - val_loss: 1.7604 - val_acc: 0.5912\n",
      "Epoch 12/30\n",
      "2719/2719 [==============================] - 1s 293us/step - loss: 0.6316 - acc: 0.8099 - val_loss: 1.7234 - val_acc: 0.6115\n",
      "Epoch 13/30\n",
      "2719/2719 [==============================] - 1s 261us/step - loss: 0.5888 - acc: 0.8213 - val_loss: 1.9722 - val_acc: 0.5574\n",
      "Epoch 14/30\n",
      "2719/2719 [==============================] - 1s 260us/step - loss: 0.5635 - acc: 0.8301 - val_loss: 2.0339 - val_acc: 0.5946\n",
      "Epoch 15/30\n",
      "2719/2719 [==============================] - 1s 299us/step - loss: 0.5354 - acc: 0.8349 - val_loss: 2.0807 - val_acc: 0.5811\n",
      "Epoch 16/30\n",
      "2719/2719 [==============================] - 1s 283us/step - loss: 0.5028 - acc: 0.8466 - val_loss: 2.0491 - val_acc: 0.6216\n",
      "Epoch 17/30\n",
      "2719/2719 [==============================] - 1s 298us/step - loss: 0.4572 - acc: 0.8617 - val_loss: 2.0879 - val_acc: 0.6149\n",
      "Epoch 18/30\n",
      "2719/2719 [==============================] - 1s 310us/step - loss: 0.4518 - acc: 0.8658 - val_loss: 2.3221 - val_acc: 0.6014\n",
      "Epoch 19/30\n",
      "2719/2719 [==============================] - 1s 247us/step - loss: 0.4703 - acc: 0.8547 - val_loss: 2.0895 - val_acc: 0.5912\n",
      "Epoch 20/30\n",
      "2719/2719 [==============================] - 1s 249us/step - loss: 0.4107 - acc: 0.8775 - val_loss: 2.2717 - val_acc: 0.5878\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2719/2719 [==============================] - 1s 359us/step - loss: 0.4015 - acc: 0.8849 - val_loss: 2.1703 - val_acc: 0.5946\n",
      "Epoch 22/30\n",
      "2719/2719 [==============================] - 1s 283us/step - loss: 0.3649 - acc: 0.8941 - val_loss: 2.4416 - val_acc: 0.6047\n",
      "Epoch 23/30\n",
      "2719/2719 [==============================] - 1s 258us/step - loss: 0.3397 - acc: 0.8996 - val_loss: 2.3673 - val_acc: 0.5946\n",
      "Epoch 24/30\n",
      "2719/2719 [==============================] - 1s 239us/step - loss: 0.3382 - acc: 0.8974 - val_loss: 2.4169 - val_acc: 0.6047\n",
      "Epoch 25/30\n",
      "2719/2719 [==============================] - 1s 303us/step - loss: 0.3306 - acc: 0.9029 - val_loss: 2.5130 - val_acc: 0.6149\n",
      "Epoch 26/30\n",
      "2719/2719 [==============================] - 1s 263us/step - loss: 0.3146 - acc: 0.9103 - val_loss: 2.6536 - val_acc: 0.6014\n",
      "Epoch 27/30\n",
      "2719/2719 [==============================] - 1s 238us/step - loss: 0.3070 - acc: 0.9084 - val_loss: 2.7074 - val_acc: 0.5709\n",
      "Epoch 28/30\n",
      "2719/2719 [==============================] - 1s 238us/step - loss: 0.3068 - acc: 0.9121 - val_loss: 2.5879 - val_acc: 0.6047\n",
      "Epoch 29/30\n",
      "2719/2719 [==============================] - 1s 234us/step - loss: 0.3010 - acc: 0.9147 - val_loss: 2.4075 - val_acc: 0.6014\n",
      "Epoch 30/30\n",
      "2719/2719 [==============================] - 1s 233us/step - loss: 0.2947 - acc: 0.9169 - val_loss: 2.7892 - val_acc: 0.5878\n",
      "296/296 [==============================] - 0s 53us/step\n"
     ]
    }
   ],
   "source": [
    "#untuk k=10\n",
    "kf = StratifiedKFold(n_splits=10, random_state=None, shuffle=False)\n",
    "val_loss_cv = []\n",
    "val_acc_cv = []\n",
    "j = 0\n",
    "for train_index, test_index in kf.split(X,y):\n",
    "    j+=1\n",
    "    print(f\"Fold {j} :\")\n",
    "    print(\"\")\n",
    "    X_train,X_test = X[train_index],X[test_index]\n",
    "    y_train,y_test = y[train_index],y[test_index]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim=X_train.shape[1], units=128,\n",
    "                     kernel_initializer='normal', bias_initializer='zeros'))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    for i in range(0, 6):\n",
    "        model.add(Dense(units=128, kernel_initializer='normal',\n",
    "                         bias_initializer='zeros'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(.15))\n",
    "\n",
    "    model.add(Dense(units=19))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train,batch_size=24,epochs=30,verbose=1,validation_data=(X_test, y_test))\n",
    "    score = model.evaluate(X_test, y_test, verbose=1)\n",
    "    val_loss_cv.append(score[0])\n",
    "    val_acc_cv.append(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss_cv : [3.7036242101736776, 3.9519291233706784, 3.1221593724619043, 2.6997571593503222, 2.5282895929393576, 2.8131870874930853, 3.027012665271759, 2.8175790000844887, 2.4955170885079636, 2.7892347993077458]\n",
      "mean_val_loss_cv : 2.9948290098960983\n",
      "val_acc_cv : [0.47588424384593964, 0.41558441577793714, 0.5346534655186603, 0.5548172760445415, 0.6245847187961059, 0.5581395358738314, 0.5966666666666667, 0.5892255898276564, 0.6195286197293086, 0.5878378378378378]\n",
      "mean_val_acc_cv : 0.5556922369918486\n"
     ]
    }
   ],
   "source": [
    "print(f\"val_loss_cv : {val_loss_cv}\")\n",
    "print(f\"mean_val_loss_cv : {np.mean(val_loss_cv)}\")\n",
    "print(f\"val_acc_cv : {val_acc_cv}\")\n",
    "print(f\"mean_val_acc_cv : {np.mean(val_acc_cv)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2109 samples, validate on 905 samples\n",
      "Epoch 1/30\n",
      "2109/2109 [==============================] - 3s 1ms/step - loss: 2.3081 - acc: 0.2077 - val_loss: 2.0970 - val_acc: 0.2166\n",
      "Epoch 2/30\n",
      "2109/2109 [==============================] - 1s 311us/step - loss: 2.0622 - acc: 0.2176 - val_loss: 2.0262 - val_acc: 0.2133\n",
      "Epoch 3/30\n",
      "2109/2109 [==============================] - 1s 304us/step - loss: 1.8343 - acc: 0.3310 - val_loss: 1.8154 - val_acc: 0.3923\n",
      "Epoch 4/30\n",
      "2109/2109 [==============================] - 1s 290us/step - loss: 1.6292 - acc: 0.4116 - val_loss: 1.7554 - val_acc: 0.4265\n",
      "Epoch 5/30\n",
      "2109/2109 [==============================] - 1s 296us/step - loss: 1.4431 - acc: 0.5111 - val_loss: 1.7139 - val_acc: 0.4917\n",
      "Epoch 6/30\n",
      "2109/2109 [==============================] - 1s 322us/step - loss: 1.2412 - acc: 0.5941 - val_loss: 1.6673 - val_acc: 0.5182\n",
      "Epoch 7/30\n",
      "2109/2109 [==============================] - 1s 302us/step - loss: 1.1076 - acc: 0.6415 - val_loss: 1.6790 - val_acc: 0.5249\n",
      "Epoch 8/30\n",
      "2109/2109 [==============================] - 1s 299us/step - loss: 0.9933 - acc: 0.7027 - val_loss: 1.6852 - val_acc: 0.5580\n",
      "Epoch 9/30\n",
      "2109/2109 [==============================] - 1s 300us/step - loss: 0.8636 - acc: 0.7373 - val_loss: 1.8077 - val_acc: 0.5459\n",
      "Epoch 10/30\n",
      "2109/2109 [==============================] - 1s 295us/step - loss: 0.7846 - acc: 0.7596 - val_loss: 1.8394 - val_acc: 0.5657\n",
      "Epoch 11/30\n",
      "2109/2109 [==============================] - 1s 307us/step - loss: 0.6998 - acc: 0.7937 - val_loss: 2.0620 - val_acc: 0.5525\n",
      "Epoch 12/30\n",
      "2109/2109 [==============================] - 1s 320us/step - loss: 0.6913 - acc: 0.7833 - val_loss: 1.8839 - val_acc: 0.5757\n",
      "Epoch 13/30\n",
      "2109/2109 [==============================] - 1s 297us/step - loss: 0.6045 - acc: 0.8132 - val_loss: 2.0975 - val_acc: 0.5591\n",
      "Epoch 14/30\n",
      "2109/2109 [==============================] - 1s 299us/step - loss: 0.5840 - acc: 0.8184 - val_loss: 1.9810 - val_acc: 0.5713\n",
      "Epoch 15/30\n",
      "2109/2109 [==============================] - 1s 295us/step - loss: 0.5793 - acc: 0.8212 - val_loss: 1.9908 - val_acc: 0.5702\n",
      "Epoch 16/30\n",
      "2109/2109 [==============================] - 1s 299us/step - loss: 0.5257 - acc: 0.8397 - val_loss: 2.2474 - val_acc: 0.5790\n",
      "Epoch 17/30\n",
      "2109/2109 [==============================] - 1s 298us/step - loss: 0.5086 - acc: 0.8412 - val_loss: 2.2822 - val_acc: 0.5613\n",
      "Epoch 18/30\n",
      "2109/2109 [==============================] - 1s 306us/step - loss: 0.4915 - acc: 0.8497 - val_loss: 2.3042 - val_acc: 0.5635\n",
      "Epoch 19/30\n",
      "2109/2109 [==============================] - 1s 307us/step - loss: 0.4372 - acc: 0.8644 - val_loss: 2.4184 - val_acc: 0.5779\n",
      "Epoch 20/30\n",
      "2109/2109 [==============================] - 1s 284us/step - loss: 0.3789 - acc: 0.8800 - val_loss: 2.5120 - val_acc: 0.5856\n",
      "Epoch 21/30\n",
      "2109/2109 [==============================] - 1s 297us/step - loss: 0.3690 - acc: 0.8862 - val_loss: 2.7132 - val_acc: 0.5702\n",
      "Epoch 22/30\n",
      "2109/2109 [==============================] - 1s 285us/step - loss: 0.3768 - acc: 0.8843 - val_loss: 2.6169 - val_acc: 0.5901\n",
      "Epoch 23/30\n",
      "2109/2109 [==============================] - 1s 303us/step - loss: 0.3520 - acc: 0.8895 - val_loss: 2.7093 - val_acc: 0.5691\n",
      "Epoch 24/30\n",
      "2109/2109 [==============================] - 1s 299us/step - loss: 0.3398 - acc: 0.8957 - val_loss: 2.7232 - val_acc: 0.5746\n",
      "Epoch 25/30\n",
      "2109/2109 [==============================] - 1s 298us/step - loss: 0.3397 - acc: 0.8914 - val_loss: 2.7698 - val_acc: 0.5823\n",
      "Epoch 26/30\n",
      "2109/2109 [==============================] - 1s 277us/step - loss: 0.3586 - acc: 0.8890 - val_loss: 2.7736 - val_acc: 0.5735\n",
      "Epoch 27/30\n",
      "2109/2109 [==============================] - 1s 311us/step - loss: 0.2875 - acc: 0.9085 - val_loss: 3.2504 - val_acc: 0.5967\n",
      "Epoch 28/30\n",
      "2109/2109 [==============================] - 1s 304us/step - loss: 0.3063 - acc: 0.9018 - val_loss: 2.9987 - val_acc: 0.5713\n",
      "Epoch 29/30\n",
      "2109/2109 [==============================] - 1s 304us/step - loss: 0.2979 - acc: 0.9109 - val_loss: 2.7584 - val_acc: 0.5768\n",
      "Epoch 30/30\n",
      "2109/2109 [==============================] - 1s 315us/step - loss: 0.3027 - acc: 0.9104 - val_loss: 2.6273 - val_acc: 0.5691\n",
      "905/905 [==============================] - 0s 96us/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=0)\n",
    "for train_index, test_index in sss.split(X,y):\n",
    "    X_train,X_test = X[train_index],X[test_index]\n",
    "    y_train,y_test = y[train_index],y[test_index]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim=X_train.shape[1], units=128,\n",
    "                     kernel_initializer='normal', bias_initializer='zeros'))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    for i in range(0, 6):\n",
    "        model.add(Dense(units=128, kernel_initializer='normal',\n",
    "                         bias_initializer='zeros'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(.15))\n",
    "\n",
    "    model.add(Dense(units=19))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train,batch_size=24,epochs=30,verbose=1,validation_data=(X_test, y_test))\n",
    "    score = model.evaluate(X_test, y_test, verbose=1)\n",
    "    val_loss_cv.append(score[0])\n",
    "    val_acc_cv.append(score[1])\n",
    "    predict = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14,  3, 14,  8, 14, 11,  6,  3, 14, 11, 11, 16, 11, 16,  6, 14, 14,\n",
       "        6, 14,  6,  6,  1,  1, 15, 17, 13, 14,  3, 11, 11, 16,  3, 15,  6,\n",
       "        1,  6, 16, 15,  6,  3, 14, 18, 14, 14, 14,  6, 15,  6, 16, 14, 15,\n",
       "       11,  3, 14, 11, 14, 11,  3, 14,  6, 11,  1,  6, 17, 15, 14, 14,  1,\n",
       "        3, 14, 14, 11, 14,  3, 14,  3, 17,  3, 13,  1, 16, 11,  3, 14, 14,\n",
       "       11, 11,  3,  1,  1,  6,  9, 15, 15,  6, 11, 11, 11, 14, 15,  3, 14,\n",
       "       13, 15,  8, 15,  3, 14, 14, 11,  3, 16, 16, 16, 14, 15,  3, 13,  3,\n",
       "        3, 14, 11,  9, 16,  6, 15,  3, 15,  3,  3, 15,  1,  8, 14, 16,  1,\n",
       "       11,  3, 15, 16, 18, 16,  3,  3,  3, 14, 14,  3, 17,  1,  3, 14, 17,\n",
       "       11, 11,  6,  6, 13,  1, 16, 15,  6,  9, 17,  9, 15, 13,  6,  6, 11,\n",
       "       14,  3, 15,  1, 16, 15,  6, 11,  3, 11,  6, 14, 11, 15,  3, 17, 11,\n",
       "        3,  6, 15, 11,  6, 14,  6, 11, 14, 14,  3, 18, 11,  9, 15,  6,  3,\n",
       "        6, 16, 14,  3, 17, 15,  8, 14, 11, 14, 14, 14,  8, 11,  3,  3, 14,\n",
       "       15, 15,  6,  6, 18,  8, 14, 11, 13,  1,  1, 11,  3,  3, 17,  9, 18,\n",
       "       14,  3, 14, 11, 16, 14, 16, 15, 18, 15, 15, 11, 11,  3, 14, 15, 14,\n",
       "       16,  6, 16, 15, 16,  1, 15,  8, 15, 14, 14, 15, 15, 15, 11,  6, 14,\n",
       "        6, 11, 15,  9, 15,  8,  6,  3,  6, 15, 11, 11, 14, 14, 15, 11,  6,\n",
       "       14,  3, 18,  3, 11, 14, 11, 15,  3, 11, 14,  1,  6, 11,  8,  3, 11,\n",
       "       13,  3,  6,  6, 14, 15,  9, 14, 14, 15, 11, 11, 14,  3, 11, 14,  3,\n",
       "        6,  3, 15, 17,  6, 14, 14,  6,  3, 14,  3, 13, 14,  2,  3, 16,  1,\n",
       "       14, 11, 11,  6, 14, 15, 15, 15, 16, 15,  1,  6,  3,  8, 16,  6,  1,\n",
       "       15,  1,  3, 11,  6,  3, 14,  6,  3, 11, 14, 11,  3, 11, 16, 14, 16,\n",
       "        6, 11,  3,  6, 17,  3, 15,  6, 11,  1, 14, 11, 11,  6,  6,  1, 11,\n",
       "       16, 15, 14, 16,  6, 14, 15,  3, 14,  6, 11, 11, 11, 17, 16, 14, 15,\n",
       "        6, 11,  1, 11,  6, 11, 14, 13, 17, 11, 14, 11, 14,  6, 14,  8, 11,\n",
       "        1,  6, 11,  6, 15,  6,  3, 14, 14, 11,  3,  1,  6, 14, 11,  3, 14,\n",
       "       16, 11, 15, 11, 14, 14,  6,  6,  6, 16,  6,  6, 16, 11, 11, 11, 11,\n",
       "       11, 14, 14,  6, 11, 14,  3,  1, 15, 11,  3, 14, 11, 11,  3,  6,  6,\n",
       "        1,  3, 15,  3, 14, 14, 15, 14, 14, 15, 11,  3,  3, 14,  3, 14,  3,\n",
       "       14, 13, 13,  2,  9,  6, 14, 11,  9, 13, 11, 11, 14, 14,  3, 11,  9,\n",
       "        3, 14,  3, 11, 11, 15, 17,  6, 11,  1,  1,  6, 11, 14, 14, 14, 15,\n",
       "        1, 11,  3, 14,  3,  1,  3, 16, 13, 13, 14, 13,  3, 11,  3, 11, 14,\n",
       "       14, 11, 15, 16,  1, 16, 11, 15,  8,  3,  3, 16, 11,  3, 18, 11, 15,\n",
       "       16,  6,  6, 11,  6, 16, 11, 11,  3, 11,  3,  8,  6,  3, 14,  8,  9,\n",
       "        1, 11, 16,  1, 11,  3, 15,  3,  3, 11, 14,  6,  8,  3,  3,  3, 11,\n",
       "       16,  3, 14,  3,  3, 15,  3, 13,  3, 16, 11, 15,  6,  1,  6,  6,  6,\n",
       "        2, 15,  3,  6, 14,  6,  6, 14, 14, 11, 11, 15, 14, 11,  1,  6, 15,\n",
       "       11, 15, 14, 13, 11, 11, 11, 15, 11,  6,  6,  3, 11,  9, 11, 15, 15,\n",
       "        1, 15,  1, 15, 14,  3,  3,  6, 14,  3,  6, 15, 11, 14, 14, 16, 15,\n",
       "       17, 14, 11,  6,  1,  3,  2,  1,  3, 11,  6, 11, 11,  3,  3,  3,  6,\n",
       "        6, 15, 17, 11, 11,  8, 14, 14, 15, 14, 13, 16, 11, 16,  3, 11, 11,\n",
       "       15,  3, 11,  6, 15,  3,  3, 17,  3,  3, 18,  3,  6, 11,  8,  3, 16,\n",
       "       15, 15,  3, 11, 14, 11,  9,  3, 14,  9, 15, 16,  1, 14, 17,  3, 17,\n",
       "       11,  3,  6, 17,  3,  6, 14, 11,  8,  6, 13, 17, 15,  3,  3,  8, 14,\n",
       "        3, 11,  6, 14, 15, 11,  3, 11, 13, 16, 16, 11,  3,  3,  6, 15, 16,\n",
       "       15, 14, 11,  6, 15,  2,  6,  6,  3,  6, 11,  6, 11,  3, 16, 13, 15,\n",
       "        2, 15, 14,  6,  6,  6,  3, 14, 14,  3, 15, 11, 15, 11,  3, 11, 14,\n",
       "       15, 15, 14,  3,  2,  1,  9,  3, 17,  3,  1, 15, 11, 14, 14, 14, 14,\n",
       "        6, 11, 14, 14, 11,  6, 14, 16,  1, 16,  6,  3, 14, 14,  6, 15, 11,\n",
       "        3, 16, 15, 15,  6, 16, 15, 11,  3, 11, 15, 15, 17, 14, 11,  6, 13,\n",
       "       16,  6,  1,  3, 11,  3,  3,  6,  3,  3, 17, 11, 15, 15, 14, 11, 11,\n",
       "       15,  3, 15, 15,  3,  6,  3,  3, 15, 11, 11, 14,  6, 15,  1,  3,  6,\n",
       "        6,  9, 14, 15, 14, 14, 14, 14, 14,  6, 14, 11,  3, 11, 14,  8, 15,\n",
       "        6, 11,  6,  1], dtype=int64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14,  9, 14,  8, 14, 11,  6,  3, 14, 11, 11, 16, 11, 16, 14, 14, 14,\n",
       "       14, 14,  6, 11, 17, 11, 15, 17, 11, 14,  3, 11, 11,  1,  3, 17,  6,\n",
       "       11,  6,  3, 15, 14,  6, 14, 16, 14, 14,  6,  6, 15, 14, 11, 14, 11,\n",
       "       11, 11, 14, 11, 14, 14, 14, 14,  6, 11,  6,  6,  3, 11,  8, 11,  3,\n",
       "       11, 14, 11, 15, 14, 14, 14,  3, 15,  3,  3, 13, 15, 11,  3, 14, 14,\n",
       "       11, 11,  3,  1,  1, 14, 16, 15, 15, 14, 11, 15,  6, 14, 15,  6, 14,\n",
       "       11, 15, 10,  1,  3, 14,  3, 16,  3, 16, 16, 11,  8,  1,  3, 14,  3,\n",
       "        6, 14, 11,  9,  6,  6, 11,  3,  6,  3,  3, 15,  1,  8, 14,  3, 14,\n",
       "       13,  3, 11,  1, 11, 16, 15, 18,  3,  8, 14,  9, 14, 18,  3, 14, 11,\n",
       "       14, 15, 16,  6,  6,  8, 14, 15, 11, 16,  8,  1, 15,  6,  6,  6, 11,\n",
       "       11,  3, 11,  1, 11, 15,  6, 14, 17, 17,  6,  6, 11, 15,  3, 17, 11,\n",
       "        3,  6, 15, 15,  6, 14,  6, 11, 14, 14,  3, 17, 11, 14, 15, 14,  3,\n",
       "       14, 16,  6,  3, 17, 15, 11,  6, 11,  8, 14,  6,  8, 11,  3,  3, 14,\n",
       "       11, 15,  6,  6,  3,  8, 14, 11, 11,  1,  1,  1,  6,  3, 17, 14,  2,\n",
       "       14,  6, 14, 11,  2, 14, 16, 15, 14, 11, 11, 11, 15,  6, 14,  3, 14,\n",
       "        3, 11, 16, 15,  3,  3, 15, 14, 15, 14, 14,  1, 15,  1,  3,  3, 11,\n",
       "       11, 11, 11, 11, 13,  3,  6,  3,  1, 11,  3, 11, 14, 14, 15, 11,  6,\n",
       "       14,  3, 16,  3, 11, 11, 11, 11,  3,  1, 14,  1,  6, 11,  8,  3,  1,\n",
       "        1,  1, 14,  1, 14, 15, 14, 14,  2, 15, 11, 11, 14,  3, 11, 14,  3,\n",
       "        6,  3, 11, 17, 14, 14, 14,  6,  3, 14, 15, 11,  6, 16,  3, 16, 13,\n",
       "       14, 11, 17,  6, 14, 15, 18,  3, 18, 11, 13,  3,  1,  3, 11,  6, 11,\n",
       "        3, 11,  3,  1, 11, 15, 11,  6, 15, 11,  3, 16, 11, 11, 15, 14, 16,\n",
       "        6, 11,  3,  6, 17, 13, 15,  6, 17, 11, 14, 11, 11,  6,  6,  1, 14,\n",
       "       14,  3,  6, 16,  6, 14, 15, 15,  1, 10,  6,  1, 11, 17,  3,  3, 15,\n",
       "        6,  3,  1, 14, 14, 11, 14,  3, 11,  1,  6, 17, 11,  6,  6,  3, 11,\n",
       "        1,  3, 11, 11, 15,  6, 15, 14, 14, 14, 16, 13,  3, 11, 11,  3, 14,\n",
       "       16,  6, 15, 14, 14, 14,  6, 16, 15,  3,  3,  6, 16, 14, 11, 11, 11,\n",
       "       11, 14, 14,  6, 11, 14,  3, 11, 11, 14,  3,  6, 11, 11, 15,  6,  3,\n",
       "       17,  6, 11, 14, 14, 14, 11, 14, 14, 15, 11,  6,  1,  1,  6, 14, 15,\n",
       "        6, 11,  1,  2,  9,  6, 14, 11, 14, 10, 11, 11, 14, 14,  3, 11,  9,\n",
       "        3, 11,  3, 11, 11, 15, 15, 10, 11, 15,  1,  6, 11, 14, 14, 14, 17,\n",
       "       11, 11, 14, 14,  3,  1,  3,  3, 13, 11, 14, 11, 15, 11,  3, 11,  3,\n",
       "       14, 11, 15, 16, 14, 16, 11, 15,  8,  6,  3, 16, 11, 16, 11, 11,  6,\n",
       "        3, 11,  6, 11,  6, 16, 11, 11,  3,  1, 16,  8,  6,  3,  6,  3, 14,\n",
       "       11, 11, 16, 11, 11,  1, 11, 14,  3, 18, 14,  6, 17, 17,  3,  3, 11,\n",
       "        1, 16, 14,  3,  3, 15,  3, 13,  3,  6,  1, 15, 17,  1,  6, 11,  6,\n",
       "        2, 15, 16,  6, 14,  1, 18, 14, 14, 11, 11,  1, 14,  3,  1,  6, 15,\n",
       "       11,  1, 14,  8, 11, 11, 11, 15, 11, 11,  6,  3, 11,  8, 16, 11, 15,\n",
       "       15, 11,  1, 15, 14,  3,  3,  6, 14,  3,  6, 15, 11, 14, 14, 15, 11,\n",
       "       17, 14,  3, 11,  1, 11,  2,  1,  1, 14,  3, 15, 11, 14,  3,  3,  6,\n",
       "        6, 15, 15, 11, 15, 14, 14, 14, 15, 14, 11, 16, 11, 16,  6, 11, 11,\n",
       "       15,  3, 11, 14, 11,  6,  3, 17,  3, 14, 16,  3,  6, 11,  2,  3, 16,\n",
       "       15, 15,  3,  6, 14,  6, 14, 11, 14, 14, 11,  3,  6, 14, 17, 11, 17,\n",
       "       11,  3,  6, 15,  2, 11, 14, 14,  8,  3, 11, 17, 15,  3,  3, 17, 14,\n",
       "        6,  1,  6, 14, 11, 11,  3, 11, 11, 16, 16, 17,  3,  6,  6, 15,  3,\n",
       "       10, 14, 11,  6, 15,  6,  3,  3,  3,  6, 11, 14, 11,  3, 16, 15, 15,\n",
       "        8, 11, 14, 11, 14,  6,  3, 14, 14,  3, 15, 15,  3, 11, 15, 11,  1,\n",
       "       15,  1, 14, 16,  2, 16,  2,  3, 11,  6, 15, 15, 11, 14,  6, 14, 16,\n",
       "        6, 11, 11, 14, 11,  3,  6, 14,  1, 15, 14,  3,  3, 14,  3,  1,  1,\n",
       "        3, 16,  3, 15,  6,  3, 15, 11,  9, 11, 11, 15, 14, 14,  1, 16, 14,\n",
       "       16,  6, 15,  6, 11,  1,  3,  6,  3, 16, 11,  1, 15,  6, 14, 11, 15,\n",
       "       15, 11, 11, 11, 16,  6, 11,  3, 15,  1, 15, 14, 11, 13,  1,  3,  3,\n",
       "        6,  1, 14,  3, 14, 14, 14, 14, 14,  6, 14,  6, 16, 11, 14,  9,  3,\n",
       "        6, 11, 14,  1], dtype=int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.569060773480663"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11    649\n",
       "14    576\n",
       "3     457\n",
       "6     382\n",
       "15    313\n",
       "1     201\n",
       "16    163\n",
       "17     90\n",
       "8      57\n",
       "13     32\n",
       "2      32\n",
       "9      22\n",
       "18     21\n",
       "10     17\n",
       "4       2\n",
       "5       1\n",
       "Name: Kelas, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1['Kelas'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 20,   0,   6,   3,   0,   2,   0,  13,   2,   3,   8,   3,   0,\n",
       "          0],\n",
       "       [  0,   4,   1,   0,   1,   1,   0,   0,   0,   1,   0,   1,   0,\n",
       "          1],\n",
       "       [  2,   0,  85,  13,   4,   0,   0,   5,   2,   5,   8,  11,   1,\n",
       "          1],\n",
       "       [  2,   1,  16,  69,   0,   0,   0,   6,   2,  14,   3,   2,   0,\n",
       "          0],\n",
       "       [  1,   1,   0,   0,   8,   1,   0,   0,   1,   4,   0,   0,   1,\n",
       "          0],\n",
       "       [  0,   0,   3,   0,   1,   3,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0],\n",
       "       [  0,   0,   0,   2,   1,   0,   0,   0,   1,   0,   1,   0,   0,\n",
       "          0],\n",
       "       [  9,   0,   8,  13,   1,   1,   0, 106,  10,  10,  27,   4,   4,\n",
       "          2],\n",
       "       [  4,   0,   1,   0,   0,   0,   0,   1,   2,   0,   2,   0,   0,\n",
       "          0],\n",
       "       [  2,   0,   7,  16,   2,   7,   0,  11,   2, 120,   0,   3,   2,\n",
       "          1],\n",
       "       [  4,   0,  10,   1,   0,   0,   0,  10,   1,   0,  60,   4,   4,\n",
       "          0],\n",
       "       [  1,   1,   9,   3,   0,   2,   0,   3,   0,   1,   0,  26,   0,\n",
       "          3],\n",
       "       [  2,   0,   2,   1,   2,   0,   0,   5,   0,   0,   2,   0,  12,\n",
       "          1],\n",
       "       [  1,   0,   1,   1,   0,   0,   0,   1,   0,   0,   1,   1,   0,\n",
       "          0]], dtype=int64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[ 20   0   6   3   0   2   0  13   2   3   8   3   0   0]\n",
      " [  0   4   1   0   1   1   0   0   0   1   0   1   0   1]\n",
      " [  2   0  85  13   4   0   0   5   2   5   8  11   1   1]\n",
      " [  2   1  16  69   0   0   0   6   2  14   3   2   0   0]\n",
      " [  1   1   0   0   8   1   0   0   1   4   0   0   1   0]\n",
      " [  0   0   3   0   1   3   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   2   1   0   0   0   1   0   1   0   0   0]\n",
      " [  9   0   8  13   1   1   0 106  10  10  27   4   4   2]\n",
      " [  4   0   1   0   0   0   0   1   2   0   2   0   0   0]\n",
      " [  2   0   7  16   2   7   0  11   2 120   0   3   2   1]\n",
      " [  4   0  10   1   0   0   0  10   1   0  60   4   4   0]\n",
      " [  1   1   9   3   0   2   0   3   0   1   0  26   0   3]\n",
      " [  2   0   2   1   2   0   0   5   0   0   2   0  12   1]\n",
      " [  1   0   1   1   0   0   0   1   0   0   1   1   0   0]]\n",
      "Normalized confusion matrix\n",
      "[[0.33 0.   0.1  0.05 0.   0.03 0.   0.22 0.03 0.05 0.13 0.05 0.   0.  ]\n",
      " [0.   0.4  0.1  0.   0.1  0.1  0.   0.   0.   0.1  0.   0.1  0.   0.1 ]\n",
      " [0.01 0.   0.62 0.09 0.03 0.   0.   0.04 0.01 0.04 0.06 0.08 0.01 0.01]\n",
      " [0.02 0.01 0.14 0.6  0.   0.   0.   0.05 0.02 0.12 0.03 0.02 0.   0.  ]\n",
      " [0.06 0.06 0.   0.   0.47 0.06 0.   0.   0.06 0.24 0.   0.   0.06 0.  ]\n",
      " [0.   0.   0.43 0.   0.14 0.43 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.4  0.2  0.   0.   0.   0.2  0.   0.2  0.   0.   0.  ]\n",
      " [0.05 0.   0.04 0.07 0.01 0.01 0.   0.54 0.05 0.05 0.14 0.02 0.02 0.01]\n",
      " [0.4  0.   0.1  0.   0.   0.   0.   0.1  0.2  0.   0.2  0.   0.   0.  ]\n",
      " [0.01 0.   0.04 0.09 0.01 0.04 0.   0.06 0.01 0.69 0.   0.02 0.01 0.01]\n",
      " [0.04 0.   0.11 0.01 0.   0.   0.   0.11 0.01 0.   0.64 0.04 0.04 0.  ]\n",
      " [0.02 0.02 0.18 0.06 0.   0.04 0.   0.06 0.   0.02 0.   0.53 0.   0.06]\n",
      " [0.07 0.   0.07 0.04 0.07 0.   0.   0.19 0.   0.   0.07 0.   0.44 0.04]\n",
      " [0.17 0.   0.17 0.17 0.   0.   0.   0.17 0.   0.   0.17 0.17 0.   0.  ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(np.unique(y_test)))\n",
    "    plt.xticks(tick_marks, np.unique(y_test), rotation=45)\n",
    "    plt.yticks(tick_marks, np.unique(y_test))\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, predict)\n",
    "np.set_printoptions(precision=2)\n",
    "print('Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm)\n",
    "\n",
    "# Normalize the confusion matrix by row (i.e by the number of samples\n",
    "# in each class)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Normalized confusion matrix')\n",
    "print(cm_normalized)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm_normalized, title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  6  8  9 10 11 13 14 15 16 17 18]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
