{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#masukin data1\n",
    "data1=pandas.read_csv('D:\\\\SKRIPSI\\\\data\\\\data_praproses\\\\jamu_herbs.csv', sep=',')\n",
    "#masukin data2\n",
    "data2=pandas.read_csv('D:\\\\SKRIPSI\\\\data\\\\data_praproses\\\\jamu_class.csv', sep=',')\n",
    "data_1 = data1.drop('IDJamu',axis=1)\n",
    "data_2 = data2.drop('Jamu ID',axis=1)\n",
    "data_1['Kelas']=data_2['Class of Diseases']\n",
    "X = data_1.drop('Kelas', axis=1).values\n",
    "y = data_1['Kelas'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=4.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 :\n",
      "\n",
      "Train on 2253 samples, validate on 762 samples\n",
      "Epoch 1/30\n",
      "2253/2253 [==============================] - 1s 549us/step - loss: 2.2401 - acc: 0.1931 - val_loss: 2.1765 - val_acc: 0.2139\n",
      "Epoch 2/30\n",
      "2253/2253 [==============================] - 1s 235us/step - loss: 2.1931 - acc: 0.1913 - val_loss: 2.1934 - val_acc: 0.2139\n",
      "Epoch 3/30\n",
      "2253/2253 [==============================] - 1s 241us/step - loss: 2.1944 - acc: 0.1900 - val_loss: 2.1808 - val_acc: 0.1890\n",
      "Epoch 4/30\n",
      "2253/2253 [==============================] - 1s 273us/step - loss: 2.1840 - acc: 0.1957 - val_loss: 2.1794 - val_acc: 0.2139\n",
      "Epoch 5/30\n",
      "2253/2253 [==============================] - 1s 284us/step - loss: 2.1812 - acc: 0.1966 - val_loss: 2.1794 - val_acc: 0.2139\n",
      "Epoch 6/30\n",
      "2253/2253 [==============================] - 1s 292us/step - loss: 2.1677 - acc: 0.2042 - val_loss: 2.1751 - val_acc: 0.2139\n",
      "Epoch 7/30\n",
      "2253/2253 [==============================] - 1s 244us/step - loss: 2.1691 - acc: 0.2086 - val_loss: 2.1849 - val_acc: 0.1890\n",
      "Epoch 8/30\n",
      "2253/2253 [==============================] - 0s 214us/step - loss: 2.1645 - acc: 0.2099 - val_loss: 2.1770 - val_acc: 0.2139\n",
      "Epoch 9/30\n",
      "2253/2253 [==============================] - 1s 270us/step - loss: 2.1673 - acc: 0.2095 - val_loss: 2.1755 - val_acc: 0.2139\n",
      "Epoch 10/30\n",
      "2253/2253 [==============================] - 1s 226us/step - loss: 2.1661 - acc: 0.2006 - val_loss: 2.1805 - val_acc: 0.1890\n",
      "Epoch 11/30\n",
      "2253/2253 [==============================] - 0s 208us/step - loss: 2.1582 - acc: 0.2179 - val_loss: 2.1774 - val_acc: 0.1890\n",
      "Epoch 12/30\n",
      "2253/2253 [==============================] - 0s 205us/step - loss: 2.1642 - acc: 0.1980 - val_loss: 2.1752 - val_acc: 0.2139\n",
      "Epoch 13/30\n",
      "2253/2253 [==============================] - 0s 209us/step - loss: 2.1616 - acc: 0.2126 - val_loss: 2.1775 - val_acc: 0.1890\n",
      "Epoch 14/30\n",
      "2253/2253 [==============================] - 0s 208us/step - loss: 2.1597 - acc: 0.1971 - val_loss: 2.1796 - val_acc: 0.2139\n",
      "Epoch 15/30\n",
      "2253/2253 [==============================] - 0s 214us/step - loss: 2.1592 - acc: 0.2219 - val_loss: 2.1789 - val_acc: 0.1890\n",
      "Epoch 16/30\n",
      "2253/2253 [==============================] - 0s 207us/step - loss: 2.1596 - acc: 0.2095 - val_loss: 2.1651 - val_acc: 0.2139\n",
      "Epoch 17/30\n",
      "2253/2253 [==============================] - 0s 217us/step - loss: 2.0360 - acc: 0.3231 - val_loss: 2.1108 - val_acc: 0.2940\n",
      "Epoch 18/30\n",
      "2253/2253 [==============================] - 1s 243us/step - loss: 1.8964 - acc: 0.3675 - val_loss: 2.0896 - val_acc: 0.2966\n",
      "Epoch 19/30\n",
      "2253/2253 [==============================] - 1s 256us/step - loss: 1.8440 - acc: 0.3680 - val_loss: 2.0771 - val_acc: 0.3018\n",
      "Epoch 20/30\n",
      "2253/2253 [==============================] - 1s 293us/step - loss: 1.8195 - acc: 0.3764 - val_loss: 2.0430 - val_acc: 0.3136\n",
      "Epoch 21/30\n",
      "2253/2253 [==============================] - 1s 283us/step - loss: 1.7964 - acc: 0.3795 - val_loss: 2.1104 - val_acc: 0.3045\n",
      "Epoch 22/30\n",
      "2253/2253 [==============================] - 1s 265us/step - loss: 1.7757 - acc: 0.3893 - val_loss: 2.0558 - val_acc: 0.3084\n",
      "Epoch 23/30\n",
      "2253/2253 [==============================] - 1s 249us/step - loss: 1.7736 - acc: 0.3866 - val_loss: 2.0079 - val_acc: 0.3360\n",
      "Epoch 24/30\n",
      "2253/2253 [==============================] - 1s 248us/step - loss: 1.7533 - acc: 0.3937 - val_loss: 2.0296 - val_acc: 0.3320\n",
      "Epoch 25/30\n",
      "2253/2253 [==============================] - 1s 247us/step - loss: 1.7414 - acc: 0.3995 - val_loss: 2.0053 - val_acc: 0.3373\n",
      "Epoch 26/30\n",
      "2253/2253 [==============================] - 1s 242us/step - loss: 1.7340 - acc: 0.4004 - val_loss: 2.0344 - val_acc: 0.3425\n",
      "Epoch 27/30\n",
      "2253/2253 [==============================] - 1s 266us/step - loss: 1.7267 - acc: 0.4048 - val_loss: 2.0658 - val_acc: 0.3373\n",
      "Epoch 28/30\n",
      "2253/2253 [==============================] - 1s 243us/step - loss: 1.7049 - acc: 0.4128 - val_loss: 2.0446 - val_acc: 0.3465\n",
      "Epoch 29/30\n",
      "2253/2253 [==============================] - 1s 242us/step - loss: 1.7003 - acc: 0.4239 - val_loss: 2.0372 - val_acc: 0.3399\n",
      "Epoch 30/30\n",
      "2253/2253 [==============================] - 1s 254us/step - loss: 1.6935 - acc: 0.4292 - val_loss: 2.1044 - val_acc: 0.3281\n",
      "762/762 [==============================] - 0s 66us/step\n",
      "Fold 2 :\n",
      "\n",
      "Train on 2261 samples, validate on 754 samples\n",
      "Epoch 1/30\n",
      "2261/2261 [==============================] - 1s 541us/step - loss: 2.2853 - acc: 0.1915 - val_loss: 2.1728 - val_acc: 0.2149\n",
      "Epoch 2/30\n",
      "2261/2261 [==============================] - 1s 252us/step - loss: 2.1953 - acc: 0.1924 - val_loss: 2.1733 - val_acc: 0.2149\n",
      "Epoch 3/30\n",
      "2261/2261 [==============================] - 1s 254us/step - loss: 2.1978 - acc: 0.2070 - val_loss: 2.1710 - val_acc: 0.1910\n",
      "Epoch 4/30\n",
      "2261/2261 [==============================] - 1s 264us/step - loss: 2.1871 - acc: 0.2008 - val_loss: 2.1741 - val_acc: 0.2149\n",
      "Epoch 5/30\n",
      "2261/2261 [==============================] - 1s 256us/step - loss: 2.1895 - acc: 0.1871 - val_loss: 2.1642 - val_acc: 0.1910\n",
      "Epoch 6/30\n",
      "2261/2261 [==============================] - 1s 280us/step - loss: 2.1852 - acc: 0.1959 - val_loss: 2.1615 - val_acc: 0.1910\n",
      "Epoch 7/30\n",
      "2261/2261 [==============================] - 1s 297us/step - loss: 2.1849 - acc: 0.1906 - val_loss: 2.1606 - val_acc: 0.1910\n",
      "Epoch 8/30\n",
      "2261/2261 [==============================] - 1s 301us/step - loss: 2.1751 - acc: 0.1964 - val_loss: 2.1578 - val_acc: 0.2149\n",
      "Epoch 9/30\n",
      "2261/2261 [==============================] - 1s 273us/step - loss: 2.1773 - acc: 0.1964 - val_loss: 2.1635 - val_acc: 0.2149\n",
      "Epoch 10/30\n",
      "2261/2261 [==============================] - 1s 241us/step - loss: 2.1703 - acc: 0.2017 - val_loss: 2.1661 - val_acc: 0.1910\n",
      "Epoch 11/30\n",
      "2261/2261 [==============================] - 1s 287us/step - loss: 2.1706 - acc: 0.2088 - val_loss: 2.1679 - val_acc: 0.2149\n",
      "Epoch 12/30\n",
      "2261/2261 [==============================] - 1s 242us/step - loss: 2.1740 - acc: 0.2034 - val_loss: 2.1577 - val_acc: 0.2149\n",
      "Epoch 13/30\n",
      "2261/2261 [==============================] - 1s 240us/step - loss: 2.1669 - acc: 0.2176 - val_loss: 2.1582 - val_acc: 0.2149\n",
      "Epoch 14/30\n",
      "2261/2261 [==============================] - 1s 235us/step - loss: 2.1641 - acc: 0.2083 - val_loss: 2.1564 - val_acc: 0.2149\n",
      "Epoch 15/30\n",
      "2261/2261 [==============================] - 1s 245us/step - loss: 2.1697 - acc: 0.2048 - val_loss: 2.1597 - val_acc: 0.2149\n",
      "Epoch 16/30\n",
      "2261/2261 [==============================] - 1s 235us/step - loss: 2.1678 - acc: 0.2039 - val_loss: 2.1573 - val_acc: 0.2149\n",
      "Epoch 17/30\n",
      "2261/2261 [==============================] - 1s 254us/step - loss: 2.1650 - acc: 0.2043 - val_loss: 2.1564 - val_acc: 0.2149\n",
      "Epoch 18/30\n",
      "2261/2261 [==============================] - 1s 275us/step - loss: 2.1609 - acc: 0.2052 - val_loss: 2.1609 - val_acc: 0.2149\n",
      "Epoch 19/30\n",
      "2261/2261 [==============================] - 1s 274us/step - loss: 2.1636 - acc: 0.2052 - val_loss: 2.1590 - val_acc: 0.2149\n",
      "Epoch 20/30\n",
      "2261/2261 [==============================] - 1s 270us/step - loss: 2.1586 - acc: 0.2105 - val_loss: 2.1660 - val_acc: 0.2149\n",
      "Epoch 21/30\n",
      "2261/2261 [==============================] - 1s 243us/step - loss: 2.1638 - acc: 0.2057 - val_loss: 2.1563 - val_acc: 0.2149\n",
      "Epoch 22/30\n",
      "2261/2261 [==============================] - 0s 215us/step - loss: 2.1645 - acc: 0.2039 - val_loss: 2.1562 - val_acc: 0.2149\n",
      "Epoch 23/30\n",
      "2261/2261 [==============================] - 1s 227us/step - loss: 2.1605 - acc: 0.2149 - val_loss: 2.1570 - val_acc: 0.2149\n",
      "Epoch 24/30\n",
      "2261/2261 [==============================] - 0s 208us/step - loss: 2.1631 - acc: 0.2083 - val_loss: 2.1581 - val_acc: 0.2149\n",
      "Epoch 25/30\n",
      "2261/2261 [==============================] - 1s 221us/step - loss: 2.1599 - acc: 0.2074 - val_loss: 2.1535 - val_acc: 0.2149\n",
      "Epoch 26/30\n",
      "2261/2261 [==============================] - 0s 219us/step - loss: 2.0943 - acc: 0.2813 - val_loss: 1.9691 - val_acc: 0.3501\n",
      "Epoch 27/30\n",
      "2261/2261 [==============================] - 0s 218us/step - loss: 1.9670 - acc: 0.3521 - val_loss: 1.8913 - val_acc: 0.3554\n",
      "Epoch 28/30\n",
      "2261/2261 [==============================] - 0s 210us/step - loss: 1.9085 - acc: 0.3605 - val_loss: 1.8409 - val_acc: 0.3952\n",
      "Epoch 29/30\n",
      "2261/2261 [==============================] - 0s 220us/step - loss: 1.8556 - acc: 0.3923 - val_loss: 1.8243 - val_acc: 0.3952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30\n",
      "2261/2261 [==============================] - 0s 215us/step - loss: 1.8188 - acc: 0.4011 - val_loss: 1.7957 - val_acc: 0.4085\n",
      "754/754 [==============================] - 0s 41us/step\n",
      "Fold 3 :\n",
      "\n",
      "Train on 2265 samples, validate on 750 samples\n",
      "Epoch 1/30\n",
      "2265/2265 [==============================] - 1s 562us/step - loss: 2.3037 - acc: 0.1921 - val_loss: 2.1621 - val_acc: 0.2160\n",
      "Epoch 2/30\n",
      "2265/2265 [==============================] - 1s 226us/step - loss: 2.2175 - acc: 0.1987 - val_loss: 2.1593 - val_acc: 0.1920\n",
      "Epoch 3/30\n",
      "2265/2265 [==============================] - 1s 224us/step - loss: 2.1974 - acc: 0.1969 - val_loss: 2.1646 - val_acc: 0.1920\n",
      "Epoch 4/30\n",
      "2265/2265 [==============================] - 1s 225us/step - loss: 2.1952 - acc: 0.1934 - val_loss: 2.1503 - val_acc: 0.2160\n",
      "Epoch 5/30\n",
      "2265/2265 [==============================] - 0s 217us/step - loss: 2.1978 - acc: 0.2102 - val_loss: 2.1578 - val_acc: 0.1520\n",
      "Epoch 6/30\n",
      "2265/2265 [==============================] - 1s 221us/step - loss: 2.1856 - acc: 0.2018 - val_loss: 2.1545 - val_acc: 0.1920\n",
      "Epoch 7/30\n",
      "2265/2265 [==============================] - 1s 258us/step - loss: 2.1864 - acc: 0.1943 - val_loss: 2.1581 - val_acc: 0.1920\n",
      "Epoch 8/30\n",
      "2265/2265 [==============================] - 1s 273us/step - loss: 2.1859 - acc: 0.1969 - val_loss: 2.1449 - val_acc: 0.2160\n",
      "Epoch 9/30\n",
      "2265/2265 [==============================] - 1s 298us/step - loss: 2.1920 - acc: 0.1828 - val_loss: 2.1496 - val_acc: 0.1920\n",
      "Epoch 10/30\n",
      "2265/2265 [==============================] - 1s 320us/step - loss: 2.1810 - acc: 0.1934 - val_loss: 2.1495 - val_acc: 0.2160\n",
      "Epoch 11/30\n",
      "2265/2265 [==============================] - 1s 285us/step - loss: 2.1766 - acc: 0.2141 - val_loss: 2.1457 - val_acc: 0.2160\n",
      "Epoch 12/30\n",
      "2265/2265 [==============================] - 1s 273us/step - loss: 2.1759 - acc: 0.1982 - val_loss: 2.1469 - val_acc: 0.2160\n",
      "Epoch 13/30\n",
      "2265/2265 [==============================] - 1s 289us/step - loss: 2.1732 - acc: 0.1916 - val_loss: 2.1491 - val_acc: 0.2160\n",
      "Epoch 14/30\n",
      "2265/2265 [==============================] - 1s 286us/step - loss: 2.1707 - acc: 0.2031 - val_loss: 2.1490 - val_acc: 0.2160\n",
      "Epoch 15/30\n",
      "2265/2265 [==============================] - 1s 272us/step - loss: 2.1731 - acc: 0.2084 - val_loss: 2.1454 - val_acc: 0.2160\n",
      "Epoch 16/30\n",
      "2265/2265 [==============================] - 1s 282us/step - loss: 2.1751 - acc: 0.2124 - val_loss: 2.1491 - val_acc: 0.1920\n",
      "Epoch 17/30\n",
      "2265/2265 [==============================] - 1s 283us/step - loss: 2.1713 - acc: 0.2040 - val_loss: 2.1451 - val_acc: 0.2160\n",
      "Epoch 18/30\n",
      "2265/2265 [==============================] - 1s 274us/step - loss: 2.1671 - acc: 0.2159 - val_loss: 2.1454 - val_acc: 0.1920\n",
      "Epoch 19/30\n",
      "2265/2265 [==============================] - 1s 289us/step - loss: 2.1707 - acc: 0.2066 - val_loss: 2.1427 - val_acc: 0.2160\n",
      "Epoch 20/30\n",
      "2265/2265 [==============================] - 1s 273us/step - loss: 2.1536 - acc: 0.2539 - val_loss: 2.0795 - val_acc: 0.3453\n",
      "Epoch 21/30\n",
      "2265/2265 [==============================] - 1s 283us/step - loss: 1.9936 - acc: 0.3660 - val_loss: 1.9692 - val_acc: 0.3480\n",
      "Epoch 22/30\n",
      "2265/2265 [==============================] - 1s 271us/step - loss: 1.8765 - acc: 0.3810 - val_loss: 1.9183 - val_acc: 0.3973\n",
      "Epoch 23/30\n",
      "2265/2265 [==============================] - 0s 214us/step - loss: 1.8093 - acc: 0.4278 - val_loss: 1.8924 - val_acc: 0.4160\n",
      "Epoch 24/30\n",
      "2265/2265 [==============================] - 1s 234us/step - loss: 1.7562 - acc: 0.4455 - val_loss: 1.9174 - val_acc: 0.3933\n",
      "Epoch 25/30\n",
      "2265/2265 [==============================] - 0s 216us/step - loss: 1.7200 - acc: 0.4539 - val_loss: 1.8768 - val_acc: 0.4187\n",
      "Epoch 26/30\n",
      "2265/2265 [==============================] - 0s 213us/step - loss: 1.6950 - acc: 0.4596 - val_loss: 1.8553 - val_acc: 0.4093\n",
      "Epoch 27/30\n",
      "2265/2265 [==============================] - 1s 228us/step - loss: 1.6725 - acc: 0.4627 - val_loss: 1.8759 - val_acc: 0.4067\n",
      "Epoch 28/30\n",
      "2265/2265 [==============================] - 1s 226us/step - loss: 1.6474 - acc: 0.4689 - val_loss: 1.8557 - val_acc: 0.4093\n",
      "Epoch 29/30\n",
      "2265/2265 [==============================] - 0s 219us/step - loss: 1.6305 - acc: 0.4693 - val_loss: 1.8759 - val_acc: 0.4120\n",
      "Epoch 30/30\n",
      "2265/2265 [==============================] - 1s 246us/step - loss: 1.6118 - acc: 0.4790 - val_loss: 1.8707 - val_acc: 0.4107\n",
      "750/750 [==============================] - 0s 51us/step\n",
      "Fold 4 :\n",
      "\n",
      "Train on 2266 samples, validate on 749 samples\n",
      "Epoch 1/30\n",
      "2266/2266 [==============================] - 2s 703us/step - loss: 2.3172 - acc: 0.1933 - val_loss: 2.1608 - val_acc: 0.2163\n",
      "Epoch 2/30\n",
      "2266/2266 [==============================] - 1s 243us/step - loss: 2.2120 - acc: 0.1911 - val_loss: 2.1755 - val_acc: 0.2163\n",
      "Epoch 3/30\n",
      "2266/2266 [==============================] - 1s 309us/step - loss: 2.1951 - acc: 0.2070 - val_loss: 2.1591 - val_acc: 0.2163\n",
      "Epoch 4/30\n",
      "2266/2266 [==============================] - 1s 268us/step - loss: 2.2063 - acc: 0.1942 - val_loss: 2.1542 - val_acc: 0.2163\n",
      "Epoch 5/30\n",
      "2266/2266 [==============================] - 1s 270us/step - loss: 2.1983 - acc: 0.1823 - val_loss: 2.1493 - val_acc: 0.1923\n",
      "Epoch 6/30\n",
      "2266/2266 [==============================] - 1s 239us/step - loss: 2.1837 - acc: 0.1977 - val_loss: 2.1471 - val_acc: 0.2163\n",
      "Epoch 7/30\n",
      "2266/2266 [==============================] - 1s 246us/step - loss: 2.1872 - acc: 0.2074 - val_loss: 2.1528 - val_acc: 0.2163\n",
      "Epoch 8/30\n",
      "2266/2266 [==============================] - 1s 244us/step - loss: 2.1831 - acc: 0.2043 - val_loss: 2.1492 - val_acc: 0.2163\n",
      "Epoch 9/30\n",
      "2266/2266 [==============================] - 1s 246us/step - loss: 2.1833 - acc: 0.1986 - val_loss: 2.1459 - val_acc: 0.2163\n",
      "Epoch 10/30\n",
      "2266/2266 [==============================] - 1s 249us/step - loss: 2.1760 - acc: 0.2039 - val_loss: 2.1467 - val_acc: 0.1923\n",
      "Epoch 11/30\n",
      "2266/2266 [==============================] - 1s 250us/step - loss: 2.1786 - acc: 0.2056 - val_loss: 2.1478 - val_acc: 0.2163\n",
      "Epoch 12/30\n",
      "2266/2266 [==============================] - 1s 267us/step - loss: 2.1769 - acc: 0.2004 - val_loss: 2.1450 - val_acc: 0.2163\n",
      "Epoch 13/30\n",
      "2266/2266 [==============================] - 1s 288us/step - loss: 2.1680 - acc: 0.2092 - val_loss: 2.1516 - val_acc: 0.2163\n",
      "Epoch 14/30\n",
      "2266/2266 [==============================] - 1s 249us/step - loss: 2.1719 - acc: 0.2030 - val_loss: 2.1436 - val_acc: 0.2163\n",
      "Epoch 15/30\n",
      "2266/2266 [==============================] - 1s 262us/step - loss: 2.1718 - acc: 0.2180 - val_loss: 2.1436 - val_acc: 0.2163\n",
      "Epoch 16/30\n",
      "2266/2266 [==============================] - 1s 255us/step - loss: 2.1670 - acc: 0.2074 - val_loss: 2.1476 - val_acc: 0.1923\n",
      "Epoch 17/30\n",
      "2266/2266 [==============================] - 1s 246us/step - loss: 2.1691 - acc: 0.2092 - val_loss: 2.1427 - val_acc: 0.2163\n",
      "Epoch 18/30\n",
      "2266/2266 [==============================] - 1s 257us/step - loss: 2.1615 - acc: 0.2215 - val_loss: 2.1558 - val_acc: 0.2163\n",
      "Epoch 19/30\n",
      "2266/2266 [==============================] - 1s 246us/step - loss: 2.1720 - acc: 0.2092 - val_loss: 2.1441 - val_acc: 0.2163\n",
      "Epoch 20/30\n",
      "2266/2266 [==============================] - 1s 245us/step - loss: 2.1650 - acc: 0.1951 - val_loss: 2.1421 - val_acc: 0.2163\n",
      "Epoch 21/30\n",
      "2266/2266 [==============================] - 1s 254us/step - loss: 2.1658 - acc: 0.2056 - val_loss: 2.1463 - val_acc: 0.2163\n",
      "Epoch 22/30\n",
      "2266/2266 [==============================] - 1s 298us/step - loss: 2.1646 - acc: 0.2149 - val_loss: 2.1418 - val_acc: 0.2163\n",
      "Epoch 23/30\n",
      "2266/2266 [==============================] - 1s 277us/step - loss: 2.0898 - acc: 0.3080 - val_loss: 1.9494 - val_acc: 0.3725\n",
      "Epoch 24/30\n",
      "2266/2266 [==============================] - 1s 228us/step - loss: 1.9255 - acc: 0.3641 - val_loss: 1.9331 - val_acc: 0.3672\n",
      "Epoch 25/30\n",
      "2266/2266 [==============================] - 0s 219us/step - loss: 1.8518 - acc: 0.3976 - val_loss: 1.9130 - val_acc: 0.4126\n",
      "Epoch 26/30\n",
      "2266/2266 [==============================] - 1s 221us/step - loss: 1.7793 - acc: 0.4360 - val_loss: 1.8638 - val_acc: 0.4099\n",
      "Epoch 27/30\n",
      "2266/2266 [==============================] - 1s 229us/step - loss: 1.7400 - acc: 0.4541 - val_loss: 1.8772 - val_acc: 0.4232\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2266/2266 [==============================] - 1s 221us/step - loss: 1.7152 - acc: 0.4598 - val_loss: 1.8615 - val_acc: 0.4326\n",
      "Epoch 29/30\n",
      "2266/2266 [==============================] - 1s 225us/step - loss: 1.6860 - acc: 0.4656 - val_loss: 1.8694 - val_acc: 0.4206\n",
      "Epoch 30/30\n",
      "2266/2266 [==============================] - 1s 227us/step - loss: 1.6760 - acc: 0.4691 - val_loss: 1.8772 - val_acc: 0.4246\n",
      "749/749 [==============================] - 0s 49us/step\n"
     ]
    }
   ],
   "source": [
    "#k=4\n",
    "kf = StratifiedKFold(n_splits=4, random_state=None, shuffle=False)\n",
    "val_loss_cv = []\n",
    "val_acc_cv = []\n",
    "j = 0\n",
    "for train_index, test_index in kf.split(X,y):\n",
    "    j+=1\n",
    "    print(f\"Fold {j} :\")\n",
    "    print(\"\")\n",
    "    X_train,X_test = X[train_index],X[test_index]\n",
    "    y_train,y_test = y[train_index],y[test_index]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim=X_train.shape[1], units=128,\n",
    "                     kernel_initializer='normal', bias_initializer='zeros'))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    for i in range(0, 6):\n",
    "        model.add(Dense(units=128, kernel_initializer='normal',\n",
    "                         bias_initializer='zeros'))\n",
    "        model.add(Activation('sigmoid'))\n",
    "        model.add(Dropout(.15))\n",
    "\n",
    "    model.add(Dense(units=19))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train,batch_size=24,epochs=30,verbose=1,validation_data=(X_test, y_test))\n",
    "    score = model.evaluate(X_test, y_test, verbose=1)\n",
    "    val_loss_cv.append(score[0])\n",
    "    val_acc_cv.append(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss_cv : [2.1043934928463512, 1.7956512183030024, 1.870691115697225, 1.8771900522692977]\n",
      "mean_val_loss_cv : 1.9119814697789692\n",
      "val_acc_cv : [0.32808398950131235, 0.40848806366047746, 0.41066666690508524, 0.42456608811748997]\n",
      "mean_val_acc_cv : 0.3929512020460913\n"
     ]
    }
   ],
   "source": [
    "print(f\"val_loss_cv : {val_loss_cv}\")\n",
    "print(f\"mean_val_loss_cv : {np.mean(val_loss_cv)}\")\n",
    "print(f\"val_acc_cv : {val_acc_cv}\")\n",
    "print(f\"mean_val_acc_cv : {np.mean(val_acc_cv)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
