{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#masukin data1\n",
    "data1=pandas.read_csv('D:\\\\SKRIPSI\\\\data\\\\data_praproses\\\\jamu_herbs.csv', sep=',')\n",
    "#masukin data2\n",
    "data2=pandas.read_csv('D:\\\\SKRIPSI\\\\data\\\\data_praproses\\\\jamu_class.csv', sep=',')\n",
    "data_1 = data1.drop('IDJamu',axis=1)\n",
    "data_2 = data2.drop('Jamu ID',axis=1)\n",
    "data_1['Kelas']=data_2['Class of Diseases']\n",
    "X = data_1.drop('Kelas', axis=1).values\n",
    "y = data_1['Kelas'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=4.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 :\n",
      "\n",
      "Train on 2253 samples, validate on 762 samples\n",
      "Epoch 1/30\n",
      "2253/2253 [==============================] - 1s 493us/step - loss: 2.3386 - acc: 0.2086 - val_loss: 2.1110 - val_acc: 0.2139\n",
      "Epoch 2/30\n",
      "2253/2253 [==============================] - 1s 237us/step - loss: 2.0422 - acc: 0.2481 - val_loss: 2.0441 - val_acc: 0.2205\n",
      "Epoch 3/30\n",
      "2253/2253 [==============================] - 1s 253us/step - loss: 1.8460 - acc: 0.3373 - val_loss: 1.9476 - val_acc: 0.3346\n",
      "Epoch 4/30\n",
      "2253/2253 [==============================] - 1s 247us/step - loss: 1.6061 - acc: 0.4296 - val_loss: 1.7436 - val_acc: 0.4396\n",
      "Epoch 5/30\n",
      "2253/2253 [==============================] - 0s 209us/step - loss: 1.3727 - acc: 0.5411 - val_loss: 2.2140 - val_acc: 0.3360\n",
      "Epoch 6/30\n",
      "2253/2253 [==============================] - 0s 209us/step - loss: 1.1659 - acc: 0.6298 - val_loss: 1.8534 - val_acc: 0.4738\n",
      "Epoch 7/30\n",
      "2253/2253 [==============================] - 0s 200us/step - loss: 1.0330 - acc: 0.6724 - val_loss: 1.8514 - val_acc: 0.4357\n",
      "Epoch 8/30\n",
      "2253/2253 [==============================] - 0s 201us/step - loss: 0.9121 - acc: 0.7102 - val_loss: 2.4168 - val_acc: 0.4383\n",
      "Epoch 9/30\n",
      "2253/2253 [==============================] - 1s 236us/step - loss: 0.8547 - acc: 0.7301 - val_loss: 2.2289 - val_acc: 0.4646\n",
      "Epoch 10/30\n",
      "2253/2253 [==============================] - 1s 229us/step - loss: 0.7925 - acc: 0.7492 - val_loss: 2.2554 - val_acc: 0.4344\n",
      "Epoch 11/30\n",
      "2253/2253 [==============================] - 1s 236us/step - loss: 0.7027 - acc: 0.7861 - val_loss: 2.4676 - val_acc: 0.4580\n",
      "Epoch 12/30\n",
      "2253/2253 [==============================] - 1s 236us/step - loss: 0.6536 - acc: 0.8060 - val_loss: 2.5125 - val_acc: 0.4777\n",
      "Epoch 13/30\n",
      "2253/2253 [==============================] - 1s 239us/step - loss: 0.6083 - acc: 0.8114 - val_loss: 2.5729 - val_acc: 0.4462\n",
      "Epoch 14/30\n",
      "2253/2253 [==============================] - 1s 245us/step - loss: 0.5672 - acc: 0.8211 - val_loss: 2.6980 - val_acc: 0.4593\n",
      "Epoch 15/30\n",
      "2253/2253 [==============================] - 1s 252us/step - loss: 0.5027 - acc: 0.8464 - val_loss: 2.7955 - val_acc: 0.4790\n",
      "Epoch 16/30\n",
      "2253/2253 [==============================] - 1s 265us/step - loss: 0.5166 - acc: 0.8384 - val_loss: 3.0079 - val_acc: 0.4619\n",
      "Epoch 17/30\n",
      "2253/2253 [==============================] - 1s 261us/step - loss: 0.4746 - acc: 0.8566 - val_loss: 3.1758 - val_acc: 0.4514\n",
      "Epoch 18/30\n",
      "2253/2253 [==============================] - 1s 237us/step - loss: 0.4053 - acc: 0.8739 - val_loss: 3.4321 - val_acc: 0.4475\n",
      "Epoch 19/30\n",
      "2253/2253 [==============================] - 1s 235us/step - loss: 0.4465 - acc: 0.8544 - val_loss: 3.3272 - val_acc: 0.4501\n",
      "Epoch 20/30\n",
      "2253/2253 [==============================] - 1s 244us/step - loss: 0.4177 - acc: 0.8713 - val_loss: 3.0907 - val_acc: 0.4724\n",
      "Epoch 21/30\n",
      "2253/2253 [==============================] - 1s 261us/step - loss: 0.4099 - acc: 0.8779 - val_loss: 3.0423 - val_acc: 0.4711\n",
      "Epoch 22/30\n",
      "2253/2253 [==============================] - 1s 270us/step - loss: 0.3962 - acc: 0.8748 - val_loss: 3.0917 - val_acc: 0.4501\n",
      "Epoch 23/30\n",
      "2253/2253 [==============================] - 1s 253us/step - loss: 0.3706 - acc: 0.8895 - val_loss: 3.4714 - val_acc: 0.4331\n",
      "Epoch 24/30\n",
      "2253/2253 [==============================] - 1s 260us/step - loss: 0.3596 - acc: 0.8939 - val_loss: 3.1956 - val_acc: 0.4646\n",
      "Epoch 25/30\n",
      "2253/2253 [==============================] - 1s 269us/step - loss: 0.3629 - acc: 0.8988 - val_loss: 3.6124 - val_acc: 0.4606\n",
      "Epoch 26/30\n",
      "2253/2253 [==============================] - 1s 322us/step - loss: 0.3226 - acc: 0.9019 - val_loss: 3.6275 - val_acc: 0.4659\n",
      "Epoch 27/30\n",
      "2253/2253 [==============================] - 1s 286us/step - loss: 0.3041 - acc: 0.9081 - val_loss: 3.4931 - val_acc: 0.4790\n",
      "Epoch 28/30\n",
      "2253/2253 [==============================] - 1s 279us/step - loss: 0.3525 - acc: 0.8904 - val_loss: 3.5683 - val_acc: 0.4567\n",
      "Epoch 29/30\n",
      "2253/2253 [==============================] - 1s 252us/step - loss: 0.3038 - acc: 0.9117 - val_loss: 3.5718 - val_acc: 0.4659\n",
      "Epoch 30/30\n",
      "2253/2253 [==============================] - ETA: 0s - loss: 0.2683 - acc: 0.927 - 1s 243us/step - loss: 0.2674 - acc: 0.9285 - val_loss: 4.0866 - val_acc: 0.4423\n",
      "762/762 [==============================] - 0s 49us/step\n",
      "Fold 2 :\n",
      "\n",
      "Train on 2261 samples, validate on 754 samples\n",
      "Epoch 1/30\n",
      "2261/2261 [==============================] - 2s 1ms/step - loss: 2.3049 - acc: 0.2061 - val_loss: 2.0939 - val_acc: 0.2149\n",
      "Epoch 2/30\n",
      "2261/2261 [==============================] - 1s 340us/step - loss: 2.0360 - acc: 0.2238 - val_loss: 2.0403 - val_acc: 0.3236\n",
      "Epoch 3/30\n",
      "2261/2261 [==============================] - 1s 341us/step - loss: 1.7866 - acc: 0.3636 - val_loss: 1.7967 - val_acc: 0.3607\n",
      "Epoch 4/30\n",
      "2261/2261 [==============================] - 1s 339us/step - loss: 1.5698 - acc: 0.4640 - val_loss: 1.6984 - val_acc: 0.4642\n",
      "Epoch 5/30\n",
      "2261/2261 [==============================] - 1s 339us/step - loss: 1.3746 - acc: 0.5303 - val_loss: 1.6579 - val_acc: 0.4469\n",
      "Epoch 6/30\n",
      "2261/2261 [==============================] - 1s 341us/step - loss: 1.2099 - acc: 0.5931 - val_loss: 1.7015 - val_acc: 0.5000\n",
      "Epoch 7/30\n",
      "2261/2261 [==============================] - 1s 335us/step - loss: 1.0806 - acc: 0.6183 - val_loss: 1.8058 - val_acc: 0.5199\n",
      "Epoch 8/30\n",
      "2261/2261 [==============================] - 1s 326us/step - loss: 0.9935 - acc: 0.6541 - val_loss: 1.8570 - val_acc: 0.5239\n",
      "Epoch 9/30\n",
      "2261/2261 [==============================] - 1s 327us/step - loss: 0.8880 - acc: 0.7006 - val_loss: 1.8225 - val_acc: 0.5557\n",
      "Epoch 10/30\n",
      "2261/2261 [==============================] - 1s 341us/step - loss: 0.8143 - acc: 0.7497 - val_loss: 1.9464 - val_acc: 0.5265\n",
      "Epoch 11/30\n",
      "2261/2261 [==============================] - 1s 340us/step - loss: 0.7171 - acc: 0.7775 - val_loss: 2.0825 - val_acc: 0.5451\n",
      "Epoch 12/30\n",
      "2261/2261 [==============================] - 1s 326us/step - loss: 0.6620 - acc: 0.7992 - val_loss: 2.0153 - val_acc: 0.5663\n",
      "Epoch 13/30\n",
      "2261/2261 [==============================] - 1s 333us/step - loss: 0.5961 - acc: 0.8235 - val_loss: 2.0015 - val_acc: 0.5822\n",
      "Epoch 14/30\n",
      "2261/2261 [==============================] - 1s 366us/step - loss: 0.5308 - acc: 0.8479 - val_loss: 2.1371 - val_acc: 0.5716\n",
      "Epoch 15/30\n",
      "2261/2261 [==============================] - 1s 398us/step - loss: 0.4958 - acc: 0.8536 - val_loss: 2.1806 - val_acc: 0.5769\n",
      "Epoch 16/30\n",
      "2261/2261 [==============================] - 1s 420us/step - loss: 0.4773 - acc: 0.8594 - val_loss: 2.1982 - val_acc: 0.5836\n",
      "Epoch 17/30\n",
      "2261/2261 [==============================] - 1s 388us/step - loss: 0.4509 - acc: 0.8638 - val_loss: 2.5099 - val_acc: 0.5491\n",
      "Epoch 18/30\n",
      "2261/2261 [==============================] - 1s 418us/step - loss: 0.4232 - acc: 0.8748 - val_loss: 2.2477 - val_acc: 0.5703\n",
      "Epoch 19/30\n",
      "2261/2261 [==============================] - 1s 386us/step - loss: 0.4219 - acc: 0.8784 - val_loss: 2.4421 - val_acc: 0.5756\n",
      "Epoch 20/30\n",
      "2261/2261 [==============================] - 1s 374us/step - loss: 0.3937 - acc: 0.8872 - val_loss: 2.3332 - val_acc: 0.5716\n",
      "Epoch 21/30\n",
      "2261/2261 [==============================] - 1s 341us/step - loss: 0.3537 - acc: 0.8947 - val_loss: 2.4674 - val_acc: 0.5769\n",
      "Epoch 22/30\n",
      "2261/2261 [==============================] - 1s 355us/step - loss: 0.3176 - acc: 0.9080 - val_loss: 2.7187 - val_acc: 0.5623\n",
      "Epoch 23/30\n",
      "2261/2261 [==============================] - 1s 425us/step - loss: 0.3365 - acc: 0.9000 - val_loss: 2.6564 - val_acc: 0.5716\n",
      "Epoch 24/30\n",
      "2261/2261 [==============================] - 1s 374us/step - loss: 0.2945 - acc: 0.9195 - val_loss: 2.7659 - val_acc: 0.5729\n",
      "Epoch 25/30\n",
      "2261/2261 [==============================] - 1s 370us/step - loss: 0.2891 - acc: 0.9098 - val_loss: 2.8304 - val_acc: 0.5756\n",
      "Epoch 26/30\n",
      "2261/2261 [==============================] - 1s 365us/step - loss: 0.2838 - acc: 0.9160 - val_loss: 2.7667 - val_acc: 0.5690\n",
      "Epoch 27/30\n",
      "2261/2261 [==============================] - 1s 353us/step - loss: 0.2928 - acc: 0.9098 - val_loss: 2.8494 - val_acc: 0.5902\n",
      "Epoch 28/30\n",
      "2261/2261 [==============================] - 1s 335us/step - loss: 0.2856 - acc: 0.9217 - val_loss: 2.6411 - val_acc: 0.5849\n",
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2261/2261 [==============================] - 1s 347us/step - loss: 0.2680 - acc: 0.9199 - val_loss: 2.6978 - val_acc: 0.5782\n",
      "Epoch 30/30\n",
      "2261/2261 [==============================] - 1s 275us/step - loss: 0.2441 - acc: 0.9292 - val_loss: 2.8113 - val_acc: 0.5769\n",
      "754/754 [==============================] - 0s 71us/step\n",
      "Fold 3 :\n",
      "\n",
      "Train on 2265 samples, validate on 750 samples\n",
      "Epoch 1/30\n",
      "2265/2265 [==============================] - 5s 2ms/step - loss: 2.3473 - acc: 0.2088 - val_loss: 2.1196 - val_acc: 0.1920\n",
      "Epoch 2/30\n",
      "2265/2265 [==============================] - 1s 629us/step - loss: 2.0749 - acc: 0.2075 - val_loss: 2.0601 - val_acc: 0.2227\n",
      "Epoch 3/30\n",
      "2265/2265 [==============================] - 1s 551us/step - loss: 1.9671 - acc: 0.2296 - val_loss: 1.9713 - val_acc: 0.3240\n",
      "Epoch 4/30\n",
      "2265/2265 [==============================] - 1s 519us/step - loss: 1.6803 - acc: 0.4185 - val_loss: 1.8510 - val_acc: 0.3920\n",
      "Epoch 5/30\n",
      "2265/2265 [==============================] - 1s 530us/step - loss: 1.4143 - acc: 0.5139 - val_loss: 1.7800 - val_acc: 0.4467\n",
      "Epoch 6/30\n",
      "2265/2265 [==============================] - 1s 493us/step - loss: 1.2598 - acc: 0.5828 - val_loss: 1.8044 - val_acc: 0.4720\n",
      "Epoch 7/30\n",
      "2265/2265 [==============================] - 1s 493us/step - loss: 1.0842 - acc: 0.6446 - val_loss: 1.7637 - val_acc: 0.5040\n",
      "Epoch 8/30\n",
      "2265/2265 [==============================] - 1s 488us/step - loss: 0.9479 - acc: 0.7002 - val_loss: 1.9012 - val_acc: 0.5333\n",
      "Epoch 9/30\n",
      "2265/2265 [==============================] - 1s 491us/step - loss: 0.8833 - acc: 0.7294 - val_loss: 1.8927 - val_acc: 0.5133\n",
      "Epoch 10/30\n",
      "2265/2265 [==============================] - 1s 530us/step - loss: 0.7820 - acc: 0.7585 - val_loss: 1.9721 - val_acc: 0.5227\n",
      "Epoch 11/30\n",
      "2265/2265 [==============================] - 1s 552us/step - loss: 0.7251 - acc: 0.7753 - val_loss: 2.0328 - val_acc: 0.5147\n",
      "Epoch 12/30\n",
      "2265/2265 [==============================] - 1s 550us/step - loss: 0.6538 - acc: 0.7947 - val_loss: 2.2098 - val_acc: 0.5213\n",
      "Epoch 13/30\n",
      "2265/2265 [==============================] - 1s 596us/step - loss: 0.6439 - acc: 0.7974 - val_loss: 2.4398 - val_acc: 0.5160\n",
      "Epoch 14/30\n",
      "2265/2265 [==============================] - 1s 513us/step - loss: 0.5869 - acc: 0.8212 - val_loss: 2.3522 - val_acc: 0.5213\n",
      "Epoch 15/30\n",
      "2265/2265 [==============================] - 1s 550us/step - loss: 0.5532 - acc: 0.8283 - val_loss: 2.5522 - val_acc: 0.5387\n",
      "Epoch 16/30\n",
      "2265/2265 [==============================] - 1s 494us/step - loss: 0.5106 - acc: 0.8358 - val_loss: 2.5644 - val_acc: 0.5213\n",
      "Epoch 17/30\n",
      "2265/2265 [==============================] - 1s 477us/step - loss: 0.5067 - acc: 0.8406 - val_loss: 2.7396 - val_acc: 0.5360\n",
      "Epoch 18/30\n",
      "2265/2265 [==============================] - 1s 482us/step - loss: 0.4911 - acc: 0.8428 - val_loss: 2.6221 - val_acc: 0.5400\n",
      "Epoch 19/30\n",
      "2265/2265 [==============================] - 1s 505us/step - loss: 0.4474 - acc: 0.8680 - val_loss: 2.7654 - val_acc: 0.5480\n",
      "Epoch 20/30\n",
      "2265/2265 [==============================] - 1s 501us/step - loss: 0.4120 - acc: 0.8706 - val_loss: 2.9679 - val_acc: 0.5347\n",
      "Epoch 21/30\n",
      "2265/2265 [==============================] - 1s 489us/step - loss: 0.4084 - acc: 0.8728 - val_loss: 2.8953 - val_acc: 0.5467\n",
      "Epoch 22/30\n",
      "2265/2265 [==============================] - 1s 577us/step - loss: 0.3591 - acc: 0.8896 - val_loss: 3.0914 - val_acc: 0.5613\n",
      "Epoch 23/30\n",
      "2265/2265 [==============================] - 1s 560us/step - loss: 0.3705 - acc: 0.8852 - val_loss: 2.8888 - val_acc: 0.5480\n",
      "Epoch 24/30\n",
      "2265/2265 [==============================] - 1s 595us/step - loss: 0.3226 - acc: 0.8998 - val_loss: 3.3120 - val_acc: 0.5347\n",
      "Epoch 25/30\n",
      "2265/2265 [==============================] - 1s 486us/step - loss: 0.3137 - acc: 0.9068 - val_loss: 3.2275 - val_acc: 0.5293\n",
      "Epoch 26/30\n",
      "2265/2265 [==============================] - 1s 455us/step - loss: 0.3663 - acc: 0.8848 - val_loss: 3.2835 - val_acc: 0.5333\n",
      "Epoch 27/30\n",
      "2265/2265 [==============================] - 1s 476us/step - loss: 0.3290 - acc: 0.9007 - val_loss: 3.4439 - val_acc: 0.5707\n",
      "Epoch 28/30\n",
      "2265/2265 [==============================] - 1s 402us/step - loss: 0.3653 - acc: 0.8883 - val_loss: 2.8738 - val_acc: 0.5413\n",
      "Epoch 29/30\n",
      "2265/2265 [==============================] - 1s 415us/step - loss: 0.3376 - acc: 0.8945 - val_loss: 3.4074 - val_acc: 0.5373\n",
      "Epoch 30/30\n",
      "2265/2265 [==============================] - 1s 318us/step - loss: 0.3118 - acc: 0.9077 - val_loss: 3.3940 - val_acc: 0.5267\n",
      "750/750 [==============================] - 0s 78us/step\n",
      "Fold 4 :\n",
      "\n",
      "Train on 2266 samples, validate on 749 samples\n",
      "Epoch 1/30\n",
      "2266/2266 [==============================] - 9s 4ms/step - loss: 2.2924 - acc: 0.2034 - val_loss: 2.0836 - val_acc: 0.2216\n",
      "Epoch 2/30\n",
      "2266/2266 [==============================] - 1s 544us/step - loss: 2.0366 - acc: 0.2176 - val_loss: 1.9783 - val_acc: 0.2457\n",
      "Epoch 3/30\n",
      "2266/2266 [==============================] - 1s 620us/step - loss: 1.7996 - acc: 0.3561 - val_loss: 1.7536 - val_acc: 0.4259\n",
      "Epoch 4/30\n",
      "2266/2266 [==============================] - 2s 666us/step - loss: 1.5136 - acc: 0.4744 - val_loss: 1.6853 - val_acc: 0.4806\n",
      "Epoch 5/30\n",
      "2266/2266 [==============================] - 1s 622us/step - loss: 1.3091 - acc: 0.5649 - val_loss: 1.6809 - val_acc: 0.4913\n",
      "Epoch 6/30\n",
      "2266/2266 [==============================] - 1s 547us/step - loss: 1.1738 - acc: 0.6165 - val_loss: 1.7032 - val_acc: 0.5274\n",
      "Epoch 7/30\n",
      "2266/2266 [==============================] - 1s 522us/step - loss: 1.0439 - acc: 0.6633 - val_loss: 1.8230 - val_acc: 0.5487\n",
      "Epoch 8/30\n",
      "2266/2266 [==============================] - 1s 598us/step - loss: 0.9384 - acc: 0.6937 - val_loss: 1.7721 - val_acc: 0.5581\n",
      "Epoch 9/30\n",
      "2266/2266 [==============================] - ETA: 0s - loss: 0.8332 - acc: 0.737 - 1s 559us/step - loss: 0.8350 - acc: 0.7370 - val_loss: 1.9649 - val_acc: 0.5741\n",
      "Epoch 10/30\n",
      "2266/2266 [==============================] - 1s 557us/step - loss: 0.7872 - acc: 0.7467 - val_loss: 2.0578 - val_acc: 0.5554\n",
      "Epoch 11/30\n",
      "2266/2266 [==============================] - 1s 549us/step - loss: 0.7078 - acc: 0.7652 - val_loss: 2.1023 - val_acc: 0.5607\n",
      "Epoch 12/30\n",
      "2266/2266 [==============================] - 1s 547us/step - loss: 0.6588 - acc: 0.7838 - val_loss: 2.0697 - val_acc: 0.5300\n",
      "Epoch 13/30\n",
      "2266/2266 [==============================] - 1s 500us/step - loss: 0.6071 - acc: 0.8049 - val_loss: 2.1668 - val_acc: 0.5688\n",
      "Epoch 14/30\n",
      "2266/2266 [==============================] - 1s 527us/step - loss: 0.5570 - acc: 0.8116 - val_loss: 2.3723 - val_acc: 0.5434\n",
      "Epoch 15/30\n",
      "2266/2266 [==============================] - 1s 522us/step - loss: 0.5291 - acc: 0.8297 - val_loss: 2.5079 - val_acc: 0.5487\n",
      "Epoch 16/30\n",
      "2266/2266 [==============================] - 1s 510us/step - loss: 0.5275 - acc: 0.8411 - val_loss: 2.2353 - val_acc: 0.5514\n",
      "Epoch 17/30\n",
      "2266/2266 [==============================] - 1s 521us/step - loss: 0.4953 - acc: 0.8500 - val_loss: 2.6742 - val_acc: 0.5434\n",
      "Epoch 18/30\n",
      "2266/2266 [==============================] - 1s 497us/step - loss: 0.4442 - acc: 0.8583 - val_loss: 2.5515 - val_acc: 0.5247\n",
      "Epoch 19/30\n",
      "2266/2266 [==============================] - 1s 511us/step - loss: 0.4791 - acc: 0.8504 - val_loss: 2.6071 - val_acc: 0.5220\n",
      "Epoch 20/30\n",
      "2266/2266 [==============================] - 1s 491us/step - loss: 0.4286 - acc: 0.8628 - val_loss: 2.8379 - val_acc: 0.5113\n",
      "Epoch 21/30\n",
      "2266/2266 [==============================] - 1s 365us/step - loss: 0.3868 - acc: 0.8729 - val_loss: 2.8732 - val_acc: 0.5354\n",
      "Epoch 22/30\n",
      "2266/2266 [==============================] - 1s 331us/step - loss: 0.3573 - acc: 0.8959 - val_loss: 2.9823 - val_acc: 0.5381\n",
      "Epoch 23/30\n",
      "2266/2266 [==============================] - 1s 291us/step - loss: 0.3329 - acc: 0.9007 - val_loss: 2.7468 - val_acc: 0.5381\n",
      "Epoch 24/30\n",
      "2266/2266 [==============================] - 1s 301us/step - loss: 0.3419 - acc: 0.8950 - val_loss: 2.9185 - val_acc: 0.5434\n",
      "Epoch 25/30\n",
      "2266/2266 [==============================] - 1s 300us/step - loss: 0.3234 - acc: 0.8981 - val_loss: 2.9836 - val_acc: 0.5354\n",
      "Epoch 26/30\n",
      "2266/2266 [==============================] - 1s 282us/step - loss: 0.3228 - acc: 0.8963 - val_loss: 2.9792 - val_acc: 0.5541\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2266/2266 [==============================] - 1s 294us/step - loss: 0.2908 - acc: 0.9122 - val_loss: 2.9527 - val_acc: 0.5714\n",
      "Epoch 28/30\n",
      "2266/2266 [==============================] - 1s 288us/step - loss: 0.2813 - acc: 0.9122 - val_loss: 3.2447 - val_acc: 0.5527\n",
      "Epoch 29/30\n",
      "2266/2266 [==============================] - 1s 303us/step - loss: 0.2744 - acc: 0.9197 - val_loss: 3.1471 - val_acc: 0.5567\n",
      "Epoch 30/30\n",
      "2266/2266 [==============================] - 1s 294us/step - loss: 0.2623 - acc: 0.9298 - val_loss: 3.0580 - val_acc: 0.5461\n",
      "749/749 [==============================] - 0s 68us/step\n"
     ]
    }
   ],
   "source": [
    "#k=4\n",
    "kf = StratifiedKFold(n_splits=4, random_state=None, shuffle=False)\n",
    "val_loss_cv = []\n",
    "val_acc_cv = []\n",
    "j = 0\n",
    "for train_index, test_index in kf.split(X,y):\n",
    "    j+=1\n",
    "    print(f\"Fold {j} :\")\n",
    "    print(\"\")\n",
    "    X_train,X_test = X[train_index],X[test_index]\n",
    "    y_train,y_test = y[train_index],y[test_index]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim=X_train.shape[1], units=128,\n",
    "                     kernel_initializer='normal', bias_initializer='zeros'))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    for i in range(0, 6):\n",
    "        model.add(Dense(units=128, kernel_initializer='normal',\n",
    "                         bias_initializer='zeros'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(.15))\n",
    "\n",
    "    model.add(Dense(units=19))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train,batch_size=24,epochs=30,verbose=1,validation_data=(X_test, y_test))\n",
    "    score = model.evaluate(X_test, y_test, verbose=1)\n",
    "    val_loss_cv.append(score[0])\n",
    "    val_acc_cv.append(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss_cv : [4.086567832416124, 2.8113387522710096, 3.3939822737375893, 3.0579759963204927]\n",
      "mean_val_loss_cv : 3.3374662136863043\n",
      "val_acc_cv : [0.442257217965101, 0.5769230770021282, 0.5266666669845581, 0.5460614152401885]\n",
      "mean_val_acc_cv : 0.522977094297994\n"
     ]
    }
   ],
   "source": [
    "print(f\"val_loss_cv : {val_loss_cv}\")\n",
    "print(f\"mean_val_loss_cv : {np.mean(val_loss_cv)}\")\n",
    "print(f\"val_acc_cv : {val_acc_cv}\")\n",
    "print(f\"mean_val_acc_cv : {np.mean(val_acc_cv)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
