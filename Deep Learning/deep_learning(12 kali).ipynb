{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#masukin data1\n",
    "data1=pandas.read_csv('D:\\\\SKRIPSI\\\\data\\\\data_praproses\\\\jamu_herbs.csv', sep=',')\n",
    "#masukin data2\n",
    "data2=pandas.read_csv('D:\\\\SKRIPSI\\\\data\\\\data_praproses\\\\jamu_class.csv', sep=',')\n",
    "data_1 = data1.drop('IDJamu',axis=1)\n",
    "data_2 = data2.drop('Jamu ID',axis=1)\n",
    "data_1['Kelas']=data_2['Class of Diseases']\n",
    "X = data_1.drop('Kelas', axis=1).values\n",
    "y = data_1['Kelas'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=4.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 :\n",
      "\n",
      "Train on 2253 samples, validate on 762 samples\n",
      "Epoch 1/30\n",
      "2253/2253 [==============================] - 2s 971us/step - loss: 2.3095 - acc: 0.1922 - val_loss: 2.1172 - val_acc: 0.2139\n",
      "Epoch 2/30\n",
      "2253/2253 [==============================] - 1s 325us/step - loss: 2.0170 - acc: 0.2645 - val_loss: 1.9543 - val_acc: 0.3320\n",
      "Epoch 3/30\n",
      "2253/2253 [==============================] - 1s 325us/step - loss: 1.7795 - acc: 0.3697 - val_loss: 1.9791 - val_acc: 0.4003\n",
      "Epoch 4/30\n",
      "2253/2253 [==============================] - 1s 452us/step - loss: 1.5343 - acc: 0.4802 - val_loss: 1.8303 - val_acc: 0.4239\n",
      "Epoch 5/30\n",
      "2253/2253 [==============================] - 1s 390us/step - loss: 1.2732 - acc: 0.5925 - val_loss: 1.7794 - val_acc: 0.4449\n",
      "Epoch 6/30\n",
      "2253/2253 [==============================] - 1s 622us/step - loss: 1.0661 - acc: 0.6693 - val_loss: 1.7939 - val_acc: 0.4908\n",
      "Epoch 7/30\n",
      "2253/2253 [==============================] - 1s 570us/step - loss: 0.9090 - acc: 0.7213 - val_loss: 1.9147 - val_acc: 0.4895\n",
      "Epoch 8/30\n",
      "2253/2253 [==============================] - 1s 541us/step - loss: 0.8230 - acc: 0.7421 - val_loss: 1.9222 - val_acc: 0.4829\n",
      "Epoch 9/30\n",
      "2253/2253 [==============================] - 1s 500us/step - loss: 0.7271 - acc: 0.7901 - val_loss: 2.2401 - val_acc: 0.4646\n",
      "Epoch 10/30\n",
      "2253/2253 [==============================] - 1s 484us/step - loss: 0.6324 - acc: 0.8154 - val_loss: 2.2363 - val_acc: 0.4790\n",
      "Epoch 11/30\n",
      "2253/2253 [==============================] - 1s 449us/step - loss: 0.5839 - acc: 0.8202 - val_loss: 2.5013 - val_acc: 0.4803\n",
      "Epoch 12/30\n",
      "2253/2253 [==============================] - 1s 492us/step - loss: 0.5337 - acc: 0.8442 - val_loss: 2.5990 - val_acc: 0.5026\n",
      "Epoch 13/30\n",
      "2253/2253 [==============================] - 1s 468us/step - loss: 0.4818 - acc: 0.8593 - val_loss: 2.4791 - val_acc: 0.4974\n",
      "Epoch 14/30\n",
      "2253/2253 [==============================] - 1s 474us/step - loss: 0.4310 - acc: 0.8744 - val_loss: 2.8043 - val_acc: 0.4948\n",
      "Epoch 15/30\n",
      "2253/2253 [==============================] - 1s 452us/step - loss: 0.4207 - acc: 0.8810 - val_loss: 2.7879 - val_acc: 0.4961\n",
      "Epoch 16/30\n",
      "2253/2253 [==============================] - 1s 495us/step - loss: 0.3848 - acc: 0.8886 - val_loss: 3.3058 - val_acc: 0.4948\n",
      "Epoch 17/30\n",
      "2253/2253 [==============================] - 1s 529us/step - loss: 0.3841 - acc: 0.8846 - val_loss: 2.6795 - val_acc: 0.4829\n",
      "Epoch 18/30\n",
      "2253/2253 [==============================] - 1s 529us/step - loss: 0.3248 - acc: 0.9041 - val_loss: 3.0743 - val_acc: 0.4934\n",
      "Epoch 19/30\n",
      "2253/2253 [==============================] - 1s 453us/step - loss: 0.3289 - acc: 0.9068 - val_loss: 3.2118 - val_acc: 0.5000\n",
      "Epoch 20/30\n",
      "2253/2253 [==============================] - 1s 503us/step - loss: 0.3494 - acc: 0.8921 - val_loss: 2.9185 - val_acc: 0.5013\n",
      "Epoch 21/30\n",
      "2253/2253 [==============================] - 1s 452us/step - loss: 0.3145 - acc: 0.9055 - val_loss: 3.2845 - val_acc: 0.4829\n",
      "Epoch 22/30\n",
      "2253/2253 [==============================] - 1s 522us/step - loss: 0.2840 - acc: 0.9148 - val_loss: 3.5717 - val_acc: 0.5026\n",
      "Epoch 23/30\n",
      "2253/2253 [==============================] - 1s 442us/step - loss: 0.2448 - acc: 0.9277 - val_loss: 3.3893 - val_acc: 0.5013\n",
      "Epoch 24/30\n",
      "2253/2253 [==============================] - 1s 483us/step - loss: 0.2424 - acc: 0.9330 - val_loss: 3.5076 - val_acc: 0.5026\n",
      "Epoch 25/30\n",
      "2253/2253 [==============================] - 1s 466us/step - loss: 0.2767 - acc: 0.9237 - val_loss: 3.4327 - val_acc: 0.4921\n",
      "Epoch 26/30\n",
      "2253/2253 [==============================] - 1s 499us/step - loss: 0.2594 - acc: 0.9232 - val_loss: 3.5926 - val_acc: 0.4843\n",
      "Epoch 27/30\n",
      "2253/2253 [==============================] - 1s 477us/step - loss: 0.2473 - acc: 0.9334 - val_loss: 3.8166 - val_acc: 0.4606\n",
      "Epoch 28/30\n",
      "2253/2253 [==============================] - 1s 527us/step - loss: 0.2405 - acc: 0.9334 - val_loss: 3.4170 - val_acc: 0.4685\n",
      "Epoch 29/30\n",
      "2253/2253 [==============================] - 1s 497us/step - loss: 0.2056 - acc: 0.9379 - val_loss: 3.4661 - val_acc: 0.5013\n",
      "Epoch 30/30\n",
      "2253/2253 [==============================] - 1s 561us/step - loss: 0.1830 - acc: 0.9454 - val_loss: 3.8342 - val_acc: 0.4856\n",
      "762/762 [==============================] - 0s 135us/step\n",
      "Fold 2 :\n",
      "\n",
      "Train on 2261 samples, validate on 754 samples\n",
      "Epoch 1/30\n",
      "2261/2261 [==============================] - 2s 883us/step - loss: 2.3244 - acc: 0.2004 - val_loss: 2.1198 - val_acc: 0.2653\n",
      "Epoch 2/30\n",
      "2261/2261 [==============================] - 1s 379us/step - loss: 2.0710 - acc: 0.2189 - val_loss: 2.0597 - val_acc: 0.2215\n",
      "Epoch 3/30\n",
      "2261/2261 [==============================] - 1s 367us/step - loss: 1.9538 - acc: 0.2570 - val_loss: 2.0356 - val_acc: 0.2772\n",
      "Epoch 4/30\n",
      "2261/2261 [==============================] - 1s 380us/step - loss: 1.7680 - acc: 0.3711 - val_loss: 1.8370 - val_acc: 0.4138\n",
      "Epoch 5/30\n",
      "2261/2261 [==============================] - 1s 378us/step - loss: 1.5130 - acc: 0.4856 - val_loss: 1.7823 - val_acc: 0.4668\n",
      "Epoch 6/30\n",
      "2261/2261 [==============================] - 1s 401us/step - loss: 1.3276 - acc: 0.5559 - val_loss: 1.7335 - val_acc: 0.5000\n",
      "Epoch 7/30\n",
      "2261/2261 [==============================] - 1s 389us/step - loss: 1.1400 - acc: 0.6289 - val_loss: 1.7471 - val_acc: 0.4828\n",
      "Epoch 8/30\n",
      "2261/2261 [==============================] - 1s 377us/step - loss: 1.0012 - acc: 0.6762 - val_loss: 1.9284 - val_acc: 0.5225\n",
      "Epoch 9/30\n",
      "2261/2261 [==============================] - 1s 490us/step - loss: 0.9084 - acc: 0.7107 - val_loss: 1.9521 - val_acc: 0.5292\n",
      "Epoch 10/30\n",
      "2261/2261 [==============================] - 1s 393us/step - loss: 0.8559 - acc: 0.7346 - val_loss: 1.9062 - val_acc: 0.5451\n",
      "Epoch 11/30\n",
      "2261/2261 [==============================] - 1s 466us/step - loss: 0.7726 - acc: 0.7576 - val_loss: 2.0287 - val_acc: 0.5318\n",
      "Epoch 12/30\n",
      "2261/2261 [==============================] - 1s 565us/step - loss: 0.6924 - acc: 0.7868 - val_loss: 2.0925 - val_acc: 0.5398\n",
      "Epoch 13/30\n",
      "2261/2261 [==============================] - 1s 653us/step - loss: 0.6628 - acc: 0.7930 - val_loss: 2.1178 - val_acc: 0.5119\n",
      "Epoch 14/30\n",
      "2261/2261 [==============================] - 1s 541us/step - loss: 0.6168 - acc: 0.8063 - val_loss: 2.3579 - val_acc: 0.5305\n",
      "Epoch 15/30\n",
      "2261/2261 [==============================] - 1s 605us/step - loss: 0.5952 - acc: 0.8271 - val_loss: 2.4458 - val_acc: 0.5186\n",
      "Epoch 16/30\n",
      "2261/2261 [==============================] - 1s 489us/step - loss: 0.5402 - acc: 0.8328 - val_loss: 2.5059 - val_acc: 0.5159\n",
      "Epoch 17/30\n",
      "2261/2261 [==============================] - 1s 484us/step - loss: 0.5399 - acc: 0.8430 - val_loss: 2.2621 - val_acc: 0.5544\n",
      "Epoch 18/30\n",
      "2261/2261 [==============================] - 1s 549us/step - loss: 0.4743 - acc: 0.8505 - val_loss: 2.3885 - val_acc: 0.5570\n",
      "Epoch 19/30\n",
      "2261/2261 [==============================] - 1s 543us/step - loss: 0.4416 - acc: 0.8686 - val_loss: 2.6007 - val_acc: 0.5491\n",
      "Epoch 20/30\n",
      "2261/2261 [==============================] - 1s 547us/step - loss: 0.4066 - acc: 0.8832 - val_loss: 2.6231 - val_acc: 0.5398\n",
      "Epoch 21/30\n",
      "2261/2261 [==============================] - 1s 477us/step - loss: 0.4225 - acc: 0.8766 - val_loss: 2.5127 - val_acc: 0.5544\n",
      "Epoch 22/30\n",
      "2261/2261 [==============================] - 1s 507us/step - loss: 0.4021 - acc: 0.8850 - val_loss: 2.5712 - val_acc: 0.5690\n",
      "Epoch 23/30\n",
      "2261/2261 [==============================] - 1s 492us/step - loss: 0.3952 - acc: 0.8863 - val_loss: 2.8076 - val_acc: 0.5424\n",
      "Epoch 24/30\n",
      "2261/2261 [==============================] - ETA: 0s - loss: 0.3789 - acc: 0.8941- ETA: 0s - loss: 0.3510 - - 1s 482us/step - loss: 0.3783 - acc: 0.8943 - val_loss: 2.6740 - val_acc: 0.5623\n",
      "Epoch 25/30\n",
      "2261/2261 [==============================] - 1s 496us/step - loss: 0.3660 - acc: 0.8912 - val_loss: 2.9375 - val_acc: 0.5424\n",
      "Epoch 26/30\n",
      "2261/2261 [==============================] - 1s 511us/step - loss: 0.3258 - acc: 0.8969 - val_loss: 2.9476 - val_acc: 0.5305\n",
      "Epoch 27/30\n",
      "2261/2261 [==============================] - 1s 452us/step - loss: 0.3274 - acc: 0.8974 - val_loss: 3.2128 - val_acc: 0.5464\n",
      "Epoch 28/30\n",
      "2261/2261 [==============================] - 1s 485us/step - loss: 0.3198 - acc: 0.9098 - val_loss: 3.0167 - val_acc: 0.5438\n",
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2261/2261 [==============================] - 1s 481us/step - loss: 0.3155 - acc: 0.9107 - val_loss: 3.1431 - val_acc: 0.5504\n",
      "Epoch 30/30\n",
      "2261/2261 [==============================] - 1s 477us/step - loss: 0.3176 - acc: 0.9089 - val_loss: 2.8194 - val_acc: 0.5318\n",
      "754/754 [==============================] - 0s 124us/step\n",
      "Fold 3 :\n",
      "\n",
      "Train on 2265 samples, validate on 750 samples\n",
      "Epoch 1/30\n",
      "2265/2265 [==============================] - 2s 1ms/step - loss: 2.3096 - acc: 0.2026 - val_loss: 2.0974 - val_acc: 0.2160\n",
      "Epoch 2/30\n",
      "2265/2265 [==============================] - 1s 343us/step - loss: 2.0579 - acc: 0.2185 - val_loss: 2.0198 - val_acc: 0.2360\n",
      "Epoch 3/30\n",
      "2265/2265 [==============================] - 1s 399us/step - loss: 1.8232 - acc: 0.3351 - val_loss: 1.8834 - val_acc: 0.3440\n",
      "Epoch 4/30\n",
      "2265/2265 [==============================] - 1s 368us/step - loss: 1.5636 - acc: 0.4755 - val_loss: 1.7312 - val_acc: 0.4240\n",
      "Epoch 5/30\n",
      "2265/2265 [==============================] - 1s 388us/step - loss: 1.3223 - acc: 0.5726 - val_loss: 1.7486 - val_acc: 0.4933\n",
      "Epoch 6/30\n",
      "2265/2265 [==============================] - 1s 407us/step - loss: 1.1486 - acc: 0.6521 - val_loss: 1.7257 - val_acc: 0.4920\n",
      "Epoch 7/30\n",
      "2265/2265 [==============================] - 1s 481us/step - loss: 1.0161 - acc: 0.6923 - val_loss: 1.9162 - val_acc: 0.5053\n",
      "Epoch 8/30\n",
      "2265/2265 [==============================] - 1s 460us/step - loss: 0.9144 - acc: 0.7219 - val_loss: 1.8937 - val_acc: 0.5387\n",
      "Epoch 9/30\n",
      "2265/2265 [==============================] - 1s 383us/step - loss: 0.8378 - acc: 0.7448 - val_loss: 1.8832 - val_acc: 0.5133\n",
      "Epoch 10/30\n",
      "2265/2265 [==============================] - 1s 492us/step - loss: 0.7596 - acc: 0.7514 - val_loss: 2.0596 - val_acc: 0.5133\n",
      "Epoch 11/30\n",
      "2265/2265 [==============================] - 1s 426us/step - loss: 0.7358 - acc: 0.7607 - val_loss: 2.2187 - val_acc: 0.5200\n",
      "Epoch 12/30\n",
      "2265/2265 [==============================] - 1s 434us/step - loss: 0.6783 - acc: 0.7912 - val_loss: 2.3017 - val_acc: 0.5373\n",
      "Epoch 13/30\n",
      "2265/2265 [==============================] - 1s 509us/step - loss: 0.6309 - acc: 0.8044 - val_loss: 2.3328 - val_acc: 0.5253\n",
      "Epoch 14/30\n",
      "2265/2265 [==============================] - 1s 399us/step - loss: 0.5841 - acc: 0.8141 - val_loss: 2.5213 - val_acc: 0.5440\n",
      "Epoch 15/30\n",
      "2265/2265 [==============================] - 1s 389us/step - loss: 0.5699 - acc: 0.8234 - val_loss: 2.5436 - val_acc: 0.5373\n",
      "Epoch 16/30\n",
      "2265/2265 [==============================] - 1s 383us/step - loss: 0.4905 - acc: 0.8455 - val_loss: 2.7257 - val_acc: 0.5440\n",
      "Epoch 17/30\n",
      "2265/2265 [==============================] - 1s 383us/step - loss: 0.5458 - acc: 0.8327 - val_loss: 2.6342 - val_acc: 0.5307\n",
      "Epoch 18/30\n",
      "2265/2265 [==============================] - 1s 374us/step - loss: 0.4767 - acc: 0.8499 - val_loss: 2.6456 - val_acc: 0.5320\n",
      "Epoch 19/30\n",
      "2265/2265 [==============================] - 1s 379us/step - loss: 0.4381 - acc: 0.8649 - val_loss: 2.6983 - val_acc: 0.5440\n",
      "Epoch 20/30\n",
      "2265/2265 [==============================] - 1s 560us/step - loss: 0.4288 - acc: 0.8755 - val_loss: 2.8581 - val_acc: 0.5333\n",
      "Epoch 21/30\n",
      "2265/2265 [==============================] - 1s 396us/step - loss: 0.3850 - acc: 0.8777 - val_loss: 2.9464 - val_acc: 0.5453\n",
      "Epoch 22/30\n",
      "2265/2265 [==============================] - 1s 440us/step - loss: 0.3931 - acc: 0.8826 - val_loss: 3.2409 - val_acc: 0.5347\n",
      "Epoch 23/30\n",
      "2265/2265 [==============================] - 1s 393us/step - loss: 0.3793 - acc: 0.8804 - val_loss: 3.0806 - val_acc: 0.5533\n",
      "Epoch 24/30\n",
      "2265/2265 [==============================] - 1s 432us/step - loss: 0.3471 - acc: 0.8923 - val_loss: 3.0529 - val_acc: 0.5387\n",
      "Epoch 25/30\n",
      "2265/2265 [==============================] - 1s 392us/step - loss: 0.3374 - acc: 0.8993 - val_loss: 3.0217 - val_acc: 0.5507\n",
      "Epoch 26/30\n",
      "2265/2265 [==============================] - 1s 382us/step - loss: 0.3228 - acc: 0.8989 - val_loss: 3.2034 - val_acc: 0.5373\n",
      "Epoch 27/30\n",
      "2265/2265 [==============================] - 1s 386us/step - loss: 0.3647 - acc: 0.8923 - val_loss: 3.0303 - val_acc: 0.5560\n",
      "Epoch 28/30\n",
      "2265/2265 [==============================] - 1s 389us/step - loss: 0.3119 - acc: 0.9082 - val_loss: 3.2323 - val_acc: 0.5453\n",
      "Epoch 29/30\n",
      "2265/2265 [==============================] - 1s 427us/step - loss: 0.3115 - acc: 0.9091 - val_loss: 3.1765 - val_acc: 0.5480\n",
      "Epoch 30/30\n",
      "2265/2265 [==============================] - 1s 428us/step - loss: 0.3018 - acc: 0.9130 - val_loss: 3.0879 - val_acc: 0.5680\n",
      "750/750 [==============================] - 0s 66us/step\n",
      "Fold 4 :\n",
      "\n",
      "Train on 2266 samples, validate on 749 samples\n",
      "Epoch 1/30\n",
      "2266/2266 [==============================] - 1s 646us/step - loss: 2.3293 - acc: 0.1946 - val_loss: 2.1053 - val_acc: 0.2163\n",
      "Epoch 2/30\n",
      "2266/2266 [==============================] - 1s 227us/step - loss: 2.0717 - acc: 0.2101 - val_loss: 2.0271 - val_acc: 0.2056\n",
      "Epoch 3/30\n",
      "2266/2266 [==============================] - 1s 233us/step - loss: 1.8510 - acc: 0.3314 - val_loss: 1.8350 - val_acc: 0.3925\n",
      "Epoch 4/30\n",
      "2266/2266 [==============================] - 1s 225us/step - loss: 1.6009 - acc: 0.4462 - val_loss: 1.7105 - val_acc: 0.4606\n",
      "Epoch 5/30\n",
      "2266/2266 [==============================] - 1s 240us/step - loss: 1.3487 - acc: 0.5560 - val_loss: 1.6169 - val_acc: 0.5541\n",
      "Epoch 6/30\n",
      "2266/2266 [==============================] - 1s 240us/step - loss: 1.1683 - acc: 0.6231 - val_loss: 1.6453 - val_acc: 0.5501\n",
      "Epoch 7/30\n",
      "2266/2266 [==============================] - 1s 226us/step - loss: 0.9999 - acc: 0.6942 - val_loss: 1.7140 - val_acc: 0.5594\n",
      "Epoch 8/30\n",
      "2266/2266 [==============================] - 0s 220us/step - loss: 0.9345 - acc: 0.6990 - val_loss: 1.8962 - val_acc: 0.5527\n",
      "Epoch 9/30\n",
      "2266/2266 [==============================] - 1s 241us/step - loss: 0.8101 - acc: 0.7502 - val_loss: 1.8954 - val_acc: 0.5754\n",
      "Epoch 10/30\n",
      "2266/2266 [==============================] - 1s 221us/step - loss: 0.7500 - acc: 0.7657 - val_loss: 1.8710 - val_acc: 0.5808\n",
      "Epoch 11/30\n",
      "2266/2266 [==============================] - 1s 238us/step - loss: 0.6939 - acc: 0.7868 - val_loss: 2.2615 - val_acc: 0.5594\n",
      "Epoch 12/30\n",
      "2266/2266 [==============================] - 1s 234us/step - loss: 0.6230 - acc: 0.7952 - val_loss: 2.1568 - val_acc: 0.5728\n",
      "Epoch 13/30\n",
      "2266/2266 [==============================] - 1s 272us/step - loss: 0.6070 - acc: 0.8054 - val_loss: 2.1294 - val_acc: 0.5581\n",
      "Epoch 14/30\n",
      "2266/2266 [==============================] - 1s 228us/step - loss: 0.5555 - acc: 0.8182 - val_loss: 2.2430 - val_acc: 0.5688\n",
      "Epoch 15/30\n",
      "2266/2266 [==============================] - 0s 221us/step - loss: 0.5542 - acc: 0.8199 - val_loss: 2.4303 - val_acc: 0.5621\n",
      "Epoch 16/30\n",
      "2266/2266 [==============================] - 1s 221us/step - loss: 0.4985 - acc: 0.8455 - val_loss: 2.3484 - val_acc: 0.5728\n",
      "Epoch 17/30\n",
      "2266/2266 [==============================] - 1s 273us/step - loss: 0.4569 - acc: 0.8601 - val_loss: 2.6492 - val_acc: 0.5554\n",
      "Epoch 18/30\n",
      "2266/2266 [==============================] - 1s 319us/step - loss: 0.4131 - acc: 0.8680 - val_loss: 2.7326 - val_acc: 0.5407\n",
      "Epoch 19/30\n",
      "2266/2266 [==============================] - 1s 231us/step - loss: 0.3914 - acc: 0.8751 - val_loss: 2.7580 - val_acc: 0.5594\n",
      "Epoch 20/30\n",
      "2266/2266 [==============================] - 1s 235us/step - loss: 0.3805 - acc: 0.8879 - val_loss: 2.7822 - val_acc: 0.5487\n",
      "Epoch 21/30\n",
      "2266/2266 [==============================] - 1s 235us/step - loss: 0.3203 - acc: 0.8981 - val_loss: 3.0673 - val_acc: 0.5634\n",
      "Epoch 22/30\n",
      "2266/2266 [==============================] - 1s 235us/step - loss: 0.3110 - acc: 0.9011 - val_loss: 2.9275 - val_acc: 0.5567\n",
      "Epoch 23/30\n",
      "2266/2266 [==============================] - 1s 223us/step - loss: 0.2974 - acc: 0.9117 - val_loss: 3.2333 - val_acc: 0.5688\n",
      "Epoch 24/30\n",
      "2266/2266 [==============================] - 1s 235us/step - loss: 0.3207 - acc: 0.9060 - val_loss: 2.7383 - val_acc: 0.5648\n",
      "Epoch 25/30\n",
      "2266/2266 [==============================] - 0s 221us/step - loss: 0.2673 - acc: 0.9192 - val_loss: 2.9937 - val_acc: 0.5741\n",
      "Epoch 26/30\n",
      "2266/2266 [==============================] - 1s 228us/step - loss: 0.2653 - acc: 0.9197 - val_loss: 3.0179 - val_acc: 0.5621\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2266/2266 [==============================] - 1s 228us/step - loss: 0.2591 - acc: 0.9263 - val_loss: 3.3084 - val_acc: 0.5594\n",
      "Epoch 28/30\n",
      "2266/2266 [==============================] - 1s 237us/step - loss: 0.2398 - acc: 0.9360 - val_loss: 3.1120 - val_acc: 0.5581\n",
      "Epoch 29/30\n",
      "2266/2266 [==============================] - 1s 221us/step - loss: 0.2286 - acc: 0.9351 - val_loss: 3.0657 - val_acc: 0.5634\n",
      "Epoch 30/30\n",
      "2266/2266 [==============================] - 1s 221us/step - loss: 0.2617 - acc: 0.9307 - val_loss: 3.0167 - val_acc: 0.5381\n",
      "749/749 [==============================] - 0s 42us/step\n"
     ]
    }
   ],
   "source": [
    "#k=4\n",
    "kf = StratifiedKFold(n_splits=4, random_state=None, shuffle=False)\n",
    "val_loss_cv = []\n",
    "val_acc_cv = []\n",
    "j = 0\n",
    "for train_index, test_index in kf.split(X,y):\n",
    "    j+=1\n",
    "    print(f\"Fold {j} :\")\n",
    "    print(\"\")\n",
    "    X_train,X_test = X[train_index],X[test_index]\n",
    "    y_train,y_test = y[train_index],y[test_index]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim=X_train.shape[1], units=128,\n",
    "                     kernel_initializer='normal', bias_initializer='zeros'))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    for i in range(0, 6):\n",
    "        model.add(Dense(units=128, kernel_initializer='normal',\n",
    "                         bias_initializer='zeros'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(.15))\n",
    "\n",
    "    model.add(Dense(units=19))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train,batch_size=24,epochs=30,verbose=1,validation_data=(X_test, y_test))\n",
    "    score = model.evaluate(X_test, y_test, verbose=1)\n",
    "    val_loss_cv.append(score[0])\n",
    "    val_acc_cv.append(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss_cv : [3.834176122360029, 2.819357617780448, 3.0878726183573404, 3.0166727856736637]\n",
      "mean_val_loss_cv : 3.1895197860428697\n",
      "val_acc_cv : [0.4855643049312702, 0.5318302390429954, 0.5679999998410543, 0.538050734511364]\n",
      "mean_val_acc_cv : 0.5308613195816709\n"
     ]
    }
   ],
   "source": [
    "print(f\"val_loss_cv : {val_loss_cv}\")\n",
    "print(f\"mean_val_loss_cv : {np.mean(val_loss_cv)}\")\n",
    "print(f\"val_acc_cv : {val_acc_cv}\")\n",
    "print(f\"mean_val_acc_cv : {np.mean(val_acc_cv)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
