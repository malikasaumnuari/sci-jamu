{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#masukin data1\n",
    "data1=pandas.read_csv('D:\\\\SKRIPSI\\\\data\\\\data_praproses\\\\jamu_herbs.csv', sep=',')\n",
    "#masukin data2\n",
    "data2=pandas.read_csv('D:\\\\SKRIPSI\\\\data\\\\data_praproses\\\\jamu_class.csv', sep=',')\n",
    "data_1 = data1.drop('IDJamu',axis=1)\n",
    "data_2 = data2.drop('Jamu ID',axis=1)\n",
    "data_1['Kelas']=data_2['Class of Diseases']\n",
    "X = data_1.drop('Kelas', axis=1).values\n",
    "y = data_1['Kelas'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=4.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 :\n",
      "\n",
      "Train on 2253 samples, validate on 762 samples\n",
      "Epoch 1/30\n",
      "2253/2253 [==============================] - 2s 677us/step - loss: 2.3690 - acc: 0.1869 - val_loss: 2.1166 - val_acc: 0.2100\n",
      "Epoch 2/30\n",
      "2253/2253 [==============================] - 1s 244us/step - loss: 2.0790 - acc: 0.2130 - val_loss: 2.0974 - val_acc: 0.2087\n",
      "Epoch 3/30\n",
      "2253/2253 [==============================] - 1s 233us/step - loss: 1.9462 - acc: 0.2805 - val_loss: 1.9759 - val_acc: 0.3504\n",
      "Epoch 4/30\n",
      "2253/2253 [==============================] - 1s 236us/step - loss: 1.7215 - acc: 0.3937 - val_loss: 1.7821 - val_acc: 0.4304\n",
      "Epoch 5/30\n",
      "2253/2253 [==============================] - 1s 251us/step - loss: 1.4519 - acc: 0.5126 - val_loss: 1.9188 - val_acc: 0.4449\n",
      "Epoch 6/30\n",
      "2253/2253 [==============================] - 1s 233us/step - loss: 1.1992 - acc: 0.6130 - val_loss: 1.9010 - val_acc: 0.4659\n",
      "Epoch 7/30\n",
      "2253/2253 [==============================] - 1s 240us/step - loss: 1.1091 - acc: 0.6636 - val_loss: 1.9905 - val_acc: 0.4974\n",
      "Epoch 8/30\n",
      "2253/2253 [==============================] - 1s 237us/step - loss: 1.0038 - acc: 0.7004 - val_loss: 1.9285 - val_acc: 0.4724\n",
      "Epoch 9/30\n",
      "2253/2253 [==============================] - 1s 235us/step - loss: 0.8774 - acc: 0.7403 - val_loss: 2.1848 - val_acc: 0.4659\n",
      "Epoch 10/30\n",
      "2253/2253 [==============================] - 1s 236us/step - loss: 0.8124 - acc: 0.7506 - val_loss: 2.3454 - val_acc: 0.4777\n",
      "Epoch 11/30\n",
      "2253/2253 [==============================] - 1s 238us/step - loss: 0.7325 - acc: 0.7798 - val_loss: 2.2208 - val_acc: 0.4921\n",
      "Epoch 12/30\n",
      "2253/2253 [==============================] - 1s 240us/step - loss: 0.6759 - acc: 0.8056 - val_loss: 2.6680 - val_acc: 0.4593\n",
      "Epoch 13/30\n",
      "2253/2253 [==============================] - 1s 263us/step - loss: 0.6095 - acc: 0.8096 - val_loss: 2.4813 - val_acc: 0.4869\n",
      "Epoch 14/30\n",
      "2253/2253 [==============================] - 1s 238us/step - loss: 0.5584 - acc: 0.8349 - val_loss: 2.7781 - val_acc: 0.4501\n",
      "Epoch 15/30\n",
      "2253/2253 [==============================] - 1s 236us/step - loss: 0.5361 - acc: 0.8415 - val_loss: 2.7850 - val_acc: 0.4803\n",
      "Epoch 16/30\n",
      "2253/2253 [==============================] - 1s 240us/step - loss: 0.5192 - acc: 0.8562 - val_loss: 2.8167 - val_acc: 0.4738\n",
      "Epoch 17/30\n",
      "2253/2253 [==============================] - 1s 245us/step - loss: 0.4909 - acc: 0.8589 - val_loss: 2.9512 - val_acc: 0.4961\n",
      "Epoch 18/30\n",
      "2253/2253 [==============================] - 1s 240us/step - loss: 0.4860 - acc: 0.8646 - val_loss: 2.9776 - val_acc: 0.5092\n",
      "Epoch 19/30\n",
      "2253/2253 [==============================] - 1s 246us/step - loss: 0.4021 - acc: 0.8899 - val_loss: 3.2003 - val_acc: 0.4790\n",
      "Epoch 20/30\n",
      "2253/2253 [==============================] - 1s 235us/step - loss: 0.4205 - acc: 0.8771 - val_loss: 3.1311 - val_acc: 0.4633\n",
      "Epoch 21/30\n",
      "2253/2253 [==============================] - 1s 241us/step - loss: 0.3874 - acc: 0.8908 - val_loss: 2.9662 - val_acc: 0.5066\n",
      "Epoch 22/30\n",
      "2253/2253 [==============================] - 1s 243us/step - loss: 0.3638 - acc: 0.9006 - val_loss: 3.4096 - val_acc: 0.4724\n",
      "Epoch 23/30\n",
      "2253/2253 [==============================] - 1s 256us/step - loss: 0.3826 - acc: 0.8908 - val_loss: 3.0700 - val_acc: 0.5013\n",
      "Epoch 24/30\n",
      "2253/2253 [==============================] - 1s 253us/step - loss: 0.3457 - acc: 0.8997 - val_loss: 3.3151 - val_acc: 0.5066\n",
      "Epoch 25/30\n",
      "2253/2253 [==============================] - 1s 261us/step - loss: 0.3518 - acc: 0.8988 - val_loss: 3.1346 - val_acc: 0.4856\n",
      "Epoch 26/30\n",
      "2253/2253 [==============================] - 1s 245us/step - loss: 0.2965 - acc: 0.9166 - val_loss: 3.4135 - val_acc: 0.4961\n",
      "Epoch 27/30\n",
      "2253/2253 [==============================] - 1s 252us/step - loss: 0.3108 - acc: 0.9090 - val_loss: 3.3719 - val_acc: 0.5039\n",
      "Epoch 28/30\n",
      "2253/2253 [==============================] - 1s 242us/step - loss: 0.3024 - acc: 0.9143 - val_loss: 3.1393 - val_acc: 0.4987\n",
      "Epoch 29/30\n",
      "2253/2253 [==============================] - 1s 318us/step - loss: 0.3069 - acc: 0.9188 - val_loss: 3.7920 - val_acc: 0.4646\n",
      "Epoch 30/30\n",
      "2253/2253 [==============================] - 1s 279us/step - loss: 0.3202 - acc: 0.9143 - val_loss: 3.3724 - val_acc: 0.4777\n",
      "762/762 [==============================] - 0s 62us/step\n",
      "Fold 2 :\n",
      "\n",
      "Train on 2261 samples, validate on 754 samples\n",
      "Epoch 1/30\n",
      "2261/2261 [==============================] - 1s 546us/step - loss: 2.3778 - acc: 0.1743 - val_loss: 2.1034 - val_acc: 0.2149\n",
      "Epoch 2/30\n",
      "2261/2261 [==============================] - 1s 257us/step - loss: 2.0730 - acc: 0.2234 - val_loss: 2.0513 - val_acc: 0.2188\n",
      "Epoch 3/30\n",
      "2261/2261 [==============================] - 1s 260us/step - loss: 1.9666 - acc: 0.2711 - val_loss: 1.9754 - val_acc: 0.3342\n",
      "Epoch 4/30\n",
      "2261/2261 [==============================] - 1s 297us/step - loss: 1.7566 - acc: 0.3950 - val_loss: 1.7455 - val_acc: 0.4416\n",
      "Epoch 5/30\n",
      "2261/2261 [==============================] - 1s 384us/step - loss: 1.5707 - acc: 0.4653 - val_loss: 1.7903 - val_acc: 0.4072\n",
      "Epoch 6/30\n",
      "2261/2261 [==============================] - 1s 269us/step - loss: 1.4149 - acc: 0.5338 - val_loss: 1.7212 - val_acc: 0.4695\n",
      "Epoch 7/30\n",
      "2261/2261 [==============================] - 1s 317us/step - loss: 1.2439 - acc: 0.5958 - val_loss: 1.6296 - val_acc: 0.4907\n",
      "Epoch 8/30\n",
      "2261/2261 [==============================] - 1s 258us/step - loss: 1.0990 - acc: 0.6515 - val_loss: 1.6955 - val_acc: 0.5212\n",
      "Epoch 9/30\n",
      "2261/2261 [==============================] - 1s 275us/step - loss: 0.9633 - acc: 0.7121 - val_loss: 1.8533 - val_acc: 0.5424\n",
      "Epoch 10/30\n",
      "2261/2261 [==============================] - 1s 269us/step - loss: 0.8512 - acc: 0.7426 - val_loss: 1.8137 - val_acc: 0.5464\n",
      "Epoch 11/30\n",
      "2261/2261 [==============================] - 1s 388us/step - loss: 0.7667 - acc: 0.7691 - val_loss: 2.0340 - val_acc: 0.5119\n",
      "Epoch 12/30\n",
      "2261/2261 [==============================] - 1s 253us/step - loss: 0.7219 - acc: 0.7855 - val_loss: 2.0513 - val_acc: 0.5663\n",
      "Epoch 13/30\n",
      "2261/2261 [==============================] - 1s 250us/step - loss: 0.6842 - acc: 0.8054 - val_loss: 2.0254 - val_acc: 0.5159\n",
      "Epoch 14/30\n",
      "2261/2261 [==============================] - 1s 251us/step - loss: 0.6318 - acc: 0.8107 - val_loss: 1.9452 - val_acc: 0.5464\n",
      "Epoch 15/30\n",
      "2261/2261 [==============================] - 1s 248us/step - loss: 0.6272 - acc: 0.8138 - val_loss: 2.1045 - val_acc: 0.5438\n",
      "Epoch 16/30\n",
      "2261/2261 [==============================] - 1s 239us/step - loss: 0.5644 - acc: 0.8333 - val_loss: 2.3225 - val_acc: 0.5305\n",
      "Epoch 17/30\n",
      "2261/2261 [==============================] - 1s 246us/step - loss: 0.5365 - acc: 0.8395 - val_loss: 2.4722 - val_acc: 0.5305\n",
      "Epoch 18/30\n",
      "2261/2261 [==============================] - 1s 246us/step - loss: 0.5337 - acc: 0.8386 - val_loss: 2.4234 - val_acc: 0.5411\n",
      "Epoch 19/30\n",
      "2261/2261 [==============================] - 1s 245us/step - loss: 0.5425 - acc: 0.8501 - val_loss: 2.5010 - val_acc: 0.5305\n",
      "Epoch 20/30\n",
      "2261/2261 [==============================] - 1s 253us/step - loss: 0.4886 - acc: 0.8589 - val_loss: 2.3991 - val_acc: 0.5305\n",
      "Epoch 21/30\n",
      "2261/2261 [==============================] - 1s 243us/step - loss: 0.4343 - acc: 0.8669 - val_loss: 2.5287 - val_acc: 0.5464\n",
      "Epoch 22/30\n",
      "2261/2261 [==============================] - 1s 243us/step - loss: 0.4437 - acc: 0.8686 - val_loss: 2.5128 - val_acc: 0.5531\n",
      "Epoch 23/30\n",
      "2261/2261 [==============================] - 1s 248us/step - loss: 0.4032 - acc: 0.8731 - val_loss: 2.6681 - val_acc: 0.5172\n",
      "Epoch 24/30\n",
      "2261/2261 [==============================] - 1s 239us/step - loss: 0.3916 - acc: 0.8841 - val_loss: 2.6454 - val_acc: 0.5451\n",
      "Epoch 25/30\n",
      "2261/2261 [==============================] - 1s 249us/step - loss: 0.3922 - acc: 0.8824 - val_loss: 2.7171 - val_acc: 0.5424\n",
      "Epoch 26/30\n",
      "2261/2261 [==============================] - 1s 240us/step - loss: 0.4229 - acc: 0.8824 - val_loss: 2.5529 - val_acc: 0.5332\n",
      "Epoch 27/30\n",
      "2261/2261 [==============================] - 1s 249us/step - loss: 0.4231 - acc: 0.8766 - val_loss: 2.7284 - val_acc: 0.5716\n",
      "Epoch 28/30\n",
      "2261/2261 [==============================] - 1s 246us/step - loss: 0.4261 - acc: 0.8824 - val_loss: 2.8381 - val_acc: 0.5358\n",
      "Epoch 29/30\n",
      "2261/2261 [==============================] - 1s 244us/step - loss: 0.3710 - acc: 0.8877 - val_loss: 2.7571 - val_acc: 0.5517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30\n",
      "2261/2261 [==============================] - 1s 232us/step - loss: 0.3264 - acc: 0.9023 - val_loss: 3.1948 - val_acc: 0.5531\n",
      "754/754 [==============================] - 0s 47us/step\n",
      "Fold 3 :\n",
      "\n",
      "Train on 2265 samples, validate on 750 samples\n",
      "Epoch 1/30\n",
      "2265/2265 [==============================] - 1s 569us/step - loss: 2.3210 - acc: 0.1823 - val_loss: 2.1143 - val_acc: 0.2173\n",
      "Epoch 2/30\n",
      "2265/2265 [==============================] - 1s 247us/step - loss: 2.0673 - acc: 0.2181 - val_loss: 2.0411 - val_acc: 0.2200\n",
      "Epoch 3/30\n",
      "2265/2265 [==============================] - 1s 249us/step - loss: 1.9391 - acc: 0.2808 - val_loss: 1.8954 - val_acc: 0.3267\n",
      "Epoch 4/30\n",
      "2265/2265 [==============================] - 1s 246us/step - loss: 1.6316 - acc: 0.4455 - val_loss: 1.8821 - val_acc: 0.4120\n",
      "Epoch 5/30\n",
      "2265/2265 [==============================] - 1s 249us/step - loss: 1.4268 - acc: 0.5302 - val_loss: 1.7606 - val_acc: 0.4840\n",
      "Epoch 6/30\n",
      "2265/2265 [==============================] - 1s 244us/step - loss: 1.2348 - acc: 0.6163 - val_loss: 1.7955 - val_acc: 0.5147\n",
      "Epoch 7/30\n",
      "2265/2265 [==============================] - 1s 242us/step - loss: 1.0980 - acc: 0.6561 - val_loss: 1.8269 - val_acc: 0.5107\n",
      "Epoch 8/30\n",
      "2265/2265 [==============================] - 1s 246us/step - loss: 0.9951 - acc: 0.6962 - val_loss: 2.0115 - val_acc: 0.4973\n",
      "Epoch 9/30\n",
      "2265/2265 [==============================] - 1s 242us/step - loss: 0.9316 - acc: 0.7099 - val_loss: 1.9961 - val_acc: 0.5253\n",
      "Epoch 10/30\n",
      "2265/2265 [==============================] - 1s 242us/step - loss: 0.8449 - acc: 0.7492 - val_loss: 2.0986 - val_acc: 0.5147\n",
      "Epoch 11/30\n",
      "2265/2265 [==============================] - 1s 249us/step - loss: 0.7864 - acc: 0.7611 - val_loss: 2.3420 - val_acc: 0.4907\n",
      "Epoch 12/30\n",
      "2265/2265 [==============================] - 1s 244us/step - loss: 0.7427 - acc: 0.7779 - val_loss: 2.3200 - val_acc: 0.5187\n",
      "Epoch 13/30\n",
      "2265/2265 [==============================] - 1s 246us/step - loss: 0.7272 - acc: 0.7792 - val_loss: 2.3936 - val_acc: 0.5333\n",
      "Epoch 14/30\n",
      "2265/2265 [==============================] - 1s 242us/step - loss: 0.6533 - acc: 0.8026 - val_loss: 2.3333 - val_acc: 0.5307\n",
      "Epoch 15/30\n",
      "2265/2265 [==============================] - 1s 247us/step - loss: 0.6471 - acc: 0.8097 - val_loss: 2.3245 - val_acc: 0.5427\n",
      "Epoch 16/30\n",
      "2265/2265 [==============================] - 1s 242us/step - loss: 0.5842 - acc: 0.8247 - val_loss: 2.6926 - val_acc: 0.5253\n",
      "Epoch 17/30\n",
      "2265/2265 [==============================] - 1s 248us/step - loss: 0.5567 - acc: 0.8283 - val_loss: 2.5319 - val_acc: 0.5253\n",
      "Epoch 18/30\n",
      "2265/2265 [==============================] - 1s 243us/step - loss: 0.5632 - acc: 0.8424 - val_loss: 2.6932 - val_acc: 0.5280\n",
      "Epoch 19/30\n",
      "2265/2265 [==============================] - 1s 245us/step - loss: 0.5152 - acc: 0.8433 - val_loss: 2.7117 - val_acc: 0.5453\n",
      "Epoch 20/30\n",
      "2265/2265 [==============================] - 1s 244us/step - loss: 0.4968 - acc: 0.8503 - val_loss: 2.8078 - val_acc: 0.5147\n",
      "Epoch 21/30\n",
      "2265/2265 [==============================] - 1s 244us/step - loss: 0.4618 - acc: 0.8614 - val_loss: 2.6428 - val_acc: 0.5227\n",
      "Epoch 22/30\n",
      "2265/2265 [==============================] - 1s 244us/step - loss: 0.4863 - acc: 0.8649 - val_loss: 2.9399 - val_acc: 0.5307\n",
      "Epoch 23/30\n",
      "2265/2265 [==============================] - 1s 242us/step - loss: 0.4495 - acc: 0.8640 - val_loss: 2.8586 - val_acc: 0.5253\n",
      "Epoch 24/30\n",
      "2265/2265 [==============================] - 1s 239us/step - loss: 0.4272 - acc: 0.8755 - val_loss: 2.7254 - val_acc: 0.5333\n",
      "Epoch 25/30\n",
      "2265/2265 [==============================] - 1s 239us/step - loss: 0.4169 - acc: 0.8812 - val_loss: 2.9547 - val_acc: 0.5280\n",
      "Epoch 26/30\n",
      "2265/2265 [==============================] - 1s 239us/step - loss: 0.4219 - acc: 0.8684 - val_loss: 3.1231 - val_acc: 0.5373\n",
      "Epoch 27/30\n",
      "2265/2265 [==============================] - 1s 242us/step - loss: 0.4078 - acc: 0.8768 - val_loss: 2.8887 - val_acc: 0.5507\n",
      "Epoch 28/30\n",
      "2265/2265 [==============================] - 1s 265us/step - loss: 0.4032 - acc: 0.8826 - val_loss: 2.9881 - val_acc: 0.5493\n",
      "Epoch 29/30\n",
      "2265/2265 [==============================] - 1s 338us/step - loss: 0.3510 - acc: 0.8905 - val_loss: 3.1794 - val_acc: 0.5453\n",
      "Epoch 30/30\n",
      "2265/2265 [==============================] - 1s 268us/step - loss: 0.3430 - acc: 0.8967 - val_loss: 2.9862 - val_acc: 0.5493\n",
      "750/750 [==============================] - 0s 52us/step\n",
      "Fold 4 :\n",
      "\n",
      "Train on 2266 samples, validate on 749 samples\n",
      "Epoch 1/30\n",
      "2266/2266 [==============================] - 2s 671us/step - loss: 2.3210 - acc: 0.1973 - val_loss: 2.0825 - val_acc: 0.2163\n",
      "Epoch 2/30\n",
      "2266/2266 [==============================] - 1s 258us/step - loss: 2.0671 - acc: 0.2096 - val_loss: 2.0267 - val_acc: 0.2256\n",
      "Epoch 3/30\n",
      "2266/2266 [==============================] - 1s 262us/step - loss: 1.9604 - acc: 0.2643 - val_loss: 1.9267 - val_acc: 0.3498\n",
      "Epoch 4/30\n",
      "2266/2266 [==============================] - 1s 408us/step - loss: 1.7404 - acc: 0.4042 - val_loss: 1.7698 - val_acc: 0.4473\n",
      "Epoch 5/30\n",
      "2266/2266 [==============================] - 1s 265us/step - loss: 1.4721 - acc: 0.4951 - val_loss: 1.7450 - val_acc: 0.4953\n",
      "Epoch 6/30\n",
      "2266/2266 [==============================] - 1s 247us/step - loss: 1.2805 - acc: 0.5887 - val_loss: 1.6878 - val_acc: 0.4900\n",
      "Epoch 7/30\n",
      "2266/2266 [==============================] - 1s 291us/step - loss: 1.1470 - acc: 0.6280 - val_loss: 1.7487 - val_acc: 0.5207\n",
      "Epoch 8/30\n",
      "2266/2266 [==============================] - 1s 244us/step - loss: 1.0269 - acc: 0.6739 - val_loss: 1.7433 - val_acc: 0.5367\n",
      "Epoch 9/30\n",
      "2266/2266 [==============================] - 1s 267us/step - loss: 0.9515 - acc: 0.6933 - val_loss: 1.8781 - val_acc: 0.5340\n",
      "Epoch 10/30\n",
      "2266/2266 [==============================] - 1s 376us/step - loss: 0.8624 - acc: 0.7158 - val_loss: 1.9000 - val_acc: 0.5407\n",
      "Epoch 11/30\n",
      "2266/2266 [==============================] - 1s 251us/step - loss: 0.7965 - acc: 0.7445 - val_loss: 2.0615 - val_acc: 0.5327\n",
      "Epoch 12/30\n",
      "2266/2266 [==============================] - 1s 304us/step - loss: 0.7437 - acc: 0.7582 - val_loss: 2.0329 - val_acc: 0.5367\n",
      "Epoch 13/30\n",
      "2266/2266 [==============================] - 1s 277us/step - loss: 0.6593 - acc: 0.7868 - val_loss: 2.1693 - val_acc: 0.5394\n",
      "Epoch 14/30\n",
      "2266/2266 [==============================] - 1s 267us/step - loss: 0.6453 - acc: 0.7961 - val_loss: 2.5439 - val_acc: 0.5421\n",
      "Epoch 15/30\n",
      "2266/2266 [==============================] - 1s 383us/step - loss: 0.6221 - acc: 0.8019 - val_loss: 2.5150 - val_acc: 0.5367\n",
      "Epoch 16/30\n",
      "2266/2266 [==============================] - 1s 271us/step - loss: 0.5821 - acc: 0.8116 - val_loss: 2.3045 - val_acc: 0.5461\n",
      "Epoch 17/30\n",
      "2266/2266 [==============================] - 1s 245us/step - loss: 0.5835 - acc: 0.8142 - val_loss: 2.2182 - val_acc: 0.5327\n",
      "Epoch 18/30\n",
      "2266/2266 [==============================] - 1s 247us/step - loss: 0.5678 - acc: 0.8151 - val_loss: 2.6020 - val_acc: 0.5327\n",
      "Epoch 19/30\n",
      "2266/2266 [==============================] - 1s 242us/step - loss: 0.5248 - acc: 0.8310 - val_loss: 2.7224 - val_acc: 0.5260\n",
      "Epoch 20/30\n",
      "2266/2266 [==============================] - 1s 244us/step - loss: 0.5268 - acc: 0.8363 - val_loss: 2.7336 - val_acc: 0.5300\n",
      "Epoch 21/30\n",
      "2266/2266 [==============================] - 1s 240us/step - loss: 0.5069 - acc: 0.8464 - val_loss: 2.6060 - val_acc: 0.5447\n",
      "Epoch 22/30\n",
      "2266/2266 [==============================] - 1s 246us/step - loss: 0.4473 - acc: 0.8544 - val_loss: 2.9008 - val_acc: 0.5554\n",
      "Epoch 23/30\n",
      "2266/2266 [==============================] - 1s 240us/step - loss: 0.4415 - acc: 0.8601 - val_loss: 2.9938 - val_acc: 0.5381\n",
      "Epoch 24/30\n",
      "2266/2266 [==============================] - 1s 242us/step - loss: 0.4436 - acc: 0.8632 - val_loss: 2.9728 - val_acc: 0.5300\n",
      "Epoch 25/30\n",
      "2266/2266 [==============================] - 1s 245us/step - loss: 0.4197 - acc: 0.8729 - val_loss: 2.9207 - val_acc: 0.5688\n",
      "Epoch 26/30\n",
      "2266/2266 [==============================] - 1s 301us/step - loss: 0.3963 - acc: 0.8738 - val_loss: 2.9364 - val_acc: 0.5567\n",
      "Epoch 27/30\n",
      "2266/2266 [==============================] - 1s 354us/step - loss: 0.3873 - acc: 0.8817 - val_loss: 3.0856 - val_acc: 0.5527\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2266/2266 [==============================] - 1s 254us/step - loss: 0.3913 - acc: 0.8875 - val_loss: 3.0415 - val_acc: 0.5461\n",
      "Epoch 29/30\n",
      "2266/2266 [==============================] - 1s 245us/step - loss: 0.3700 - acc: 0.8883 - val_loss: 3.1195 - val_acc: 0.5260\n",
      "Epoch 30/30\n",
      "2266/2266 [==============================] - 1s 261us/step - loss: 0.4106 - acc: 0.8716 - val_loss: 2.9234 - val_acc: 0.5340\n",
      "749/749 [==============================] - 0s 53us/step\n"
     ]
    }
   ],
   "source": [
    "#k=4\n",
    "kf = StratifiedKFold(n_splits=4, random_state=None, shuffle=False)\n",
    "val_loss_cv = []\n",
    "val_acc_cv = []\n",
    "j = 0\n",
    "for train_index, test_index in kf.split(X,y):\n",
    "    j+=1\n",
    "    print(f\"Fold {j} :\")\n",
    "    print(\"\")\n",
    "    X_train,X_test = X[train_index],X[test_index]\n",
    "    y_train,y_test = y[train_index],y[test_index]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim=X_train.shape[1], units=128,\n",
    "                     kernel_initializer='normal', bias_initializer='zeros'))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    for i in range(0, 6):\n",
    "        model.add(Dense(units=128, kernel_initializer='normal',\n",
    "                         bias_initializer='zeros'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(.25))\n",
    "\n",
    "    model.add(Dense(units=19))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train,batch_size=24,epochs=30,verbose=1,validation_data=(X_test, y_test))\n",
    "    score = model.evaluate(X_test, y_test, verbose=1)\n",
    "    val_loss_cv.append(score[0])\n",
    "    val_acc_cv.append(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss_cv : [3.372432643660097, 3.194831607828722, 2.9862142066955566, 2.923446524127303]\n",
      "mean_val_loss_cv : 3.11923124557792\n",
      "val_acc_cv : [0.4776902889094641, 0.5530503980360866, 0.5493333331743876, 0.5340453940574253]\n",
      "mean_val_acc_cv : 0.5285298535443409\n"
     ]
    }
   ],
   "source": [
    "print(f\"val_loss_cv : {val_loss_cv}\")\n",
    "print(f\"mean_val_loss_cv : {np.mean(val_loss_cv)}\")\n",
    "print(f\"val_acc_cv : {val_acc_cv}\")\n",
    "print(f\"mean_val_acc_cv : {np.mean(val_acc_cv)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
