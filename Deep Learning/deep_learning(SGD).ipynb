{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#masukin data1\n",
    "data1=pandas.read_csv('D:\\\\SKRIPSI\\\\data\\\\data_praproses\\\\jamu_herbs.csv', sep=',')\n",
    "#masukin data2\n",
    "data2=pandas.read_csv('D:\\\\SKRIPSI\\\\data\\\\data_praproses\\\\jamu_class.csv', sep=',')\n",
    "data_1 = data1.drop('IDJamu',axis=1)\n",
    "data_2 = data2.drop('Jamu ID',axis=1)\n",
    "data_1['Kelas']=data_2['Class of Diseases']\n",
    "X = data_1.drop('Kelas', axis=1).values\n",
    "y = data_1['Kelas'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=4.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 :\n",
      "\n",
      "Train on 2253 samples, validate on 762 samples\n",
      "Epoch 1/30\n",
      "2253/2253 [==============================] - 2s 783us/step - loss: 2.8822 - acc: 0.2091 - val_loss: 2.8194 - val_acc: 0.2139\n",
      "Epoch 2/30\n",
      "2253/2253 [==============================] - 1s 303us/step - loss: 2.7589 - acc: 0.2157 - val_loss: 2.7009 - val_acc: 0.2139\n",
      "Epoch 3/30\n",
      "2253/2253 [==============================] - 1s 307us/step - loss: 2.6412 - acc: 0.2157 - val_loss: 2.5859 - val_acc: 0.2139\n",
      "Epoch 4/30\n",
      "2253/2253 [==============================] - 1s 335us/step - loss: 2.5264 - acc: 0.2157 - val_loss: 2.4781 - val_acc: 0.2139\n",
      "Epoch 5/30\n",
      "2253/2253 [==============================] - 1s 299us/step - loss: 2.4270 - acc: 0.2157 - val_loss: 2.3876 - val_acc: 0.2139\n",
      "Epoch 6/30\n",
      "2253/2253 [==============================] - 1s 309us/step - loss: 2.3463 - acc: 0.2157 - val_loss: 2.3211 - val_acc: 0.2139\n",
      "Epoch 7/30\n",
      "2253/2253 [==============================] - 1s 309us/step - loss: 2.2859 - acc: 0.2162 - val_loss: 2.2765 - val_acc: 0.2139\n",
      "Epoch 8/30\n",
      "2253/2253 [==============================] - 1s 311us/step - loss: 2.2531 - acc: 0.2184 - val_loss: 2.2480 - val_acc: 0.2139\n",
      "Epoch 9/30\n",
      "2253/2253 [==============================] - 1s 321us/step - loss: 2.2320 - acc: 0.2148 - val_loss: 2.2294 - val_acc: 0.2139\n",
      "Epoch 10/30\n",
      "2253/2253 [==============================] - 1s 339us/step - loss: 2.2119 - acc: 0.2046 - val_loss: 2.2169 - val_acc: 0.2139\n",
      "Epoch 11/30\n",
      "2253/2253 [==============================] - 1s 351us/step - loss: 2.2028 - acc: 0.2086 - val_loss: 2.2083 - val_acc: 0.2139\n",
      "Epoch 12/30\n",
      "2253/2253 [==============================] - 1s 365us/step - loss: 2.1947 - acc: 0.1917 - val_loss: 2.2021 - val_acc: 0.2139\n",
      "Epoch 13/30\n",
      "2253/2253 [==============================] - 1s 362us/step - loss: 2.1882 - acc: 0.2091 - val_loss: 2.1975 - val_acc: 0.2139\n",
      "Epoch 14/30\n",
      "2253/2253 [==============================] - 1s 332us/step - loss: 2.1848 - acc: 0.2099 - val_loss: 2.1942 - val_acc: 0.2139\n",
      "Epoch 15/30\n",
      "2253/2253 [==============================] - 1s 354us/step - loss: 2.1805 - acc: 0.2104 - val_loss: 2.1914 - val_acc: 0.2139\n",
      "Epoch 16/30\n",
      "2253/2253 [==============================] - 1s 313us/step - loss: 2.1788 - acc: 0.2153 - val_loss: 2.1893 - val_acc: 0.2139\n",
      "Epoch 17/30\n",
      "2253/2253 [==============================] - 1s 316us/step - loss: 2.1763 - acc: 0.2015 - val_loss: 2.1877 - val_acc: 0.2139\n",
      "Epoch 18/30\n",
      "2253/2253 [==============================] - 1s 324us/step - loss: 2.1803 - acc: 0.2059 - val_loss: 2.1863 - val_acc: 0.2139\n",
      "Epoch 19/30\n",
      "2253/2253 [==============================] - 1s 321us/step - loss: 2.1740 - acc: 0.2175 - val_loss: 2.1851 - val_acc: 0.2139\n",
      "Epoch 20/30\n",
      "2253/2253 [==============================] - 1s 313us/step - loss: 2.1733 - acc: 0.2002 - val_loss: 2.1841 - val_acc: 0.2139\n",
      "Epoch 21/30\n",
      "2253/2253 [==============================] - 1s 319us/step - loss: 2.1724 - acc: 0.1966 - val_loss: 2.1832 - val_acc: 0.2139\n",
      "Epoch 22/30\n",
      "2253/2253 [==============================] - 1s 315us/step - loss: 2.1694 - acc: 0.2104 - val_loss: 2.1824 - val_acc: 0.2139\n",
      "Epoch 23/30\n",
      "2253/2253 [==============================] - 1s 311us/step - loss: 2.1677 - acc: 0.2148 - val_loss: 2.1819 - val_acc: 0.2139\n",
      "Epoch 24/30\n",
      "2253/2253 [==============================] - 1s 322us/step - loss: 2.1691 - acc: 0.2130 - val_loss: 2.1811 - val_acc: 0.2139\n",
      "Epoch 25/30\n",
      "2253/2253 [==============================] - 1s 319us/step - loss: 2.1666 - acc: 0.2073 - val_loss: 2.1804 - val_acc: 0.2139\n",
      "Epoch 26/30\n",
      "2253/2253 [==============================] - 1s 277us/step - loss: 2.1722 - acc: 0.2082 - val_loss: 2.1800 - val_acc: 0.2139\n",
      "Epoch 27/30\n",
      "2253/2253 [==============================] - 1s 248us/step - loss: 2.1689 - acc: 0.2006 - val_loss: 2.1797 - val_acc: 0.2139\n",
      "Epoch 28/30\n",
      "2253/2253 [==============================] - 1s 257us/step - loss: 2.1692 - acc: 0.2059 - val_loss: 2.1792 - val_acc: 0.2139\n",
      "Epoch 29/30\n",
      "2253/2253 [==============================] - 1s 249us/step - loss: 2.1656 - acc: 0.2037 - val_loss: 2.1788 - val_acc: 0.2139\n",
      "Epoch 30/30\n",
      "2253/2253 [==============================] - 1s 245us/step - loss: 2.1633 - acc: 0.2108 - val_loss: 2.1788 - val_acc: 0.2139\n",
      "762/762 [==============================] - 0s 75us/step\n",
      "Fold 2 :\n",
      "\n",
      "Train on 2261 samples, validate on 754 samples\n",
      "Epoch 1/30\n",
      "2261/2261 [==============================] - 2s 722us/step - loss: 2.8721 - acc: 0.2061 - val_loss: 2.7971 - val_acc: 0.2321\n",
      "Epoch 2/30\n",
      "2261/2261 [==============================] - 1s 315us/step - loss: 2.7284 - acc: 0.2017 - val_loss: 2.6582 - val_acc: 0.2149\n",
      "Epoch 3/30\n",
      "2261/2261 [==============================] - 1s 316us/step - loss: 2.5962 - acc: 0.2061 - val_loss: 2.5298 - val_acc: 0.2149\n",
      "Epoch 4/30\n",
      "2261/2261 [==============================] - 1s 328us/step - loss: 2.4753 - acc: 0.2176 - val_loss: 2.4193 - val_acc: 0.2149\n",
      "Epoch 5/30\n",
      "2261/2261 [==============================] - 1s 323us/step - loss: 2.3787 - acc: 0.2039 - val_loss: 2.3353 - val_acc: 0.2149\n",
      "Epoch 6/30\n",
      "2261/2261 [==============================] - 1s 324us/step - loss: 2.3077 - acc: 0.2061 - val_loss: 2.2789 - val_acc: 0.2149\n",
      "Epoch 7/30\n",
      "2261/2261 [==============================] - ETA: 0s - loss: 2.2656 - acc: 0.212 - 1s 302us/step - loss: 2.2641 - acc: 0.2105 - val_loss: 2.2437 - val_acc: 0.2149\n",
      "Epoch 8/30\n",
      "2261/2261 [==============================] - 1s 323us/step - loss: 2.2379 - acc: 0.2110 - val_loss: 2.2216 - val_acc: 0.2149\n",
      "Epoch 9/30\n",
      "2261/2261 [==============================] - 1s 329us/step - loss: 2.2196 - acc: 0.2136 - val_loss: 2.2073 - val_acc: 0.2149\n",
      "Epoch 10/30\n",
      "2261/2261 [==============================] - 1s 324us/step - loss: 2.2044 - acc: 0.2061 - val_loss: 2.1968 - val_acc: 0.2149\n",
      "Epoch 11/30\n",
      "2261/2261 [==============================] - 1s 320us/step - loss: 2.1958 - acc: 0.2070 - val_loss: 2.1894 - val_acc: 0.2149\n",
      "Epoch 12/30\n",
      "2261/2261 [==============================] - 1s 310us/step - loss: 2.1922 - acc: 0.2132 - val_loss: 2.1842 - val_acc: 0.2149\n",
      "Epoch 13/30\n",
      "2261/2261 [==============================] - 1s 320us/step - loss: 2.1873 - acc: 0.1950 - val_loss: 2.1798 - val_acc: 0.2149\n",
      "Epoch 14/30\n",
      "2261/2261 [==============================] - 1s 325us/step - loss: 2.1851 - acc: 0.2145 - val_loss: 2.1766 - val_acc: 0.2149\n",
      "Epoch 15/30\n",
      "2261/2261 [==============================] - 1s 330us/step - loss: 2.1808 - acc: 0.2132 - val_loss: 2.1740 - val_acc: 0.2149\n",
      "Epoch 16/30\n",
      "2261/2261 [==============================] - 1s 323us/step - loss: 2.1761 - acc: 0.2119 - val_loss: 2.1719 - val_acc: 0.2149\n",
      "Epoch 17/30\n",
      "2261/2261 [==============================] - 1s 312us/step - loss: 2.1736 - acc: 0.2083 - val_loss: 2.1701 - val_acc: 0.2149\n",
      "Epoch 18/30\n",
      "2261/2261 [==============================] - 1s 313us/step - loss: 2.1766 - acc: 0.2119 - val_loss: 2.1689 - val_acc: 0.2149\n",
      "Epoch 19/30\n",
      "2261/2261 [==============================] - 1s 310us/step - loss: 2.1780 - acc: 0.2061 - val_loss: 2.1676 - val_acc: 0.2149\n",
      "Epoch 20/30\n",
      "2261/2261 [==============================] - 1s 314us/step - loss: 2.1780 - acc: 0.2145 - val_loss: 2.1666 - val_acc: 0.2149\n",
      "Epoch 21/30\n",
      "2261/2261 [==============================] - 1s 324us/step - loss: 2.1688 - acc: 0.2092 - val_loss: 2.1660 - val_acc: 0.2149\n",
      "Epoch 22/30\n",
      "2261/2261 [==============================] - 1s 304us/step - loss: 2.1740 - acc: 0.2149 - val_loss: 2.1652 - val_acc: 0.2149\n",
      "Epoch 23/30\n",
      "2261/2261 [==============================] - 1s 304us/step - loss: 2.1742 - acc: 0.2114 - val_loss: 2.1651 - val_acc: 0.2149\n",
      "Epoch 24/30\n",
      "2261/2261 [==============================] - 1s 320us/step - loss: 2.1755 - acc: 0.2074 - val_loss: 2.1641 - val_acc: 0.2149\n",
      "Epoch 25/30\n",
      "2261/2261 [==============================] - 1s 308us/step - loss: 2.1704 - acc: 0.2026 - val_loss: 2.1634 - val_acc: 0.2149\n",
      "Epoch 26/30\n",
      "2261/2261 [==============================] - 1s 328us/step - loss: 2.1694 - acc: 0.2149 - val_loss: 2.1628 - val_acc: 0.2149\n",
      "Epoch 27/30\n",
      "2261/2261 [==============================] - 1s 335us/step - loss: 2.1718 - acc: 0.2052 - val_loss: 2.1623 - val_acc: 0.2149\n",
      "Epoch 28/30\n",
      "2261/2261 [==============================] - 1s 312us/step - loss: 2.1660 - acc: 0.2127 - val_loss: 2.1620 - val_acc: 0.2149\n",
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2261/2261 [==============================] - 1s 304us/step - loss: 2.1749 - acc: 0.2004 - val_loss: 2.1617 - val_acc: 0.2149\n",
      "Epoch 30/30\n",
      "2261/2261 [==============================] - 1s 311us/step - loss: 2.1686 - acc: 0.1995 - val_loss: 2.1616 - val_acc: 0.2149\n",
      "754/754 [==============================] - 0s 92us/step\n",
      "Fold 3 :\n",
      "\n",
      "Train on 2265 samples, validate on 750 samples\n",
      "Epoch 1/30\n",
      "2265/2265 [==============================] - 1s 493us/step - loss: 2.8602 - acc: 0.1916 - val_loss: 2.7732 - val_acc: 0.2160\n",
      "Epoch 2/30\n",
      "2265/2265 [==============================] - 0s 216us/step - loss: 2.6992 - acc: 0.2093 - val_loss: 2.6173 - val_acc: 0.2160\n",
      "Epoch 3/30\n",
      "2265/2265 [==============================] - 1s 226us/step - loss: 2.5523 - acc: 0.2018 - val_loss: 2.4772 - val_acc: 0.2160\n",
      "Epoch 4/30\n",
      "2265/2265 [==============================] - 1s 229us/step - loss: 2.4272 - acc: 0.2088 - val_loss: 2.3673 - val_acc: 0.2160\n",
      "Epoch 5/30\n",
      "2265/2265 [==============================] - 0s 197us/step - loss: 2.3385 - acc: 0.2124 - val_loss: 2.2934 - val_acc: 0.2160\n",
      "Epoch 6/30\n",
      "2265/2265 [==============================] - 0s 198us/step - loss: 2.2833 - acc: 0.2035 - val_loss: 2.2477 - val_acc: 0.2160\n",
      "Epoch 7/30\n",
      "2265/2265 [==============================] - 0s 192us/step - loss: 2.2465 - acc: 0.2088 - val_loss: 2.2182 - val_acc: 0.2160\n",
      "Epoch 8/30\n",
      "2265/2265 [==============================] - 0s 194us/step - loss: 2.2246 - acc: 0.2124 - val_loss: 2.2000 - val_acc: 0.2160\n",
      "Epoch 9/30\n",
      "2265/2265 [==============================] - 0s 207us/step - loss: 2.2094 - acc: 0.2128 - val_loss: 2.1882 - val_acc: 0.2160\n",
      "Epoch 10/30\n",
      "2265/2265 [==============================] - 0s 203us/step - loss: 2.2091 - acc: 0.2022 - val_loss: 2.1802 - val_acc: 0.2160\n",
      "Epoch 11/30\n",
      "2265/2265 [==============================] - 0s 207us/step - loss: 2.1927 - acc: 0.2079 - val_loss: 2.1744 - val_acc: 0.2160\n",
      "Epoch 12/30\n",
      "2265/2265 [==============================] - 0s 196us/step - loss: 2.1895 - acc: 0.2071 - val_loss: 2.1701 - val_acc: 0.2160\n",
      "Epoch 13/30\n",
      "2265/2265 [==============================] - 0s 198us/step - loss: 2.1918 - acc: 0.2044 - val_loss: 2.1671 - val_acc: 0.2160\n",
      "Epoch 14/30\n",
      "2265/2265 [==============================] - 0s 204us/step - loss: 2.1857 - acc: 0.2128 - val_loss: 2.1647 - val_acc: 0.2160\n",
      "Epoch 15/30\n",
      "2265/2265 [==============================] - 0s 194us/step - loss: 2.1842 - acc: 0.2128 - val_loss: 2.1626 - val_acc: 0.2160\n",
      "Epoch 16/30\n",
      "2265/2265 [==============================] - 0s 203us/step - loss: 2.1844 - acc: 0.2168 - val_loss: 2.1609 - val_acc: 0.2160\n",
      "Epoch 17/30\n",
      "2265/2265 [==============================] - 0s 200us/step - loss: 2.1823 - acc: 0.2004 - val_loss: 2.1600 - val_acc: 0.2160\n",
      "Epoch 18/30\n",
      "2265/2265 [==============================] - 0s 205us/step - loss: 2.1759 - acc: 0.2159 - val_loss: 2.1586 - val_acc: 0.2160\n",
      "Epoch 19/30\n",
      "2265/2265 [==============================] - 0s 209us/step - loss: 2.1748 - acc: 0.2137 - val_loss: 2.1574 - val_acc: 0.2160\n",
      "Epoch 20/30\n",
      "2265/2265 [==============================] - 0s 202us/step - loss: 2.1839 - acc: 0.2106 - val_loss: 2.1566 - val_acc: 0.2160\n",
      "Epoch 21/30\n",
      "2265/2265 [==============================] - 0s 205us/step - loss: 2.1771 - acc: 0.2146 - val_loss: 2.1563 - val_acc: 0.2160\n",
      "Epoch 22/30\n",
      "2265/2265 [==============================] - 0s 200us/step - loss: 2.1798 - acc: 0.2026 - val_loss: 2.1551 - val_acc: 0.2160\n",
      "Epoch 23/30\n",
      "2265/2265 [==============================] - 0s 194us/step - loss: 2.1778 - acc: 0.2102 - val_loss: 2.1546 - val_acc: 0.2160\n",
      "Epoch 24/30\n",
      "2265/2265 [==============================] - 0s 210us/step - loss: 2.1722 - acc: 0.2084 - val_loss: 2.1539 - val_acc: 0.2160\n",
      "Epoch 25/30\n",
      "2265/2265 [==============================] - 0s 192us/step - loss: 2.1742 - acc: 0.2049 - val_loss: 2.1532 - val_acc: 0.2160\n",
      "Epoch 26/30\n",
      "2265/2265 [==============================] - 0s 202us/step - loss: 2.1721 - acc: 0.2071 - val_loss: 2.1527 - val_acc: 0.2160\n",
      "Epoch 27/30\n",
      "2265/2265 [==============================] - 0s 201us/step - loss: 2.1745 - acc: 0.2097 - val_loss: 2.1523 - val_acc: 0.2160\n",
      "Epoch 28/30\n",
      "2265/2265 [==============================] - 0s 203us/step - loss: 2.1718 - acc: 0.2146 - val_loss: 2.1524 - val_acc: 0.2160\n",
      "Epoch 29/30\n",
      "2265/2265 [==============================] - 0s 194us/step - loss: 2.1718 - acc: 0.2071 - val_loss: 2.1516 - val_acc: 0.2160\n",
      "Epoch 30/30\n",
      "2265/2265 [==============================] - 0s 205us/step - loss: 2.1753 - acc: 0.2079 - val_loss: 2.1512 - val_acc: 0.2160\n",
      "750/750 [==============================] - 0s 68us/step\n",
      "Fold 4 :\n",
      "\n",
      "Train on 2266 samples, validate on 749 samples\n",
      "Epoch 1/30\n",
      "2266/2266 [==============================] - 1s 503us/step - loss: 2.8833 - acc: 0.2092 - val_loss: 2.8188 - val_acc: 0.2163\n",
      "Epoch 2/30\n",
      "2266/2266 [==============================] - 1s 223us/step - loss: 2.7631 - acc: 0.2136 - val_loss: 2.7019 - val_acc: 0.2163\n",
      "Epoch 3/30\n",
      "2266/2266 [==============================] - 0s 209us/step - loss: 2.6499 - acc: 0.2154 - val_loss: 2.5910 - val_acc: 0.2163\n",
      "Epoch 4/30\n",
      "2266/2266 [==============================] - 0s 203us/step - loss: 2.5447 - acc: 0.2127 - val_loss: 2.4891 - val_acc: 0.2163\n",
      "Epoch 5/30\n",
      "2266/2266 [==============================] - 0s 207us/step - loss: 2.4522 - acc: 0.2162 - val_loss: 2.4030 - val_acc: 0.2163\n",
      "Epoch 6/30\n",
      "2266/2266 [==============================] - 0s 205us/step - loss: 2.3774 - acc: 0.2154 - val_loss: 2.3364 - val_acc: 0.2163\n",
      "Epoch 7/30\n",
      "2266/2266 [==============================] - 0s 197us/step - loss: 2.3242 - acc: 0.2096 - val_loss: 2.2883 - val_acc: 0.2163\n",
      "Epoch 8/30\n",
      "2266/2266 [==============================] - 0s 218us/step - loss: 2.2838 - acc: 0.2176 - val_loss: 2.2542 - val_acc: 0.2163\n",
      "Epoch 9/30\n",
      "2266/2266 [==============================] - 0s 217us/step - loss: 2.2545 - acc: 0.2114 - val_loss: 2.2300 - val_acc: 0.2163\n",
      "Epoch 10/30\n",
      "2266/2266 [==============================] - 0s 207us/step - loss: 2.2374 - acc: 0.2096 - val_loss: 2.2130 - val_acc: 0.2163\n",
      "Epoch 11/30\n",
      "2266/2266 [==============================] - 0s 203us/step - loss: 2.2254 - acc: 0.2132 - val_loss: 2.2005 - val_acc: 0.2163\n",
      "Epoch 12/30\n",
      "2266/2266 [==============================] - 0s 205us/step - loss: 2.2141 - acc: 0.2087 - val_loss: 2.1912 - val_acc: 0.2163\n",
      "Epoch 13/30\n",
      "2266/2266 [==============================] - 0s 216us/step - loss: 2.2049 - acc: 0.2114 - val_loss: 2.1840 - val_acc: 0.2163\n",
      "Epoch 14/30\n",
      "2266/2266 [==============================] - 0s 214us/step - loss: 2.2003 - acc: 0.2083 - val_loss: 2.1787 - val_acc: 0.2163\n",
      "Epoch 15/30\n",
      "2266/2266 [==============================] - 0s 207us/step - loss: 2.1942 - acc: 0.2105 - val_loss: 2.1744 - val_acc: 0.2163\n",
      "Epoch 16/30\n",
      "2266/2266 [==============================] - 0s 198us/step - loss: 2.1915 - acc: 0.2162 - val_loss: 2.1710 - val_acc: 0.2163\n",
      "Epoch 17/30\n",
      "2266/2266 [==============================] - 0s 204us/step - loss: 2.1897 - acc: 0.2070 - val_loss: 2.1682 - val_acc: 0.2163\n",
      "Epoch 18/30\n",
      "2266/2266 [==============================] - 0s 201us/step - loss: 2.1882 - acc: 0.2039 - val_loss: 2.1660 - val_acc: 0.2163\n",
      "Epoch 19/30\n",
      "2266/2266 [==============================] - 0s 200us/step - loss: 2.1840 - acc: 0.2193 - val_loss: 2.1641 - val_acc: 0.2163\n",
      "Epoch 20/30\n",
      "2266/2266 [==============================] - 0s 202us/step - loss: 2.1811 - acc: 0.2101 - val_loss: 2.1623 - val_acc: 0.2163\n",
      "Epoch 21/30\n",
      "2266/2266 [==============================] - 0s 194us/step - loss: 2.1857 - acc: 0.2039 - val_loss: 2.1611 - val_acc: 0.2163\n",
      "Epoch 22/30\n",
      "2266/2266 [==============================] - 0s 212us/step - loss: 2.1811 - acc: 0.2079 - val_loss: 2.1597 - val_acc: 0.2163\n",
      "Epoch 23/30\n",
      "2266/2266 [==============================] - 0s 206us/step - loss: 2.1774 - acc: 0.2083 - val_loss: 2.1586 - val_acc: 0.2163\n",
      "Epoch 24/30\n",
      "2266/2266 [==============================] - 0s 207us/step - loss: 2.1816 - acc: 0.2043 - val_loss: 2.1576 - val_acc: 0.2163\n",
      "Epoch 25/30\n",
      "2266/2266 [==============================] - 0s 204us/step - loss: 2.1826 - acc: 0.2079 - val_loss: 2.1568 - val_acc: 0.2163\n",
      "Epoch 26/30\n",
      "2266/2266 [==============================] - 1s 229us/step - loss: 2.1794 - acc: 0.2056 - val_loss: 2.1561 - val_acc: 0.2163\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2266/2266 [==============================] - 0s 212us/step - loss: 2.1783 - acc: 0.2105 - val_loss: 2.1554 - val_acc: 0.2163\n",
      "Epoch 28/30\n",
      "2266/2266 [==============================] - 0s 200us/step - loss: 2.1797 - acc: 0.2048 - val_loss: 2.1549 - val_acc: 0.2163\n",
      "Epoch 29/30\n",
      "2266/2266 [==============================] - 0s 197us/step - loss: 2.1717 - acc: 0.2105 - val_loss: 2.1542 - val_acc: 0.2163\n",
      "Epoch 30/30\n",
      "2266/2266 [==============================] - 0s 186us/step - loss: 2.1773 - acc: 0.1990 - val_loss: 2.1535 - val_acc: 0.2163\n",
      "749/749 [==============================] - 0s 42us/step\n"
     ]
    }
   ],
   "source": [
    "#k=4\n",
    "kf = StratifiedKFold(n_splits=4, random_state=None, shuffle=False)\n",
    "val_loss_cv = []\n",
    "val_acc_cv = []\n",
    "j = 0\n",
    "for train_index, test_index in kf.split(X,y):\n",
    "    j+=1\n",
    "    print(f\"Fold {j} :\")\n",
    "    print(\"\")\n",
    "    X_train,X_test = X[train_index],X[test_index]\n",
    "    y_train,y_test = y[train_index],y[test_index]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim=X_train.shape[1], units=128,\n",
    "                     kernel_initializer='normal', bias_initializer='zeros'))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    for i in range(0, 6):\n",
    "        model.add(Dense(units=128, kernel_initializer='normal',\n",
    "                         bias_initializer='zeros'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(.15))\n",
    "\n",
    "    model.add(Dense(units=19))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train,batch_size=24,epochs=30,verbose=1,validation_data=(X_test, y_test))\n",
    "    score = model.evaluate(X_test, y_test, verbose=1)\n",
    "    val_loss_cv.append(score[0])\n",
    "    val_acc_cv.append(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss_cv : [2.178764377679099, 2.161570122134464, 2.151235881169637, 2.153547831307425]\n",
      "mean_val_loss_cv : 2.1612795530726565\n",
      "val_acc_cv : [0.21391076115485563, 0.21485411140583555, 0.216, 0.2162883845126836]\n",
      "mean_val_acc_cv : 0.2152633142683437\n"
     ]
    }
   ],
   "source": [
    "print(f\"val_loss_cv : {val_loss_cv}\")\n",
    "print(f\"mean_val_loss_cv : {np.mean(val_loss_cv)}\")\n",
    "print(f\"val_acc_cv : {val_acc_cv}\")\n",
    "print(f\"mean_val_acc_cv : {np.mean(val_acc_cv)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
