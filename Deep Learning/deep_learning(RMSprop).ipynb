{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#masukin data1\n",
    "data1=pandas.read_csv('D:\\\\SKRIPSI\\\\data\\\\data_praproses\\\\jamu_herbs.csv', sep=',')\n",
    "#masukin data2\n",
    "data2=pandas.read_csv('D:\\\\SKRIPSI\\\\data\\\\data_praproses\\\\jamu_class.csv', sep=',')\n",
    "data_1 = data1.drop('IDJamu',axis=1)\n",
    "data_2 = data2.drop('Jamu ID',axis=1)\n",
    "data_1['Kelas']=data_2['Class of Diseases']\n",
    "X = data_1.drop('Kelas', axis=1).values\n",
    "y = data_1['Kelas'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=4.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 :\n",
      "\n",
      "Train on 2253 samples, validate on 762 samples\n",
      "Epoch 1/30\n",
      "2253/2253 [==============================] - 1s 431us/step - loss: 2.2199 - acc: 0.2095 - val_loss: 2.0903 - val_acc: 0.2034\n",
      "Epoch 2/30\n",
      "2253/2253 [==============================] - 1s 234us/step - loss: 2.0260 - acc: 0.2423 - val_loss: 2.0680 - val_acc: 0.2730\n",
      "Epoch 3/30\n",
      "2253/2253 [==============================] - 1s 247us/step - loss: 1.8176 - acc: 0.3347 - val_loss: 1.8831 - val_acc: 0.3583\n",
      "Epoch 4/30\n",
      "2253/2253 [==============================] - 1s 222us/step - loss: 1.6073 - acc: 0.4421 - val_loss: 1.8059 - val_acc: 0.4318\n",
      "Epoch 5/30\n",
      "2253/2253 [==============================] - 0s 217us/step - loss: 1.4187 - acc: 0.5286 - val_loss: 1.8487 - val_acc: 0.4423\n",
      "Epoch 6/30\n",
      "2253/2253 [==============================] - 0s 220us/step - loss: 1.2814 - acc: 0.5908 - val_loss: 1.9234 - val_acc: 0.4252\n",
      "Epoch 7/30\n",
      "2253/2253 [==============================] - 1s 224us/step - loss: 1.1763 - acc: 0.6272 - val_loss: 1.9488 - val_acc: 0.4672\n",
      "Epoch 8/30\n",
      "2253/2253 [==============================] - 0s 220us/step - loss: 1.0622 - acc: 0.6605 - val_loss: 2.5095 - val_acc: 0.4173\n",
      "Epoch 9/30\n",
      "2253/2253 [==============================] - 0s 220us/step - loss: 0.9883 - acc: 0.6964 - val_loss: 2.1377 - val_acc: 0.4895\n",
      "Epoch 10/30\n",
      "2253/2253 [==============================] - 1s 244us/step - loss: 0.9025 - acc: 0.7168 - val_loss: 2.4710 - val_acc: 0.4567\n",
      "Epoch 11/30\n",
      "2253/2253 [==============================] - 0s 220us/step - loss: 0.8437 - acc: 0.7266 - val_loss: 2.2480 - val_acc: 0.4514\n",
      "Epoch 12/30\n",
      "2253/2253 [==============================] - 1s 235us/step - loss: 0.7749 - acc: 0.7585 - val_loss: 2.4763 - val_acc: 0.4383\n",
      "Epoch 13/30\n",
      "2253/2253 [==============================] - 1s 236us/step - loss: 0.7288 - acc: 0.7750 - val_loss: 2.5767 - val_acc: 0.4449\n",
      "Epoch 14/30\n",
      "2253/2253 [==============================] - 0s 208us/step - loss: 0.6810 - acc: 0.7963 - val_loss: 2.7186 - val_acc: 0.4475\n",
      "Epoch 15/30\n",
      "2253/2253 [==============================] - 0s 201us/step - loss: 0.6596 - acc: 0.7989 - val_loss: 2.9803 - val_acc: 0.4344\n",
      "Epoch 16/30\n",
      "2253/2253 [==============================] - 0s 195us/step - loss: 0.6031 - acc: 0.8189 - val_loss: 3.1826 - val_acc: 0.4462\n",
      "Epoch 17/30\n",
      "2253/2253 [==============================] - 0s 195us/step - loss: 0.5769 - acc: 0.8309 - val_loss: 3.4136 - val_acc: 0.4554\n",
      "Epoch 18/30\n",
      "2253/2253 [==============================] - 0s 201us/step - loss: 0.5609 - acc: 0.8287 - val_loss: 3.4851 - val_acc: 0.4278\n",
      "Epoch 19/30\n",
      "2253/2253 [==============================] - 0s 206us/step - loss: 0.5124 - acc: 0.8504 - val_loss: 3.3169 - val_acc: 0.4357\n",
      "Epoch 20/30\n",
      "2253/2253 [==============================] - 0s 201us/step - loss: 0.4954 - acc: 0.8513 - val_loss: 3.3379 - val_acc: 0.4724\n",
      "Epoch 21/30\n",
      "2253/2253 [==============================] - 1s 222us/step - loss: 0.4698 - acc: 0.8557 - val_loss: 3.8644 - val_acc: 0.4449\n",
      "Epoch 22/30\n",
      "2253/2253 [==============================] - 1s 222us/step - loss: 0.4308 - acc: 0.8748 - val_loss: 3.9500 - val_acc: 0.4593\n",
      "Epoch 23/30\n",
      "2253/2253 [==============================] - 0s 219us/step - loss: 0.4213 - acc: 0.8615 - val_loss: 4.0707 - val_acc: 0.4633\n",
      "Epoch 24/30\n",
      "2253/2253 [==============================] - 0s 218us/step - loss: 0.4175 - acc: 0.8708 - val_loss: 4.1806 - val_acc: 0.4646\n",
      "Epoch 25/30\n",
      "2253/2253 [==============================] - 1s 222us/step - loss: 0.4155 - acc: 0.8704 - val_loss: 4.3908 - val_acc: 0.4580\n",
      "Epoch 26/30\n",
      "2253/2253 [==============================] - 1s 223us/step - loss: 0.4005 - acc: 0.8784 - val_loss: 4.2248 - val_acc: 0.4698\n",
      "Epoch 27/30\n",
      "2253/2253 [==============================] - 1s 236us/step - loss: 0.3956 - acc: 0.8797 - val_loss: 3.9302 - val_acc: 0.4790\n",
      "Epoch 28/30\n",
      "2253/2253 [==============================] - 1s 222us/step - loss: 0.3644 - acc: 0.8913 - val_loss: 4.1982 - val_acc: 0.4567\n",
      "Epoch 29/30\n",
      "2253/2253 [==============================] - 1s 222us/step - loss: 0.3283 - acc: 0.8997 - val_loss: 4.3650 - val_acc: 0.4816\n",
      "Epoch 30/30\n",
      "2253/2253 [==============================] - 0s 215us/step - loss: 0.3387 - acc: 0.9006 - val_loss: 4.3484 - val_acc: 0.4869\n",
      "762/762 [==============================] - 0s 41us/step\n",
      "Fold 2 :\n",
      "\n",
      "Train on 2261 samples, validate on 754 samples\n",
      "Epoch 1/30\n",
      "2261/2261 [==============================] - 1s 509us/step - loss: 2.2283 - acc: 0.1937 - val_loss: 2.0694 - val_acc: 0.2149\n",
      "Epoch 2/30\n",
      "2261/2261 [==============================] - 1s 244us/step - loss: 2.0363 - acc: 0.2379 - val_loss: 2.0690 - val_acc: 0.3064\n",
      "Epoch 3/30\n",
      "2261/2261 [==============================] - 0s 221us/step - loss: 1.7991 - acc: 0.3746 - val_loss: 1.7514 - val_acc: 0.4682\n",
      "Epoch 4/30\n",
      "2261/2261 [==============================] - 0s 199us/step - loss: 1.6044 - acc: 0.4724 - val_loss: 1.6482 - val_acc: 0.4496\n",
      "Epoch 5/30\n",
      "2261/2261 [==============================] - 0s 202us/step - loss: 1.4145 - acc: 0.5210 - val_loss: 1.7472 - val_acc: 0.4973\n",
      "Epoch 6/30\n",
      "2261/2261 [==============================] - 0s 194us/step - loss: 1.2872 - acc: 0.5944 - val_loss: 1.7763 - val_acc: 0.4907\n",
      "Epoch 7/30\n",
      "2261/2261 [==============================] - 0s 198us/step - loss: 1.1520 - acc: 0.6413 - val_loss: 1.6508 - val_acc: 0.5133\n",
      "Epoch 8/30\n",
      "2261/2261 [==============================] - 1s 224us/step - loss: 1.0615 - acc: 0.6559 - val_loss: 1.7754 - val_acc: 0.4960\n",
      "Epoch 9/30\n",
      "2261/2261 [==============================] - 1s 226us/step - loss: 0.9845 - acc: 0.6838 - val_loss: 1.7601 - val_acc: 0.5424\n",
      "Epoch 10/30\n",
      "2261/2261 [==============================] - 0s 193us/step - loss: 0.9294 - acc: 0.7032 - val_loss: 1.7789 - val_acc: 0.5305\n",
      "Epoch 11/30\n",
      "2261/2261 [==============================] - 1s 225us/step - loss: 0.8925 - acc: 0.7284 - val_loss: 1.8095 - val_acc: 0.5464\n",
      "Epoch 12/30\n",
      "2261/2261 [==============================] - 0s 203us/step - loss: 0.8327 - acc: 0.7351 - val_loss: 1.8936 - val_acc: 0.5318\n",
      "Epoch 13/30\n",
      "2261/2261 [==============================] - 1s 243us/step - loss: 0.7686 - acc: 0.7665 - val_loss: 2.0288 - val_acc: 0.5411\n",
      "Epoch 14/30\n",
      "2261/2261 [==============================] - 0s 196us/step - loss: 0.7024 - acc: 0.7921 - val_loss: 2.0744 - val_acc: 0.5491\n",
      "Epoch 15/30\n",
      "2261/2261 [==============================] - 0s 219us/step - loss: 0.6880 - acc: 0.7979 - val_loss: 2.1410 - val_acc: 0.5703\n",
      "Epoch 16/30\n",
      "2261/2261 [==============================] - 0s 209us/step - loss: 0.6814 - acc: 0.7948 - val_loss: 2.2133 - val_acc: 0.5411\n",
      "Epoch 17/30\n",
      "2261/2261 [==============================] - 0s 209us/step - loss: 0.6066 - acc: 0.8218 - val_loss: 2.7402 - val_acc: 0.5305\n",
      "Epoch 18/30\n",
      "2261/2261 [==============================] - 0s 209us/step - loss: 0.5821 - acc: 0.8306 - val_loss: 2.3691 - val_acc: 0.5411\n",
      "Epoch 19/30\n",
      "2261/2261 [==============================] - 0s 205us/step - loss: 0.5544 - acc: 0.8328 - val_loss: 2.4453 - val_acc: 0.5318\n",
      "Epoch 20/30\n",
      "2261/2261 [==============================] - 0s 202us/step - loss: 0.5143 - acc: 0.8448 - val_loss: 2.5280 - val_acc: 0.5504\n",
      "Epoch 21/30\n",
      "2261/2261 [==============================] - 0s 218us/step - loss: 0.5254 - acc: 0.8403 - val_loss: 2.4958 - val_acc: 0.5464\n",
      "Epoch 22/30\n",
      "2261/2261 [==============================] - 0s 208us/step - loss: 0.4859 - acc: 0.8540 - val_loss: 2.7919 - val_acc: 0.5597\n",
      "Epoch 23/30\n",
      "2261/2261 [==============================] - 0s 212us/step - loss: 0.4951 - acc: 0.8567 - val_loss: 2.5576 - val_acc: 0.5597\n",
      "Epoch 24/30\n",
      "2261/2261 [==============================] - 0s 211us/step - loss: 0.4688 - acc: 0.8571 - val_loss: 2.5455 - val_acc: 0.5385\n",
      "Epoch 25/30\n",
      "2261/2261 [==============================] - 0s 208us/step - loss: 0.4436 - acc: 0.8673 - val_loss: 2.7561 - val_acc: 0.5531\n",
      "Epoch 26/30\n",
      "2261/2261 [==============================] - 0s 212us/step - loss: 0.4106 - acc: 0.8660 - val_loss: 2.7618 - val_acc: 0.5531\n",
      "Epoch 27/30\n",
      "2261/2261 [==============================] - 0s 210us/step - loss: 0.4305 - acc: 0.8704 - val_loss: 2.9192 - val_acc: 0.5464\n",
      "Epoch 28/30\n",
      "2261/2261 [==============================] - 0s 210us/step - loss: 0.4046 - acc: 0.8815 - val_loss: 3.5476 - val_acc: 0.5239\n",
      "Epoch 29/30\n",
      "2261/2261 [==============================] - 0s 202us/step - loss: 0.3785 - acc: 0.8837 - val_loss: 3.3828 - val_acc: 0.5557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30\n",
      "2261/2261 [==============================] - 0s 212us/step - loss: 0.3862 - acc: 0.8837 - val_loss: 3.0219 - val_acc: 0.5531\n",
      "754/754 [==============================] - 0s 46us/step\n",
      "Fold 3 :\n",
      "\n",
      "Train on 2265 samples, validate on 750 samples\n",
      "Epoch 1/30\n",
      "2265/2265 [==============================] - 1s 504us/step - loss: 2.2300 - acc: 0.1987 - val_loss: 2.0819 - val_acc: 0.2213\n",
      "Epoch 2/30\n",
      "2265/2265 [==============================] - 1s 221us/step - loss: 1.9285 - acc: 0.2971 - val_loss: 1.8697 - val_acc: 0.3507\n",
      "Epoch 3/30\n",
      "2265/2265 [==============================] - 1s 237us/step - loss: 1.7052 - acc: 0.3969 - val_loss: 1.8044 - val_acc: 0.4173\n",
      "Epoch 4/30\n",
      "2265/2265 [==============================] - 1s 233us/step - loss: 1.5991 - acc: 0.4680 - val_loss: 1.8464 - val_acc: 0.4453\n",
      "Epoch 5/30\n",
      "2265/2265 [==============================] - 1s 233us/step - loss: 1.4629 - acc: 0.5130 - val_loss: 1.7439 - val_acc: 0.4693\n",
      "Epoch 6/30\n",
      "2265/2265 [==============================] - 1s 255us/step - loss: 1.2887 - acc: 0.5938 - val_loss: 1.6784 - val_acc: 0.4960\n",
      "Epoch 7/30\n",
      "2265/2265 [==============================] - 1s 306us/step - loss: 1.1703 - acc: 0.6402 - val_loss: 1.7519 - val_acc: 0.5373\n",
      "Epoch 8/30\n",
      "2265/2265 [==============================] - 1s 305us/step - loss: 1.0868 - acc: 0.6706 - val_loss: 1.8466 - val_acc: 0.5467\n",
      "Epoch 9/30\n",
      "2265/2265 [==============================] - 1s 328us/step - loss: 0.9741 - acc: 0.6954 - val_loss: 1.8370 - val_acc: 0.5253\n",
      "Epoch 10/30\n",
      "2265/2265 [==============================] - 1s 345us/step - loss: 0.9016 - acc: 0.7227 - val_loss: 1.9293 - val_acc: 0.5373\n",
      "Epoch 11/30\n",
      "2265/2265 [==============================] - 1s 321us/step - loss: 0.8402 - acc: 0.7329 - val_loss: 1.9942 - val_acc: 0.5413\n",
      "Epoch 12/30\n",
      "2265/2265 [==============================] - 1s 334us/step - loss: 0.7809 - acc: 0.7554 - val_loss: 2.3654 - val_acc: 0.5200\n",
      "Epoch 13/30\n",
      "2265/2265 [==============================] - 1s 334us/step - loss: 0.7326 - acc: 0.7726 - val_loss: 2.3287 - val_acc: 0.5640\n",
      "Epoch 14/30\n",
      "2265/2265 [==============================] - 1s 334us/step - loss: 0.6870 - acc: 0.7903 - val_loss: 2.1925 - val_acc: 0.5320\n",
      "Epoch 15/30\n",
      "2265/2265 [==============================] - 1s 342us/step - loss: 0.6610 - acc: 0.8022 - val_loss: 2.3156 - val_acc: 0.5747\n",
      "Epoch 16/30\n",
      "2265/2265 [==============================] - 1s 368us/step - loss: 0.6166 - acc: 0.8132 - val_loss: 2.3164 - val_acc: 0.5800\n",
      "Epoch 17/30\n",
      "2265/2265 [==============================] - 1s 378us/step - loss: 0.5623 - acc: 0.8265 - val_loss: 2.6880 - val_acc: 0.5680\n",
      "Epoch 18/30\n",
      "2265/2265 [==============================] - 1s 397us/step - loss: 0.5529 - acc: 0.8296 - val_loss: 2.7561 - val_acc: 0.5320\n",
      "Epoch 19/30\n",
      "2265/2265 [==============================] - 1s 378us/step - loss: 0.5291 - acc: 0.8331 - val_loss: 3.0389 - val_acc: 0.5680\n",
      "Epoch 20/30\n",
      "2265/2265 [==============================] - ETA: 0s - loss: 0.4963 - acc: 0.847 - 1s 373us/step - loss: 0.4952 - acc: 0.8481 - val_loss: 2.9086 - val_acc: 0.5813\n",
      "Epoch 21/30\n",
      "2265/2265 [==============================] - 1s 344us/step - loss: 0.4921 - acc: 0.8547 - val_loss: 2.8415 - val_acc: 0.5507\n",
      "Epoch 22/30\n",
      "2265/2265 [==============================] - 1s 344us/step - loss: 0.4504 - acc: 0.8614 - val_loss: 3.3616 - val_acc: 0.5773\n",
      "Epoch 23/30\n",
      "2265/2265 [==============================] - 1s 337us/step - loss: 0.4402 - acc: 0.8627 - val_loss: 3.1637 - val_acc: 0.5867\n",
      "Epoch 24/30\n",
      "2265/2265 [==============================] - 1s 347us/step - loss: 0.4203 - acc: 0.8768 - val_loss: 3.0696 - val_acc: 0.5747\n",
      "Epoch 25/30\n",
      "2265/2265 [==============================] - 1s 345us/step - loss: 0.4147 - acc: 0.8737 - val_loss: 3.1486 - val_acc: 0.5493\n",
      "Epoch 26/30\n",
      "2265/2265 [==============================] - 1s 348us/step - loss: 0.4178 - acc: 0.8834 - val_loss: 3.2278 - val_acc: 0.5973\n",
      "Epoch 27/30\n",
      "2265/2265 [==============================] - 1s 351us/step - loss: 0.3970 - acc: 0.8857 - val_loss: 3.3251 - val_acc: 0.5547\n",
      "Epoch 28/30\n",
      "2265/2265 [==============================] - 1s 344us/step - loss: 0.3593 - acc: 0.8901 - val_loss: 3.5190 - val_acc: 0.5787\n",
      "Epoch 29/30\n",
      "2265/2265 [==============================] - 1s 335us/step - loss: 0.3583 - acc: 0.9024 - val_loss: 3.5596 - val_acc: 0.5960\n",
      "Epoch 30/30\n",
      "2265/2265 [==============================] - 1s 333us/step - loss: 0.3586 - acc: 0.8985 - val_loss: 3.5407 - val_acc: 0.5800\n",
      "750/750 [==============================] - 0s 85us/step\n",
      "Fold 4 :\n",
      "\n",
      "Train on 2266 samples, validate on 749 samples\n",
      "Epoch 1/30\n",
      "2266/2266 [==============================] - 1s 599us/step - loss: 2.2508 - acc: 0.2030 - val_loss: 2.1020 - val_acc: 0.2203\n",
      "Epoch 2/30\n",
      "2266/2266 [==============================] - 1s 339us/step - loss: 2.0654 - acc: 0.2224 - val_loss: 2.0515 - val_acc: 0.2176\n",
      "Epoch 3/30\n",
      "2266/2266 [==============================] - 1s 328us/step - loss: 1.8986 - acc: 0.3129 - val_loss: 1.8700 - val_acc: 0.3578\n",
      "Epoch 4/30\n",
      "2266/2266 [==============================] - 1s 347us/step - loss: 1.6518 - acc: 0.4356 - val_loss: 1.7080 - val_acc: 0.4446\n",
      "Epoch 5/30\n",
      "2266/2266 [==============================] - 1s 341us/step - loss: 1.5138 - acc: 0.4912 - val_loss: 1.7424 - val_acc: 0.4473\n",
      "Epoch 6/30\n",
      "2266/2266 [==============================] - 1s 357us/step - loss: 1.3928 - acc: 0.5503 - val_loss: 1.7263 - val_acc: 0.4646\n",
      "Epoch 7/30\n",
      "2266/2266 [==============================] - 1s 337us/step - loss: 1.2688 - acc: 0.5949 - val_loss: 1.7330 - val_acc: 0.5033\n",
      "Epoch 8/30\n",
      "2266/2266 [==============================] - 1s 341us/step - loss: 1.1541 - acc: 0.6346 - val_loss: 1.6365 - val_acc: 0.5527\n",
      "Epoch 9/30\n",
      "2266/2266 [==============================] - 1s 342us/step - loss: 1.0788 - acc: 0.6664 - val_loss: 1.6499 - val_acc: 0.5367\n",
      "Epoch 10/30\n",
      "2266/2266 [==============================] - 1s 352us/step - loss: 0.9990 - acc: 0.6968 - val_loss: 1.9733 - val_acc: 0.5434\n",
      "Epoch 11/30\n",
      "2266/2266 [==============================] - 1s 332us/step - loss: 0.9349 - acc: 0.7162 - val_loss: 1.7825 - val_acc: 0.5621\n",
      "Epoch 12/30\n",
      "2266/2266 [==============================] - 1s 330us/step - loss: 0.8666 - acc: 0.7251 - val_loss: 1.7909 - val_acc: 0.5834\n",
      "Epoch 13/30\n",
      "2266/2266 [==============================] - 1s 339us/step - loss: 0.8223 - acc: 0.7396 - val_loss: 1.8921 - val_acc: 0.5648\n",
      "Epoch 14/30\n",
      "2266/2266 [==============================] - 1s 338us/step - loss: 0.7720 - acc: 0.7643 - val_loss: 1.9828 - val_acc: 0.5567\n",
      "Epoch 15/30\n",
      "2266/2266 [==============================] - 1s 344us/step - loss: 0.7346 - acc: 0.7595 - val_loss: 2.1848 - val_acc: 0.5541\n",
      "Epoch 16/30\n",
      "2266/2266 [==============================] - 1s 339us/step - loss: 0.6930 - acc: 0.7833 - val_loss: 2.3833 - val_acc: 0.5087\n",
      "Epoch 17/30\n",
      "2266/2266 [==============================] - 1s 320us/step - loss: 0.6790 - acc: 0.7935 - val_loss: 2.2214 - val_acc: 0.5714\n",
      "Epoch 18/30\n",
      "2266/2266 [==============================] - 1s 335us/step - loss: 0.6228 - acc: 0.8010 - val_loss: 2.3433 - val_acc: 0.5781\n",
      "Epoch 19/30\n",
      "2266/2266 [==============================] - 1s 325us/step - loss: 0.5857 - acc: 0.8182 - val_loss: 2.4364 - val_acc: 0.5754\n",
      "Epoch 20/30\n",
      "2266/2266 [==============================] - 1s 340us/step - loss: 0.5556 - acc: 0.8288 - val_loss: 2.8039 - val_acc: 0.5714\n",
      "Epoch 21/30\n",
      "2266/2266 [==============================] - 1s 343us/step - loss: 0.5381 - acc: 0.8350 - val_loss: 2.7397 - val_acc: 0.5781\n",
      "Epoch 22/30\n",
      "2266/2266 [==============================] - 1s 325us/step - loss: 0.4930 - acc: 0.8464 - val_loss: 2.8739 - val_acc: 0.5808\n",
      "Epoch 23/30\n",
      "2266/2266 [==============================] - 1s 331us/step - loss: 0.4937 - acc: 0.8447 - val_loss: 2.8457 - val_acc: 0.5728\n",
      "Epoch 24/30\n",
      "2266/2266 [==============================] - 1s 336us/step - loss: 0.4588 - acc: 0.8628 - val_loss: 2.5999 - val_acc: 0.5581\n",
      "Epoch 25/30\n",
      "2266/2266 [==============================] - 1s 322us/step - loss: 0.4475 - acc: 0.8636 - val_loss: 3.0702 - val_acc: 0.5634\n",
      "Epoch 26/30\n",
      "2266/2266 [==============================] - 1s 336us/step - loss: 0.4273 - acc: 0.8667 - val_loss: 3.1991 - val_acc: 0.5461\n",
      "Epoch 27/30\n",
      "2266/2266 [==============================] - 1s 372us/step - loss: 0.4140 - acc: 0.8778 - val_loss: 3.0394 - val_acc: 0.5567\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2266/2266 [==============================] - 1s 325us/step - loss: 0.4183 - acc: 0.8769 - val_loss: 3.0338 - val_acc: 0.5501\n",
      "Epoch 29/30\n",
      "2266/2266 [==============================] - 1s 325us/step - loss: 0.3956 - acc: 0.8826 - val_loss: 3.5241 - val_acc: 0.5621\n",
      "Epoch 30/30\n",
      "2266/2266 [==============================] - 1s 294us/step - loss: 0.4006 - acc: 0.8813 - val_loss: 3.3693 - val_acc: 0.5447\n",
      "749/749 [==============================] - 0s 63us/step\n"
     ]
    }
   ],
   "source": [
    "#k=4\n",
    "kf = StratifiedKFold(n_splits=4, random_state=None, shuffle=False)\n",
    "val_loss_cv = []\n",
    "val_acc_cv = []\n",
    "j = 0\n",
    "for train_index, test_index in kf.split(X,y):\n",
    "    j+=1\n",
    "    print(f\"Fold {j} :\")\n",
    "    print(\"\")\n",
    "    X_train,X_test = X[train_index],X[test_index]\n",
    "    y_train,y_test = y[train_index],y[test_index]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim=X_train.shape[1], units=128,\n",
    "                     kernel_initializer='normal', bias_initializer='zeros'))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    for i in range(0, 6):\n",
    "        model.add(Dense(units=128, kernel_initializer='normal',\n",
    "                         bias_initializer='zeros'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(.15))\n",
    "\n",
    "    model.add(Dense(units=19))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train,batch_size=24,epochs=30,verbose=1,validation_data=(X_test, y_test))\n",
    "    score = model.evaluate(X_test, y_test, verbose=1)\n",
    "    val_loss_cv.append(score[0])\n",
    "    val_acc_cv.append(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss_cv : [4.348435033963421, 3.021886712992539, 3.5407393372853595, 3.369259163279718]\n",
      "mean_val_loss_cv : 3.5700800618802595\n",
      "val_acc_cv : [0.4868766408892754, 0.5530503979570354, 0.5800000003178915, 0.544726301855016]\n",
      "mean_val_acc_cv : 0.5411633352548045\n"
     ]
    }
   ],
   "source": [
    "print(f\"val_loss_cv : {val_loss_cv}\")\n",
    "print(f\"mean_val_loss_cv : {np.mean(val_loss_cv)}\")\n",
    "print(f\"val_acc_cv : {val_acc_cv}\")\n",
    "print(f\"mean_val_acc_cv : {np.mean(val_acc_cv)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
